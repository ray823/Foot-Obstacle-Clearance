{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0feb1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "D:\\Users\\Ray Lee\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Users\\Ray Lee\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Users\\Ray Lee\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Users\\Ray Lee\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Users\\Ray Lee\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Users\\Ray Lee\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "D:\\Users\\Ray Lee\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Users\\Ray Lee\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Users\\Ray Lee\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Users\\Ray Lee\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Users\\Ray Lee\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Users\\Ray Lee\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sympy as sp\n",
    "import random\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "from sympy.plotting import plot3d\n",
    "from IPython.display import display\n",
    "from sympy import Symbol\n",
    "import scipy.io\n",
    "from mat4py import loadmat\n",
    "import keras\n",
    "from keras.callbacks import History,EarlyStopping\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.recurrent import GRU\n",
    "from keras.layers import Bidirectional\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.layers import Reshape\n",
    "import time\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45844247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E01\\OC10\\Trial40\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E01\\OC10\\Trial41\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E01\\OC10\\Trial49\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E01\\OC10\\Trial50\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E01\\OC20\\Trial100\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E01\\OC20\\Trial109\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E01\\OC20\\Trial110\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E01\\OC20\\Trial99\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E01\\OC30\\Trial113\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E01\\OC30\\Trial114\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E01\\OC30\\Trial116\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E01\\OC30\\Trial121\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E02\\OC10\\Trial110\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E02\\OC10\\Trial111\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E02\\OC10\\Trial115\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E02\\OC10\\Trial116\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E02\\OC20\\Trial152\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E02\\OC20\\Trial153\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E02\\OC20\\Trial157\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E02\\OC20\\Trial158\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E02\\OC30\\Trial173\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E02\\OC30\\Trial174\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E02\\OC30\\Trial177\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E02\\OC30\\Trial178\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E03\\OC10\\Trial20\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E03\\OC10\\Trial21\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E03\\OC10\\Trial25\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E03\\OC10\\Trial26\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E03\\OC20\\Trial71\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E03\\OC20\\Trial72\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E03\\OC20\\Trial77\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E03\\OC20\\Trial78\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E03\\OC30\\Trial81\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E03\\OC30\\Trial82\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E03\\OC30\\Trial87\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E03\\OC30\\Trial88\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E04\\OC10\\Trial45\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E04\\OC10\\Trial46\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E04\\OC10\\Trial50\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E04\\OC10\\Trial52\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E04\\OC20\\Trial70\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E04\\OC20\\Trial71\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E04\\OC20\\Trial74\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E04\\OC20\\Trial75\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E04\\OC30\\Trial90\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E04\\OC30\\Trial91\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E04\\OC30\\Trial98\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E04\\OC30\\Trial99\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E05\\OC10\\Trial41\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E05\\OC10\\Trial42\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E05\\OC10\\Trial45\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E05\\OC10\\Trial46\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E05\\OC20\\Trial81\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E05\\OC20\\Trial82\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E05\\OC20\\Trial86\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E05\\OC20\\Trial87\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E05\\OC30\\Trial110\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E05\\OC30\\Trial111\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E05\\OC30\\Trial114\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E05\\OC30\\Trial115\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E06\\OC10\\Trial24\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E06\\OC10\\Trial25\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E06\\OC10\\Trial30\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E06\\OC10\\Trial32\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E06\\OC20\\Trial72\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E06\\OC20\\Trial74\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E06\\OC20\\Trial76\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E06\\OC20\\Trial77\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E06\\OC30\\Trial130\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E06\\OC30\\Trial132\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E06\\OC30\\Trial138\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E06\\OC30\\Trial142\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E07\\OC10\\Trial46\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E07\\OC10\\Trial47\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E07\\OC10\\Trial48\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E07\\OC10\\Trial50\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E07\\OC20\\Trial67\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E07\\OC20\\Trial69\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E07\\OC20\\Trial73\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E07\\OC20\\Trial75\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E07\\OC30\\Trial100\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E07\\OC30\\Trial104\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E07\\OC30\\Trial105\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E07\\OC30\\Trial97\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E09\\OC10\\Trial54\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E09\\OC10\\Trial55\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E09\\OC10\\Trial56\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E09\\OC10\\Trial60\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E09\\OC20\\Trial78\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E09\\OC20\\Trial81\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E09\\OC20\\Trial83\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E09\\OC20\\Trial88\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E09\\OC30\\Trial102\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E09\\OC30\\Trial105\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E09\\OC30\\Trial111\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E09\\OC30\\Trial112\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E10\\OC10\\Trial55\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E10\\OC10\\Trial56\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E10\\OC10\\Trial58\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E10\\OC10\\Trial60\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E10\\OC20\\Trial85\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E10\\OC20\\Trial87\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E10\\OC20\\Trial92\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E10\\OC20\\Trial93\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E10\\OC30\\Trial110\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E10\\OC30\\Trial112\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E10\\OC30\\Trial120\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E10\\OC30\\Trial122\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E11\\OC10\\Trial47\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E11\\OC10\\Trial48\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E11\\OC10\\Trial55\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E11\\OC10\\Trial56\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E11\\OC20\\Trial70\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E11\\OC20\\Trial71\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E11\\OC20\\Trial74\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E11\\OC20\\Trial75\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E11\\OC30\\Trial127\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E11\\OC30\\Trial128\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E11\\OC30\\Trial134\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E11\\OC30\\Trial135\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E12\\OC10\\Trial27\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E12\\OC10\\Trial30\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E12\\OC10\\Trial34\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E12\\OC10\\Trial35\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E12\\OC20\\Trial101\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E12\\OC20\\Trial82\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E12\\OC20\\Trial94\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E12\\OC20\\Trial96\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E12\\OC30\\Trial121\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E12\\OC30\\Trial122\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E12\\OC30\\Trial123\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E12\\OC30\\Trial126\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E13\\OC10\\Trial49\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E13\\OC10\\Trial50\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E13\\OC10\\Trial52\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E13\\OC10\\Trial54\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E13\\OC20\\Trial87\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E13\\OC20\\Trial88\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E13\\OC20\\Trial90\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E13\\OC20\\Trial91\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E13\\OC30\\Trial107\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E13\\OC30\\Trial108\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E13\\OC30\\Trial113\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E13\\OC30\\Trial116\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E14\\OC10\\Trial48\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E14\\OC10\\Trial49\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E14\\OC10\\Trial50\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E14\\OC10\\Trial52\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E14\\OC20\\Trial58\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E14\\OC20\\Trial59\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E14\\OC20\\Trial60\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E14\\OC20\\Trial62\\Results.mat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E14\\OC30\\Trial92\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E14\\OC30\\Trial93\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E14\\OC30\\Trial95\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E14\\OC30\\Trial96\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E15\\OC10\\Trial36\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E15\\OC10\\Trial38\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E15\\OC10\\Trial39\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E15\\OC10\\Trial45\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E15\\OC20\\Trial59\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E15\\OC20\\Trial60\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E15\\OC20\\Trial65\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E15\\OC20\\Trial66\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E15\\OC30\\Trial111\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E15\\OC30\\Trial112\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E15\\OC30\\Trial115\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E15\\OC30\\Trial117\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E16\\OC10\\Trial36\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E16\\OC10\\Trial37\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E16\\OC10\\Trial39\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E16\\OC10\\Trial40\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E16\\OC20\\Trial72\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E16\\OC20\\Trial73\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E16\\OC20\\Trial79\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E16\\OC20\\Trial80\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E16\\OC30\\Trial122\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E16\\OC30\\Trial123\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E16\\OC30\\Trial126\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E16\\OC30\\Trial128\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E17\\OC10\\Trial50\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E17\\OC10\\Trial52\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E17\\OC10\\Trial54\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E17\\OC10\\Trial57\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E17\\OC20\\Trial74\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E17\\OC20\\Trial75\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E17\\OC20\\Trial80\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E17\\OC20\\Trial81\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E17\\OC30\\Trial127\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E17\\OC30\\Trial129\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E17\\OC30\\Trial138\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E17\\OC30\\Trial139\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E18\\OC10\\Trial73\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E18\\OC10\\Trial74\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E18\\OC10\\Trial77\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E18\\OC10\\Trial87\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E18\\OC20\\Trial100\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E18\\OC20\\Trial97\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E18\\OC20\\Trial98\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E18\\OC20\\Trial99\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E18\\OC30\\Trial162\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E18\\OC30\\Trial163\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E18\\OC30\\Trial164\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E18\\OC30\\Trial165\\Results.mat\n",
      "[[[-1.85592973e+01 -1.90803045e+01 -1.87862629e+01 ... -3.76789879e+00\n",
      "   -6.07677844e+00 -7.29325804e+00]\n",
      "  [-3.84781590e+00 -3.20896126e+00 -2.57869571e+00 ... -5.51788470e+00\n",
      "   -4.58697359e+00 -3.49665725e+00]\n",
      "  [-2.93677355e+00 -2.57873037e+00 -2.59398353e+00 ... -1.42303724e+00\n",
      "   -1.92032046e+00 -2.18092033e+00]\n",
      "  ...\n",
      "  [ 2.22474176e+02  2.22474176e+02  2.22474176e+02 ...  2.22474176e+02\n",
      "    2.22474176e+02  2.22474176e+02]\n",
      "  [ 3.32924076e+02  3.32924076e+02  3.32924076e+02 ...  3.32924076e+02\n",
      "    3.32924076e+02  3.32924076e+02]\n",
      "  [ 3.25739195e+02  3.25739195e+02  3.25739195e+02 ...  3.25739195e+02\n",
      "    3.25739195e+02  3.25739195e+02]]\n",
      "\n",
      " [[-9.70035625e+00 -1.00515583e+01 -9.34058876e+00 ... -3.93716714e+00\n",
      "   -6.02556767e+00 -7.27759620e+00]\n",
      "  [-5.75983350e+00 -4.63195053e+00 -4.14533811e+00 ... -6.21241577e+00\n",
      "   -5.67477095e+00 -4.99240690e+00]\n",
      "  [-2.12273165e+00 -2.18466607e+00 -2.01615504e+00 ... -7.76796907e-01\n",
      "   -1.63168535e+00 -2.36125927e+00]\n",
      "  ...\n",
      "  [ 2.22474176e+02  2.22474176e+02  2.22474176e+02 ...  2.22474176e+02\n",
      "    2.22474176e+02  2.22474176e+02]\n",
      "  [ 3.32924076e+02  3.32924076e+02  3.32924076e+02 ...  3.32924076e+02\n",
      "    3.32924076e+02  3.32924076e+02]\n",
      "  [ 3.25739195e+02  3.25739195e+02  3.25739195e+02 ...  3.25739195e+02\n",
      "    3.25739195e+02  3.25739195e+02]]\n",
      "\n",
      " [[-1.15720778e+01 -1.18184826e+01 -1.10173601e+01 ... -3.21166943e+00\n",
      "   -5.00608685e+00 -5.84269981e+00]\n",
      "  [-5.24339811e+00 -4.27596528e+00 -3.80558949e+00 ... -5.52233219e+00\n",
      "   -4.49130297e+00 -3.24554597e+00]\n",
      "  [-9.02272083e-01 -1.40903206e+00 -1.35969266e+00 ... -1.58003337e-01\n",
      "   -7.84037030e-01 -1.17809700e+00]\n",
      "  ...\n",
      "  [ 2.22474176e+02  2.22474176e+02  2.22474176e+02 ...  2.22474176e+02\n",
      "    2.22474176e+02  2.22474176e+02]\n",
      "  [ 3.32924076e+02  3.32924076e+02  3.32924076e+02 ...  3.32924076e+02\n",
      "    3.32924076e+02  3.32924076e+02]\n",
      "  [ 3.25739195e+02  3.25739195e+02  3.25739195e+02 ...  3.25739195e+02\n",
      "    3.25739195e+02  3.25739195e+02]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-2.07408275e+01 -2.09021243e+01 -1.97168390e+01 ... -4.72394034e+00\n",
      "   -1.00307593e+01 -1.46406110e+01]\n",
      "  [ 1.07871773e+01  9.45764403e+00  8.31552635e+00 ...  1.05886919e+01\n",
      "    1.16722240e+01  1.19547547e+01]\n",
      "  [ 7.73964087e+00  6.69745325e+00  5.86342167e+00 ...  3.57434719e+00\n",
      "    5.11534105e+00  6.11314475e+00]\n",
      "  ...\n",
      "  [ 1.93898408e+02  1.93898408e+02  1.93898408e+02 ...  1.93898408e+02\n",
      "    1.93898408e+02  1.93898408e+02]\n",
      "  [ 3.62922007e+02  3.62922007e+02  3.62922007e+02 ...  3.62922007e+02\n",
      "    3.62922007e+02  3.62922007e+02]\n",
      "  [ 3.87272353e+02  3.87272353e+02  3.87272353e+02 ...  3.87272353e+02\n",
      "    3.87272353e+02  3.87272353e+02]]\n",
      "\n",
      " [[-1.28739509e+01 -1.33402629e+01 -1.29871391e+01 ... -2.98799166e+00\n",
      "   -6.31792698e+00 -8.42909099e+00]\n",
      "  [-1.06409276e+01 -8.81700980e+00 -7.02750342e+00 ... -8.11231115e+00\n",
      "   -9.27487174e+00 -9.11097310e+00]\n",
      "  [-4.40589134e+00 -4.03574491e+00 -3.42930058e+00 ... -1.18276493e+00\n",
      "   -2.14412190e+00 -2.70831465e+00]\n",
      "  ...\n",
      "  [ 1.93898408e+02  1.93898408e+02  1.93898408e+02 ...  1.93898408e+02\n",
      "    1.93898408e+02  1.93898408e+02]\n",
      "  [ 3.62922007e+02  3.62922007e+02  3.62922007e+02 ...  3.62922007e+02\n",
      "    3.62922007e+02  3.62922007e+02]\n",
      "  [ 3.87272353e+02  3.87272353e+02  3.87272353e+02 ...  3.87272353e+02\n",
      "    3.87272353e+02  3.87272353e+02]]\n",
      "\n",
      " [[-1.72287511e+01 -1.67588093e+01 -1.57690390e+01 ... -2.29825144e+00\n",
      "   -5.23610949e+00 -7.48081982e+00]\n",
      "  [-1.05007562e+01 -8.82734832e+00 -7.58036133e+00 ... -7.05032678e+00\n",
      "   -7.73207731e+00 -7.53453948e+00]\n",
      "  [-6.29765750e+00 -5.55503514e+00 -4.76536345e+00 ... -1.04179268e+00\n",
      "   -2.00764950e+00 -2.72531339e+00]\n",
      "  ...\n",
      "  [ 1.93898408e+02  1.93898408e+02  1.93898408e+02 ...  1.93898408e+02\n",
      "    1.93898408e+02  1.93898408e+02]\n",
      "  [ 3.62922007e+02  3.62922007e+02  3.62922007e+02 ...  3.62922007e+02\n",
      "    3.62922007e+02  3.62922007e+02]\n",
      "  [ 3.87272353e+02  3.87272353e+02  3.87272353e+02 ...  3.87272353e+02\n",
      "    3.87272353e+02  3.87272353e+02]]]\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "Results_cross = []\n",
    "\n",
    "def findAllFile_cross(base):\n",
    "    for root, ds, fs in os.walk(base):\n",
    "        for f in fs:\n",
    "            if f.endswith('.mat'):\n",
    "                fullname = os.path.join(root, f)\n",
    "                mat = loadmat(fullname) \n",
    "                Results_cross.append(mat)\n",
    "                yield fullname\n",
    "\n",
    "#build temp list for crossing\n",
    "IKlist = []\n",
    "IAlist = []\n",
    "GVlist = []\n",
    "EPlist = []\n",
    "EP_OBSlist = []\n",
    "AP_01list = []\n",
    "AP_02list = []\n",
    "AP_03list = []\n",
    "AP_04list = []\n",
    "AP_05list = []\n",
    "AP_06list = []\n",
    "\n",
    "\n",
    "AP_01_array = np.empty((1,101))\n",
    "AP_02_array = np.empty((1,101))\n",
    "AP_03_array = np.empty((1,101))\n",
    "AP_04_array = np.empty((1,101))\n",
    "AP_05_array = np.empty((1,101))\n",
    "AP_06_array = np.empty((1,101))\n",
    "\n",
    "IK_array = np.empty((6,101,3))\n",
    "IK_tay = np.empty((3,101))\n",
    "IK_toay = np.empty((6,3,101))\n",
    "\n",
    "\n",
    "IA_array = np.empty((4,101,1))\n",
    "IA_tay = np.empty((1,101))\n",
    "IA_toay = np.empty((4,1,101))\n",
    "\n",
    "GV_array = np.empty((1,101,1))\n",
    "GV_tay = np.empty((1,101))\n",
    "GV_toay = np.empty((1,1,101))\n",
    "\n",
    "\n",
    "\n",
    "Feature = np.empty((29,101))\n",
    "\n",
    "\n",
    "\n",
    "def getfeature(value):\n",
    "    \n",
    "    \n",
    "    #EP_array = np.empty((1))\n",
    "    o = Results_cross[value]['Results']['EP']\n",
    "    EPlist.append(o)\n",
    "    \n",
    "    EP_array = np.array(EPlist[value]['LeadingToeClearance'])\n",
    "    Feature_obstacles1 = EP_array\n",
    "    \n",
    "    \n",
    "    x = Results_cross[value]['Results']['IK']\n",
    "    IKlist.append(x)\n",
    "    \n",
    "    IK_array[0,:,:] = np.array(IKlist[value]['LeadingAnkle'])\n",
    "    IK_array[1,:,:] = np.array(IKlist[value]['LeadingHip'])\n",
    "    IK_array[2,:,:] = np.array(IKlist[value]['LeadingKnee'])\n",
    "    IK_array[3,:,:] = np.array(IKlist[value]['TrailingAnkle'])\n",
    "    IK_array[4,:,:] = np.array(IKlist[value]['TrailingHip'])\n",
    "    IK_array[5,:,:] = np.array(IKlist[value]['TrailingKnee'])\n",
    "    \n",
    "    \n",
    "   \n",
    "    for i in range(IK_toay.shape[0]):  \n",
    "        IK_tay = np.transpose(IK_array[i])\n",
    "        IK_toay[i,:,:] = IK_tay\n",
    "   \n",
    "\n",
    "    k = 0\n",
    "    for i in range(IK_toay.shape[0]):\n",
    "        for j in range(IK_toay.shape[1]):\n",
    "            Feature[k,:] = IK_toay[i,j,:] #k = 3*i+j\n",
    "            k += 1\n",
    "    \n",
    "    y = Results_cross[value]['Results']['IA']\n",
    "    IAlist.append(y)\n",
    "    IA_array[0,:,:] = np.array(IAlist[value]['FrontalIA'])\n",
    "    IA_array[1,:,:] = np.array(IAlist[value]['FrontalRCIA'])\n",
    "    IA_array[2,:,:] = np.array(IAlist[value]['SagittalIA'])\n",
    "    IA_array[3,:,:] = np.array(IAlist[value]['SagittalRCIA'])\n",
    "    \n",
    "    for i in range(IA_array.shape[0]):\n",
    "      IA_tay = np.transpose(IA_array[i])\n",
    "      IA_toay[i,:,:] = IA_tay\n",
    "      \n",
    "\n",
    "    for i in range(IA_toay.shape[0]):\n",
    "        for j in range(IA_toay.shape[1]):\n",
    "            Feature[k,:] = IA_toay[i,j,:] #k = 3*i+j\n",
    "            k += 1\n",
    "    \n",
    "    z = Results_cross[value]['Results']['SelfDefinedVariables']\n",
    "    GVlist.append(z)\n",
    "    GV_array[0,:,:] = np.array(GVlist[value]['GaitVelocity'])\n",
    "    GV_tay = np.transpose(GV_array[0])\n",
    "    GV_toay[0,:,:] = GV_tay\n",
    "    Feature[22,:] = GV_toay[0,0,:]\n",
    "    '''\n",
    "    #從EP取出障礙物高度並與Clearance相加取得toe離地高度\n",
    "    A = Results_cross[value]['Results']['EP']\n",
    "    EP_OBSlist.append(A)\n",
    "    \n",
    "    EP_OBS_array = np.array(EP_OBSlist[value]['OBS']+EP_OBSlist[value]['LeadingToeClearance'])\n",
    "    Feature_obstacles1 = EP_OBS_array\n",
    "    '''\n",
    "    \n",
    "    #取出AP單一值資料並變成序列資料\n",
    "    B = Results_cross[value]['Results']['AP']['BodyHeight']\n",
    "    AP_01list.append(B)\n",
    "    for i in range(101):\n",
    "        AP_01_array[:,i] = np.array(AP_01list[value])\n",
    "        Feature[23,:] = AP_01_array[:,i]\n",
    "    \n",
    "    C = Results_cross[value]['Results']['AP']['BW']\n",
    "    AP_02list.append(C)\n",
    "    for i in range(101):\n",
    "        AP_02_array[:,i] = np.array(AP_02list[value])\n",
    "        Feature[24,:] = AP_02_array[:,i]\n",
    "    \n",
    "    D = Results_cross[value]['Results']['AP']['FootLength']\n",
    "    AP_03list.append(D)\n",
    "    for i in range(101):\n",
    "        AP_03_array[:,i] = np.array(AP_03list[value])\n",
    "        Feature[25,:] = AP_03_array[:,i]\n",
    "        \n",
    "    E = Results_cross[value]['Results']['AP']['HipWidth']\n",
    "    AP_04list.append(E)\n",
    "    for i in range(101):\n",
    "        AP_04_array[:,i] = np.array(AP_04list[value])\n",
    "        Feature[26,:] = AP_04_array[:,i]\n",
    "    \n",
    "    F = Results_cross[value]['Results']['AP']['ShankLength']\n",
    "    AP_05list.append(F)\n",
    "    for i in range(101):\n",
    "        AP_05_array[:,i] = np.array(AP_05list[value])\n",
    "        Feature[27,:] = AP_05_array[:,i]\n",
    "    \n",
    "    G = Results_cross[value]['Results']['AP']['ThighLength']\n",
    "    AP_06list.append(G)\n",
    "    for i in range(101):\n",
    "        AP_06_array[:,i] = np.array(AP_06list[value])\n",
    "        Feature[28,:] = AP_06_array[:,i]\n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "    return Feature,Feature_obstacles1\n",
    "\n",
    "Feature_cross = np.empty((204,29,101))\n",
    "Feature_obstacles = np.empty((204))\n",
    "FEATUREccc = np.empty((29,101))\n",
    "\n",
    "\n",
    "\n",
    "base = r\"C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/\"\n",
    "\n",
    "\n",
    "for i in findAllFile_cross(base):\n",
    "    print(i)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(Results_cross)):\n",
    "    FEATUREccc,Feature_obs= getfeature(i)\n",
    "    Feature_cross[i,:,:] = FEATUREccc\n",
    "    Feature_obstacles[i] = Feature_obs\n",
    "\n",
    "    \n",
    "print(Feature_cross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9309940",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_normalized = (Feature_cross - Feature_cross.mean()) / Feature_cross.std()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_normalized, Feature_obstacles, test_size=0.1, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "#train=0.8，val=0.1，test=0.1\n",
    "\n",
    "# reshape input to be [samples, time steps, features] which is required for LSTM\n",
    "X_train =X_train.reshape(X_train.shape[0],X_train.shape[2] , X_train.shape[1])\n",
    "X_val =X_val.reshape(X_val.shape[0],X_val.shape[2] , X_val.shape[1])\n",
    "X_test = X_test.reshape(X_test.shape[0],X_test.shape[2] , X_test.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebccfc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(keras.layers.Layer):\n",
    "        def __init__(self, attention_units):\n",
    "            super(SelfAttention, self).__init__()\n",
    "            self.attention_units = attention_units\n",
    "\n",
    "        def build(self, input_shape):\n",
    "            self.W = self.add_weight(\n",
    "                shape=(input_shape[-1], self.attention_units),\n",
    "                initializer=\"glorot_uniform\",\n",
    "                trainable=True\n",
    "            )\n",
    "            self.b = self.add_weight(\n",
    "                shape=(self.attention_units,),\n",
    "                initializer=\"zeros\",\n",
    "                trainable=True\n",
    "            )\n",
    "            self.V = self.add_weight(\n",
    "                shape=(self.attention_units, 1),\n",
    "                initializer=\"glorot_uniform\",\n",
    "                trainable=True\n",
    "            )\n",
    "    \n",
    "        def call(self, inputs):\n",
    "            score = keras.activations.tanh(keras.backend.dot(inputs, self.W) + self.b)\n",
    "            attention_weights = keras.activations.softmax(keras.backend.dot(score, self.V), axis=1)\n",
    "            attended_input = inputs * attention_weights\n",
    "            return attended_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "366d3ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Users\\Ray Lee\\anaconda3\\envs\\tf1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 164 samples, validate on 19 samples\n",
      "Epoch 1/2000\n",
      "164/164 [==============================] - 1s 8ms/step - loss: 35182.7440 - val_loss: 25099.5039\n",
      "Epoch 2/2000\n",
      "164/164 [==============================] - 0s 991us/step - loss: 35124.8436 - val_loss: 25036.5176\n",
      "Epoch 3/2000\n",
      "164/164 [==============================] - 0s 979us/step - loss: 35029.5104 - val_loss: 24924.6250\n",
      "Epoch 4/2000\n",
      "164/164 [==============================] - 0s 973us/step - loss: 34856.1557 - val_loss: 24705.5156\n",
      "Epoch 5/2000\n",
      "164/164 [==============================] - 0s 955us/step - loss: 34479.2935 - val_loss: 24157.0840\n",
      "Epoch 6/2000\n",
      "164/164 [==============================] - 0s 924us/step - loss: 33606.0151 - val_loss: 23192.7383\n",
      "Epoch 7/2000\n",
      "164/164 [==============================] - 0s 911us/step - loss: 32206.3219 - val_loss: 21649.4512\n",
      "Epoch 8/2000\n",
      "164/164 [==============================] - 0s 904us/step - loss: 29883.6297 - val_loss: 19105.1875\n",
      "Epoch 9/2000\n",
      "164/164 [==============================] - 0s 946us/step - loss: 26025.3703 - val_loss: 15158.7930\n",
      "Epoch 10/2000\n",
      "164/164 [==============================] - 0s 921us/step - loss: 20170.6911 - val_loss: 9772.8691\n",
      "Epoch 11/2000\n",
      "164/164 [==============================] - 0s 918us/step - loss: 12203.6540 - val_loss: 4725.4160\n",
      "Epoch 12/2000\n",
      "164/164 [==============================] - 0s 912us/step - loss: 4600.4976 - val_loss: 5538.0806\n",
      "Epoch 13/2000\n",
      "164/164 [==============================] - 0s 918us/step - loss: 3676.2151 - val_loss: 10194.4600\n",
      "Epoch 14/2000\n",
      "164/164 [==============================] - 0s 912us/step - loss: 4440.5106 - val_loss: 6788.5879\n",
      "Epoch 15/2000\n",
      "164/164 [==============================] - 0s 918us/step - loss: 3007.3317 - val_loss: 4562.4590\n",
      "Epoch 16/2000\n",
      "164/164 [==============================] - 0s 924us/step - loss: 3050.7218 - val_loss: 4202.7681\n",
      "Epoch 17/2000\n",
      "164/164 [==============================] - 0s 930us/step - loss: 3148.9933 - val_loss: 4582.1489\n",
      "Epoch 18/2000\n",
      "164/164 [==============================] - 0s 930us/step - loss: 2912.3334 - val_loss: 5443.4634\n",
      "Epoch 19/2000\n",
      "164/164 [==============================] - 0s 946us/step - loss: 2988.0233 - val_loss: 6075.2070\n",
      "Epoch 20/2000\n",
      "164/164 [==============================] - 0s 906us/step - loss: 3006.6694 - val_loss: 5200.0410\n",
      "Epoch 21/2000\n",
      "164/164 [==============================] - 0s 918us/step - loss: 2919.0380 - val_loss: 4966.3667\n",
      "Epoch 22/2000\n",
      "164/164 [==============================] - 0s 937us/step - loss: 2898.9130 - val_loss: 5207.2261\n",
      "Epoch 23/2000\n",
      "164/164 [==============================] - 0s 955us/step - loss: 2895.7419 - val_loss: 5138.0435\n",
      "Epoch 24/2000\n",
      "164/164 [==============================] - 0s 937us/step - loss: 2907.7794 - val_loss: 4959.3330\n",
      "Epoch 25/2000\n",
      "164/164 [==============================] - 0s 924us/step - loss: 2915.9315 - val_loss: 4914.1631\n",
      "Epoch 26/2000\n",
      "164/164 [==============================] - 0s 930us/step - loss: 2928.0548 - val_loss: 5011.7319\n",
      "Epoch 27/2000\n",
      "164/164 [==============================] - 0s 918us/step - loss: 2879.7203 - val_loss: 5420.1777\n",
      "Epoch 28/2000\n",
      "164/164 [==============================] - 0s 934us/step - loss: 2926.7656 - val_loss: 5316.8433\n",
      "Epoch 29/2000\n",
      "164/164 [==============================] - 0s 942us/step - loss: 2901.6617 - val_loss: 5141.1875\n",
      "Epoch 30/2000\n",
      "164/164 [==============================] - 0s 930us/step - loss: 2952.9859 - val_loss: 4676.1011\n",
      "Epoch 31/2000\n",
      "164/164 [==============================] - 0s 930us/step - loss: 2926.3582 - val_loss: 4976.7695\n",
      "Epoch 32/2000\n",
      "164/164 [==============================] - 0s 930us/step - loss: 2958.5063 - val_loss: 5230.3999\n",
      "Epoch 33/2000\n",
      "164/164 [==============================] - 0s 930us/step - loss: 2903.8966 - val_loss: 4995.5586\n",
      "Epoch 34/2000\n",
      "164/164 [==============================] - 0s 918us/step - loss: 2921.2755 - val_loss: 4743.9858\n",
      "Epoch 35/2000\n",
      "164/164 [==============================] - 0s 919us/step - loss: 2950.2876 - val_loss: 4880.2285\n",
      "Epoch 36/2000\n",
      "164/164 [==============================] - 0s 930us/step - loss: 2911.0868 - val_loss: 5026.5303\n",
      "Epoch 37/2000\n",
      "164/164 [==============================] - 0s 943us/step - loss: 2917.2444 - val_loss: 4884.8960\n",
      "Epoch 38/2000\n",
      "164/164 [==============================] - 0s 917us/step - loss: 2888.6566 - val_loss: 5328.5146\n",
      "Epoch 39/2000\n",
      "164/164 [==============================] - 0s 919us/step - loss: 2919.9355 - val_loss: 5177.1587\n",
      "Epoch 40/2000\n",
      "164/164 [==============================] - 0s 918us/step - loss: 2900.2545 - val_loss: 4772.4453\n",
      "Epoch 41/2000\n",
      "164/164 [==============================] - 0s 918us/step - loss: 2948.8990 - val_loss: 4861.2310\n",
      "Epoch 42/2000\n",
      "164/164 [==============================] - 0s 950us/step - loss: 2887.5552 - val_loss: 5569.7642\n",
      "Epoch 43/2000\n",
      "164/164 [==============================] - 0s 930us/step - loss: 3064.9901 - val_loss: 6107.2261\n",
      "Epoch 44/2000\n",
      "164/164 [==============================] - 0s 949us/step - loss: 2989.4319 - val_loss: 5164.2573\n",
      "Epoch 45/2000\n",
      "164/164 [==============================] - 0s 924us/step - loss: 2898.5758 - val_loss: 4656.2979\n",
      "Epoch 46/2000\n",
      "164/164 [==============================] - 0s 930us/step - loss: 2953.0993 - val_loss: 4514.6782\n",
      "Epoch 47/2000\n",
      "164/164 [==============================] - 0s 922us/step - loss: 3035.5081 - val_loss: 4544.5176\n",
      "Epoch 48/2000\n",
      "164/164 [==============================] - 0s 930us/step - loss: 2962.9466 - val_loss: 4938.8994\n",
      "Epoch 49/2000\n",
      "164/164 [==============================] - 0s 928us/step - loss: 2927.9025 - val_loss: 5197.7783\n",
      "Epoch 50/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2918.7905 - val_loss: 5055.6138\n",
      "Epoch 51/2000\n",
      "164/164 [==============================] - 0s 930us/step - loss: 2893.7185 - val_loss: 5056.8945\n",
      "Epoch 52/2000\n",
      "164/164 [==============================] - 0s 943us/step - loss: 2930.0323 - val_loss: 5031.0098\n",
      "Epoch 53/2000\n",
      "164/164 [==============================] - 0s 924us/step - loss: 2936.9537 - val_loss: 4886.7861\n",
      "Epoch 54/2000\n",
      "164/164 [==============================] - 0s 937us/step - loss: 2905.7386 - val_loss: 5166.7466\n",
      "Epoch 55/2000\n",
      "164/164 [==============================] - 0s 949us/step - loss: 2925.4857 - val_loss: 5489.9771\n",
      "Epoch 56/2000\n",
      "164/164 [==============================] - 0s 967us/step - loss: 2917.3198 - val_loss: 5354.3208\n",
      "Epoch 57/2000\n",
      "164/164 [==============================] - 0s 928us/step - loss: 2909.2402 - val_loss: 4899.6152\n",
      "Epoch 58/2000\n",
      "164/164 [==============================] - 0s 937us/step - loss: 2955.5509 - val_loss: 4927.3662\n",
      "Epoch 59/2000\n",
      "164/164 [==============================] - 0s 928us/step - loss: 2930.6545 - val_loss: 5320.9336\n",
      "Epoch 60/2000\n",
      "164/164 [==============================] - 0s 928us/step - loss: 2949.7684 - val_loss: 5910.7573\n",
      "Epoch 61/2000\n",
      "164/164 [==============================] - 0s 937us/step - loss: 2976.4139 - val_loss: 5501.8218\n",
      "Epoch 62/2000\n",
      "164/164 [==============================] - 0s 930us/step - loss: 2902.6482 - val_loss: 5032.3579\n",
      "Epoch 63/2000\n",
      "164/164 [==============================] - 0s 930us/step - loss: 2930.0013 - val_loss: 4961.5771\n",
      "Epoch 64/2000\n",
      "164/164 [==============================] - 0s 949us/step - loss: 2922.9321 - val_loss: 5394.6387\n",
      "Epoch 65/2000\n",
      "164/164 [==============================] - 0s 930us/step - loss: 2893.5266 - val_loss: 4999.5312\n",
      "Epoch 66/2000\n",
      "164/164 [==============================] - 0s 937us/step - loss: 2977.3747 - val_loss: 4681.9946\n",
      "Epoch 67/2000\n",
      "164/164 [==============================] - 0s 946us/step - loss: 2916.4400 - val_loss: 5097.4868\n",
      "Epoch 68/2000\n",
      "164/164 [==============================] - 0s 934us/step - loss: 2926.4549 - val_loss: 5487.1074\n",
      "Epoch 69/2000\n",
      "164/164 [==============================] - 0s 930us/step - loss: 2945.4114 - val_loss: 5214.0928\n",
      "Epoch 70/2000\n",
      "164/164 [==============================] - 0s 934us/step - loss: 2900.5819 - val_loss: 5318.5547\n",
      "Epoch 71/2000\n",
      "164/164 [==============================] - 0s 934us/step - loss: 2928.5638 - val_loss: 5072.5698\n",
      "Epoch 72/2000\n",
      "164/164 [==============================] - 0s 924us/step - loss: 2891.2826 - val_loss: 4688.6802\n",
      "Epoch 73/2000\n",
      "164/164 [==============================] - 0s 930us/step - loss: 2947.2991 - val_loss: 4701.1533\n",
      "Epoch 74/2000\n",
      "164/164 [==============================] - 0s 924us/step - loss: 2946.9625 - val_loss: 5043.7920\n",
      "Epoch 75/2000\n",
      "164/164 [==============================] - 0s 924us/step - loss: 2935.5587 - val_loss: 5989.4053\n",
      "Epoch 76/2000\n",
      "164/164 [==============================] - 0s 930us/step - loss: 3003.1152 - val_loss: 5241.1211\n",
      "Epoch 77/2000\n",
      "164/164 [==============================] - 0s 930us/step - loss: 2915.3349 - val_loss: 4719.1709\n",
      "Epoch 78/2000\n",
      "164/164 [==============================] - 0s 937us/step - loss: 2926.5919 - val_loss: 5061.9160\n",
      "Epoch 79/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2926.8135 - val_loss: 4808.0723\n",
      "Epoch 80/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2906.2355 - val_loss: 5144.0625\n",
      "Epoch 81/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2912.1272 - val_loss: 5625.5493\n",
      "Epoch 82/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2951.7673 - val_loss: 5559.3291\n",
      "Epoch 83/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2926.9291 - val_loss: 4842.2285\n",
      "Epoch 84/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2927.0998 - val_loss: 4709.0630\n",
      "Epoch 85/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2917.3645 - val_loss: 5019.4048\n",
      "Epoch 86/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2985.9777 - val_loss: 5473.4941\n",
      "Epoch 87/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2900.8560 - val_loss: 4603.9712\n",
      "Epoch 88/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3045.7743 - val_loss: 4424.1494\n",
      "Epoch 89/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2963.3165 - val_loss: 5180.4648\n",
      "Epoch 90/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2885.4061 - val_loss: 5543.1333\n",
      "Epoch 91/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2921.2402 - val_loss: 4926.9492\n",
      "Epoch 92/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2931.5252 - val_loss: 4585.9653\n",
      "Epoch 93/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2964.6738 - val_loss: 5117.3618\n",
      "Epoch 94/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2959.7785 - val_loss: 5371.1455\n",
      "Epoch 95/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2890.0474 - val_loss: 4980.1040\n",
      "Epoch 96/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2930.1713 - val_loss: 4980.8350\n",
      "Epoch 97/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2906.3658 - val_loss: 5548.9312\n",
      "Epoch 98/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2965.0368 - val_loss: 5572.0718\n",
      "Epoch 99/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2893.2958 - val_loss: 4843.6753\n",
      "Epoch 100/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2934.2499 - val_loss: 4895.8511\n",
      "Epoch 101/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2922.1597 - val_loss: 5247.0117\n",
      "Epoch 102/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2946.4132 - val_loss: 5572.9531\n",
      "Epoch 103/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2875.8309 - val_loss: 4700.8774\n",
      "Epoch 104/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3030.6831 - val_loss: 4492.9243\n",
      "Epoch 105/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2963.7840 - val_loss: 5270.5586\n",
      "Epoch 106/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2909.3918 - val_loss: 6195.0566\n",
      "Epoch 107/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3103.6411 - val_loss: 5529.6450\n",
      "Epoch 108/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2969.5436 - val_loss: 4461.9727\n",
      "Epoch 109/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3052.5434 - val_loss: 4696.7568\n",
      "Epoch 110/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2932.5971 - val_loss: 5791.2983\n",
      "Epoch 111/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3030.5357 - val_loss: 5710.2881\n",
      "Epoch 112/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2916.8751 - val_loss: 4585.2349\n",
      "Epoch 113/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3042.8416 - val_loss: 4582.6895\n",
      "Epoch 114/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2975.9877 - val_loss: 5686.0259\n",
      "Epoch 115/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2949.4517 - val_loss: 5379.5273\n",
      "Epoch 116/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2939.9764 - val_loss: 5618.4731\n",
      "Epoch 117/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2909.1909 - val_loss: 5045.7583\n",
      "Epoch 118/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2919.6939 - val_loss: 4709.3765\n",
      "Epoch 119/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2907.1135 - val_loss: 5112.1899\n",
      "Epoch 120/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2962.1042 - val_loss: 5865.7217\n",
      "Epoch 121/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2962.4996 - val_loss: 4967.4746\n",
      "Epoch 122/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2989.6841 - val_loss: 4620.3140\n",
      "Epoch 123/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2983.4306 - val_loss: 5090.8159\n",
      "Epoch 124/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2914.6122 - val_loss: 5112.2344\n",
      "Epoch 125/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2889.3506 - val_loss: 5103.1133\n",
      "Epoch 126/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2879.9565 - val_loss: 5127.9814\n",
      "Epoch 127/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2935.5197 - val_loss: 4974.6655\n",
      "Epoch 128/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2944.3301 - val_loss: 4928.6436\n",
      "Epoch 129/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2924.9755 - val_loss: 5182.0425\n",
      "Epoch 130/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2925.3061 - val_loss: 5148.6577\n",
      "Epoch 131/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2901.3355 - val_loss: 4904.7515\n",
      "Epoch 132/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2905.8757 - val_loss: 5290.9824\n",
      "Epoch 133/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2896.5860 - val_loss: 5116.8965\n",
      "Epoch 134/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2901.6017 - val_loss: 5005.8228\n",
      "Epoch 135/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2902.9692 - val_loss: 5267.9712\n",
      "Epoch 136/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2893.7648 - val_loss: 5181.3140\n",
      "Epoch 137/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2920.9293 - val_loss: 5101.4956\n",
      "Epoch 138/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2936.1135 - val_loss: 4799.2969\n",
      "Epoch 139/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2960.2938 - val_loss: 4914.2383\n",
      "Epoch 140/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2932.6676 - val_loss: 5755.3086\n",
      "Epoch 141/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2946.6441 - val_loss: 5248.8560\n",
      "Epoch 142/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2949.7807 - val_loss: 4730.7744\n",
      "Epoch 143/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2952.9784 - val_loss: 4651.0044\n",
      "Epoch 144/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2984.0428 - val_loss: 4713.9546\n",
      "Epoch 145/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2930.2226 - val_loss: 5109.1123\n",
      "Epoch 146/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 [==============================] - 0s 1ms/step - loss: 2908.9731 - val_loss: 5350.2695\n",
      "Epoch 147/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2912.3579 - val_loss: 5243.8560\n",
      "Epoch 148/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2898.9668 - val_loss: 4891.7251\n",
      "Epoch 149/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2981.6211 - val_loss: 4544.6045\n",
      "Epoch 150/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2964.8403 - val_loss: 5085.8901\n",
      "Epoch 151/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2929.3135 - val_loss: 5483.7461\n",
      "Epoch 152/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2954.4304 - val_loss: 5091.9312\n",
      "Epoch 153/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2908.3066 - val_loss: 5252.3027\n",
      "Epoch 154/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2887.8989 - val_loss: 5254.6455\n",
      "Epoch 155/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2883.3815 - val_loss: 5353.3115\n",
      "Epoch 156/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2945.0841 - val_loss: 5640.8843\n",
      "Epoch 157/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2911.2759 - val_loss: 4973.8750\n",
      "Epoch 158/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2893.9732 - val_loss: 5130.4985\n",
      "Epoch 159/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2896.0840 - val_loss: 5443.0918\n",
      "Epoch 160/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2915.6739 - val_loss: 5352.7383\n",
      "Epoch 161/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2908.8519 - val_loss: 5322.9199\n",
      "Epoch 162/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2920.1566 - val_loss: 5386.8306\n",
      "Epoch 163/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2913.4385 - val_loss: 5238.8027\n",
      "Epoch 164/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2924.7331 - val_loss: 5126.2607\n",
      "Epoch 165/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2920.2696 - val_loss: 5462.6074\n",
      "Epoch 166/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2938.7887 - val_loss: 5320.5444\n",
      "Epoch 167/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2918.3086 - val_loss: 4960.9434\n",
      "Epoch 168/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2923.9901 - val_loss: 5207.9766\n",
      "Epoch 169/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2890.5701 - val_loss: 5261.2788\n",
      "Epoch 170/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2897.7288 - val_loss: 5298.6182\n",
      "Epoch 171/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2913.5875 - val_loss: 5125.6377\n",
      "Epoch 172/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2917.8580 - val_loss: 5261.9341\n",
      "Epoch 173/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2901.0811 - val_loss: 4889.0259\n",
      "Epoch 174/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2904.1917 - val_loss: 4687.9336\n",
      "Epoch 175/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2936.8570 - val_loss: 5261.2778\n",
      "Epoch 176/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2915.3524 - val_loss: 5613.9697\n",
      "Epoch 177/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2922.4902 - val_loss: 4953.5923\n",
      "Epoch 178/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2976.9875 - val_loss: 4731.7090\n",
      "Epoch 179/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2915.9516 - val_loss: 4801.8091\n",
      "Epoch 180/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2923.0999 - val_loss: 5142.2393\n",
      "Epoch 181/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2896.8572 - val_loss: 5385.8931\n",
      "Epoch 182/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2932.3825 - val_loss: 5371.1885\n",
      "Epoch 183/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2906.3434 - val_loss: 5707.7852\n",
      "Epoch 184/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3008.8854 - val_loss: 5756.8760\n",
      "Epoch 185/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2958.7464 - val_loss: 4998.5864\n",
      "Epoch 186/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2924.8470 - val_loss: 4918.3232\n",
      "Epoch 187/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2900.2487 - val_loss: 5147.2788\n",
      "Epoch 188/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2929.8539 - val_loss: 5368.9121\n",
      "Epoch 189/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2908.2071 - val_loss: 5290.9517\n",
      "Epoch 190/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2913.5428 - val_loss: 4784.2021\n",
      "Epoch 191/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2960.6944 - val_loss: 4537.5488\n",
      "Epoch 192/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3016.4200 - val_loss: 4595.6865\n",
      "Epoch 193/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2919.9900 - val_loss: 5155.8213\n",
      "Epoch 194/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2914.0779 - val_loss: 5326.6348\n",
      "Epoch 195/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2910.9295 - val_loss: 5374.3809\n",
      "Epoch 196/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2885.1257 - val_loss: 5272.3501\n",
      "Epoch 197/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2881.5979 - val_loss: 5046.2930\n",
      "Epoch 198/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2958.5375 - val_loss: 4702.4688\n",
      "Epoch 199/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2950.1342 - val_loss: 4890.9458\n",
      "Epoch 200/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2885.4319 - val_loss: 5231.3960\n",
      "Epoch 201/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2903.5081 - val_loss: 5224.8765\n",
      "Epoch 202/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2915.2616 - val_loss: 4878.2124\n",
      "Epoch 203/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2902.1728 - val_loss: 4951.5356\n",
      "Epoch 204/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2912.9346 - val_loss: 4871.8364\n",
      "Epoch 205/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2912.2822 - val_loss: 4986.5503\n",
      "Epoch 206/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2887.7047 - val_loss: 5920.7114\n",
      "Epoch 207/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3104.8097 - val_loss: 6134.3857\n",
      "Epoch 208/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2959.4367 - val_loss: 4719.9575\n",
      "Epoch 209/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3043.2137 - val_loss: 4427.3472\n",
      "Epoch 210/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3031.5924 - val_loss: 5043.2422\n",
      "Epoch 211/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2906.0177 - val_loss: 5565.8086\n",
      "Epoch 212/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2906.7914 - val_loss: 5033.1992\n",
      "Epoch 213/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2915.3565 - val_loss: 5066.3506\n",
      "Epoch 214/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2926.0926 - val_loss: 5260.0615\n",
      "Epoch 215/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2915.0490 - val_loss: 5024.2031\n",
      "Epoch 216/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2937.3803 - val_loss: 5104.6733\n",
      "Epoch 217/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2882.2346 - val_loss: 5159.3892\n",
      "Epoch 218/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2933.5292 - val_loss: 5111.6323\n",
      "Epoch 219/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2928.7069 - val_loss: 5160.5615\n",
      "Epoch 220/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2917.1513 - val_loss: 4782.2925\n",
      "Epoch 221/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2913.9423 - val_loss: 5190.7969\n",
      "Epoch 222/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2975.5164 - val_loss: 5892.4722\n",
      "Epoch 223/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2982.3433 - val_loss: 5092.7905\n",
      "Epoch 224/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2950.0071 - val_loss: 4276.7959\n",
      "Epoch 225/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3114.1814 - val_loss: 4865.7173\n",
      "Epoch 226/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2916.7045 - val_loss: 5334.3486\n",
      "Epoch 227/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2901.4419 - val_loss: 5095.9502\n",
      "Epoch 228/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2927.6641 - val_loss: 5535.3057\n",
      "Epoch 229/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2933.9511 - val_loss: 5106.3799\n",
      "Epoch 230/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2969.6686 - val_loss: 4547.3125\n",
      "Epoch 231/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3005.6993 - val_loss: 4728.0933\n",
      "Epoch 232/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2886.5865 - val_loss: 5269.7197\n",
      "Epoch 233/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2917.4785 - val_loss: 5149.9062\n",
      "Epoch 234/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2901.5886 - val_loss: 5122.4414\n",
      "Epoch 235/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2902.0417 - val_loss: 4890.6758\n",
      "Epoch 236/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2936.3976 - val_loss: 5108.4136\n",
      "Epoch 237/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2897.7672 - val_loss: 5168.6597\n",
      "Epoch 238/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2879.1811 - val_loss: 5009.1958\n",
      "Epoch 239/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2922.3784 - val_loss: 4543.9360\n",
      "Epoch 240/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3015.6503 - val_loss: 4723.1475\n",
      "Epoch 241/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2875.8198 - val_loss: 5569.9556\n",
      "Epoch 242/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2951.9730 - val_loss: 5453.3364\n",
      "Epoch 243/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2912.6085 - val_loss: 4946.9302\n",
      "Epoch 244/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2903.7067 - val_loss: 5088.8340\n",
      "Epoch 245/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2904.6504 - val_loss: 5049.8735\n",
      "Epoch 246/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2893.1080 - val_loss: 4972.0664\n",
      "Epoch 247/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2954.5819 - val_loss: 4663.3828\n",
      "Epoch 248/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2953.8616 - val_loss: 5094.5273\n",
      "Epoch 249/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2894.3719 - val_loss: 5397.2319\n",
      "Epoch 250/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2887.1402 - val_loss: 5083.3042\n",
      "Epoch 251/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2960.5845 - val_loss: 4627.6919\n",
      "Epoch 252/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2965.7988 - val_loss: 4795.4028\n",
      "Epoch 253/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2910.5229 - val_loss: 5653.5229\n",
      "Epoch 254/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2952.8266 - val_loss: 5500.4780\n",
      "Epoch 255/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2911.1199 - val_loss: 4920.2183\n",
      "Epoch 256/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2923.4402 - val_loss: 4848.7915\n",
      "Epoch 257/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2930.3917 - val_loss: 5518.5610\n",
      "Epoch 258/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3023.7070 - val_loss: 5920.1348\n",
      "Epoch 259/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2979.6279 - val_loss: 5440.1372\n",
      "Epoch 260/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2934.1387 - val_loss: 4608.0815\n",
      "Epoch 261/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2989.8064 - val_loss: 4661.9043\n",
      "Epoch 262/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2920.6750 - val_loss: 5194.1274\n",
      "Epoch 263/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2912.8878 - val_loss: 5432.9341\n",
      "Epoch 264/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2955.5281 - val_loss: 5885.2598\n",
      "Epoch 265/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2991.8487 - val_loss: 5303.6934\n",
      "Epoch 266/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2951.8312 - val_loss: 4526.1572\n",
      "Epoch 267/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2939.7217 - val_loss: 5280.9248\n",
      "Epoch 268/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2965.4848 - val_loss: 5591.9482\n",
      "Epoch 269/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2922.4133 - val_loss: 4814.9468\n",
      "Epoch 270/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2910.8503 - val_loss: 4804.9756\n",
      "Epoch 271/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2905.0377 - val_loss: 5115.6455\n",
      "Epoch 272/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2899.1365 - val_loss: 5465.0010\n",
      "Epoch 273/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2948.0666 - val_loss: 5543.4009\n",
      "Epoch 274/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2935.7440 - val_loss: 5004.1621\n",
      "Epoch 275/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2896.6572 - val_loss: 5290.9282\n",
      "Epoch 276/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2923.4572 - val_loss: 5560.2954\n",
      "Epoch 277/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3035.1747 - val_loss: 6071.3330\n",
      "Epoch 278/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2906.2588 - val_loss: 4579.6255\n",
      "Epoch 279/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3189.0633 - val_loss: 4180.1719\n",
      "Epoch 280/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3237.3268 - val_loss: 4473.0522\n",
      "Epoch 281/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3000.4822 - val_loss: 5347.7446\n",
      "Epoch 282/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2877.9136 - val_loss: 4887.1060\n",
      "Epoch 283/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2915.4262 - val_loss: 4746.8398\n",
      "Epoch 284/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2914.1341 - val_loss: 5068.1660\n",
      "Epoch 285/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2913.8933 - val_loss: 5124.3345\n",
      "Epoch 286/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2906.4999 - val_loss: 5062.8965\n",
      "Epoch 287/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2904.7619 - val_loss: 4993.2021\n",
      "Epoch 288/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2937.3462 - val_loss: 4788.4023\n",
      "Epoch 289/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2919.8715 - val_loss: 5088.0264\n",
      "Epoch 290/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3015.1903 - val_loss: 5789.6919\n",
      "Epoch 291/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2950.4338 - val_loss: 5043.1729\n",
      "Epoch 292/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2900.5629 - val_loss: 4872.4985\n",
      "Epoch 293/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2946.9452 - val_loss: 4871.0688\n",
      "Epoch 294/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 [==============================] - 0s 1ms/step - loss: 2920.2693 - val_loss: 5243.4399\n",
      "Epoch 295/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2925.4593 - val_loss: 5458.4644\n",
      "Epoch 296/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2918.2285 - val_loss: 5249.8921\n",
      "Epoch 297/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2940.9349 - val_loss: 5255.4355\n",
      "Epoch 298/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2923.9330 - val_loss: 5264.7070\n",
      "Epoch 299/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2927.2973 - val_loss: 5118.4243\n",
      "Epoch 300/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2935.9227 - val_loss: 5730.2056\n",
      "Epoch 301/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2920.8247 - val_loss: 4922.8896\n",
      "Epoch 302/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2931.0192 - val_loss: 4759.0249\n",
      "Epoch 303/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2953.8392 - val_loss: 4810.8984\n",
      "Epoch 304/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2935.1876 - val_loss: 5457.1606\n",
      "Epoch 305/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2935.0620 - val_loss: 5143.4775\n",
      "Epoch 306/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2997.9454 - val_loss: 4421.3394\n",
      "Epoch 307/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3019.6084 - val_loss: 4906.0522\n",
      "Epoch 308/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2896.1616 - val_loss: 5329.8867\n",
      "Epoch 309/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2912.5332 - val_loss: 5375.0288\n",
      "Epoch 310/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2927.5155 - val_loss: 4743.0488\n",
      "Epoch 311/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2938.5570 - val_loss: 4876.0142\n",
      "Epoch 312/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2932.8195 - val_loss: 5208.9316\n",
      "Epoch 313/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2952.7020 - val_loss: 5004.8296\n",
      "Epoch 314/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2900.5827 - val_loss: 5197.7749\n",
      "Epoch 315/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2898.0923 - val_loss: 5199.1890\n",
      "Epoch 316/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2921.8179 - val_loss: 5064.4790\n",
      "Epoch 317/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2975.3000 - val_loss: 5490.5186\n",
      "Epoch 318/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2901.3639 - val_loss: 4646.8188\n",
      "Epoch 319/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2993.7658 - val_loss: 4640.7852\n",
      "Epoch 320/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2925.7882 - val_loss: 5529.0947\n",
      "Epoch 321/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2901.6337 - val_loss: 5101.9634\n",
      "Epoch 322/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2976.6932 - val_loss: 4720.3940\n",
      "Epoch 323/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2931.5111 - val_loss: 5005.2778\n",
      "Epoch 324/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2912.4939 - val_loss: 5404.7510\n",
      "Epoch 325/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2913.9505 - val_loss: 5230.3477\n",
      "Epoch 326/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2982.7222 - val_loss: 4572.8765\n",
      "Epoch 327/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2993.0412 - val_loss: 4664.6719\n",
      "Epoch 328/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2917.7842 - val_loss: 5384.8423\n",
      "Epoch 329/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2912.8763 - val_loss: 5394.4092\n",
      "Epoch 330/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2891.7081 - val_loss: 4919.2363\n",
      "Epoch 331/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2904.9537 - val_loss: 4778.9214\n",
      "Epoch 332/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2935.8887 - val_loss: 5062.3809\n",
      "Epoch 333/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2930.9531 - val_loss: 6025.2344\n",
      "Epoch 334/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3018.3827 - val_loss: 5552.5239\n",
      "Epoch 335/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2925.5464 - val_loss: 4886.5420\n",
      "Epoch 336/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2926.2745 - val_loss: 4772.7510\n",
      "Epoch 337/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2914.8248 - val_loss: 5183.9360\n",
      "Epoch 338/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2914.9608 - val_loss: 5090.3574\n",
      "Epoch 339/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2892.1196 - val_loss: 4938.4370\n",
      "Epoch 340/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2931.7131 - val_loss: 4883.0464\n",
      "Epoch 341/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2923.3733 - val_loss: 5029.0166\n",
      "Epoch 342/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2916.6963 - val_loss: 5013.4121\n",
      "Epoch 343/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2900.8129 - val_loss: 5268.6533\n",
      "Epoch 344/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2914.5295 - val_loss: 5595.2070\n",
      "Epoch 345/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2942.9847 - val_loss: 5368.7485\n",
      "Epoch 346/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2902.4196 - val_loss: 4921.5034\n",
      "Epoch 347/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2939.3561 - val_loss: 4741.8032\n",
      "Epoch 348/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2906.6289 - val_loss: 5208.5298\n",
      "Epoch 349/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2906.3480 - val_loss: 5592.3691\n",
      "Epoch 350/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2911.8277 - val_loss: 4776.0923\n",
      "Epoch 351/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2963.1837 - val_loss: 4696.8188\n",
      "Epoch 352/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2940.3137 - val_loss: 4891.0215\n",
      "Epoch 353/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2902.8464 - val_loss: 4875.7568\n",
      "Epoch 354/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2922.7324 - val_loss: 5063.5610\n",
      "Epoch 355/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2906.6403 - val_loss: 5413.4434\n",
      "Epoch 356/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2908.7297 - val_loss: 5151.0703\n",
      "Epoch 357/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2942.7339 - val_loss: 4898.1973\n",
      "Epoch 358/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2923.0929 - val_loss: 4929.7031\n",
      "Epoch 359/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2892.2235 - val_loss: 4862.6152\n",
      "Epoch 360/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2927.8164 - val_loss: 5199.4248\n",
      "Epoch 361/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2899.1895 - val_loss: 5196.8389\n",
      "Epoch 362/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2914.3277 - val_loss: 5135.7832\n",
      "Epoch 363/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2877.4890 - val_loss: 5173.7534\n",
      "Epoch 364/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2911.9988 - val_loss: 4802.7939\n",
      "Epoch 365/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2935.2388 - val_loss: 4797.3770\n",
      "Epoch 366/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2949.2647 - val_loss: 5133.5249\n",
      "Epoch 367/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2913.6129 - val_loss: 5214.7646\n",
      "Epoch 368/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2928.9088 - val_loss: 5547.3682\n",
      "Epoch 369/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2914.5828 - val_loss: 5109.6709\n",
      "Epoch 370/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2932.9045 - val_loss: 4755.0410\n",
      "Epoch 371/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2943.3650 - val_loss: 4964.7285\n",
      "Epoch 372/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2890.7895 - val_loss: 5508.0181\n",
      "Epoch 373/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2996.6319 - val_loss: 5691.5249\n",
      "Epoch 374/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2921.0411 - val_loss: 4643.6602\n",
      "Epoch 375/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2993.3824 - val_loss: 4800.6182\n",
      "Epoch 376/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3032.6150 - val_loss: 6066.1416\n",
      "Epoch 377/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2985.8332 - val_loss: 4913.9932\n",
      "Epoch 378/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2929.6313 - val_loss: 4630.4077\n",
      "Epoch 379/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2965.3028 - val_loss: 5100.6001\n",
      "Epoch 380/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2971.2287 - val_loss: 5432.9185\n",
      "Epoch 381/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2913.0256 - val_loss: 4937.3364\n",
      "Epoch 382/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2894.2128 - val_loss: 5088.0659\n",
      "Epoch 383/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2900.6142 - val_loss: 5137.2651\n",
      "Epoch 384/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2914.2975 - val_loss: 5081.6567\n",
      "Epoch 385/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2889.9041 - val_loss: 4988.9775\n",
      "Epoch 386/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2906.8895 - val_loss: 5236.9751\n",
      "Epoch 387/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2931.8588 - val_loss: 5316.4150\n",
      "Epoch 388/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2887.4401 - val_loss: 4983.7402\n",
      "Epoch 389/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2933.1981 - val_loss: 4611.5117\n",
      "Epoch 390/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2974.8319 - val_loss: 4818.7437\n",
      "Epoch 391/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2984.4540 - val_loss: 5492.7695\n",
      "Epoch 392/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2912.4702 - val_loss: 5066.3462\n",
      "Epoch 393/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2928.4701 - val_loss: 5219.6504\n",
      "Epoch 394/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2918.9229 - val_loss: 5157.6538\n",
      "Epoch 395/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2902.9919 - val_loss: 4844.3931\n",
      "Epoch 396/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2942.1817 - val_loss: 4776.2749\n",
      "Epoch 397/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2906.7075 - val_loss: 5079.0620\n",
      "Epoch 398/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2904.1554 - val_loss: 5591.4766\n",
      "Epoch 399/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2930.0715 - val_loss: 5632.9897\n",
      "Epoch 400/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2910.8355 - val_loss: 4955.1660\n",
      "Epoch 401/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2958.4599 - val_loss: 4481.8926\n",
      "Epoch 402/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3025.1666 - val_loss: 4760.5352\n",
      "Epoch 403/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2921.4431 - val_loss: 4891.9780\n",
      "Epoch 404/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2890.8827 - val_loss: 5447.6816\n",
      "Epoch 405/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2931.1125 - val_loss: 5183.2017\n",
      "Epoch 406/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2914.2623 - val_loss: 4355.3418\n",
      "Epoch 407/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3114.7256 - val_loss: 4553.9194\n",
      "Epoch 408/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2871.9717 - val_loss: 5345.8892\n",
      "Epoch 409/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2906.4536 - val_loss: 5124.6743\n",
      "Epoch 410/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2928.6782 - val_loss: 4667.0801\n",
      "Epoch 411/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2938.0480 - val_loss: 5027.4360\n",
      "Epoch 412/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2911.1983 - val_loss: 5127.4209\n",
      "Epoch 413/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2861.7933 - val_loss: 5467.8101\n",
      "Epoch 414/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2915.8165 - val_loss: 5128.6313\n",
      "Epoch 415/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2922.7030 - val_loss: 4835.3472\n",
      "Epoch 416/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2941.4643 - val_loss: 5302.4751\n",
      "Epoch 417/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2961.7552 - val_loss: 5445.2827\n",
      "Epoch 418/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2928.8175 - val_loss: 4723.0513\n",
      "Epoch 419/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2911.2814 - val_loss: 5064.0444\n",
      "Epoch 420/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2935.7313 - val_loss: 5570.4277\n",
      "Epoch 421/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2899.1203 - val_loss: 5031.5063\n",
      "Epoch 422/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2965.6479 - val_loss: 4676.4761\n",
      "Epoch 423/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2905.1576 - val_loss: 5121.8296\n",
      "Epoch 424/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2910.4233 - val_loss: 5131.5664\n",
      "Epoch 425/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2937.4090 - val_loss: 5031.0728\n",
      "Epoch 426/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2909.8961 - val_loss: 4685.8594\n",
      "Epoch 427/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2956.4467 - val_loss: 4862.9106\n",
      "Epoch 428/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2892.8117 - val_loss: 5480.4277\n",
      "Epoch 429/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2936.0236 - val_loss: 5220.6187\n",
      "Epoch 430/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2996.1089 - val_loss: 4781.8315\n",
      "Epoch 431/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2924.8318 - val_loss: 5158.0889\n",
      "Epoch 432/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2887.5662 - val_loss: 5462.3711\n",
      "Epoch 433/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2933.3754 - val_loss: 5289.3110\n",
      "Epoch 434/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2917.4631 - val_loss: 5371.3330\n",
      "Epoch 435/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2899.6360 - val_loss: 5109.7852\n",
      "Epoch 436/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2917.8240 - val_loss: 4894.3501\n",
      "Epoch 437/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2916.8308 - val_loss: 5380.3052\n",
      "Epoch 438/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2929.6133 - val_loss: 4828.3740\n",
      "Epoch 439/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2934.7516 - val_loss: 4891.6001\n",
      "Epoch 440/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2917.6086 - val_loss: 5428.7202\n",
      "Epoch 441/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2926.9231 - val_loss: 5501.0288\n",
      "Epoch 442/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 [==============================] - 0s 1ms/step - loss: 2950.9666 - val_loss: 5367.1470\n",
      "Epoch 443/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2905.9137 - val_loss: 5139.4810\n",
      "Epoch 444/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2871.0481 - val_loss: 5162.7920\n",
      "Epoch 445/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2929.2375 - val_loss: 5034.2891\n",
      "Epoch 446/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2921.1274 - val_loss: 5137.9663\n",
      "Epoch 447/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2940.7641 - val_loss: 5406.6572\n",
      "Epoch 448/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2875.9071 - val_loss: 5044.1836\n",
      "Epoch 449/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2906.5430 - val_loss: 5094.4888\n",
      "Epoch 450/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2894.7773 - val_loss: 5150.6479\n",
      "Epoch 451/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2947.3404 - val_loss: 5473.1455\n",
      "Epoch 452/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2883.6817 - val_loss: 5180.2632\n",
      "Epoch 453/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2942.3708 - val_loss: 5077.5347\n",
      "Epoch 454/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2926.7734 - val_loss: 5388.2173\n",
      "Epoch 455/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2906.8061 - val_loss: 5288.8291\n",
      "Epoch 456/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2890.7392 - val_loss: 5012.4888\n",
      "Epoch 457/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2886.7917 - val_loss: 5132.8135\n",
      "Epoch 458/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2911.4534 - val_loss: 5135.7866\n",
      "Epoch 459/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2910.4932 - val_loss: 4900.1436\n",
      "Epoch 460/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2896.0016 - val_loss: 5074.8535\n",
      "Epoch 461/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2899.5996 - val_loss: 4863.8003\n",
      "Epoch 462/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2901.7644 - val_loss: 5021.0166\n",
      "Epoch 463/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2890.4955 - val_loss: 5396.7471\n",
      "Epoch 464/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2922.5735 - val_loss: 5064.6064\n",
      "Epoch 465/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2912.5555 - val_loss: 4840.8774\n",
      "Epoch 466/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2952.7396 - val_loss: 4702.2568\n",
      "Epoch 467/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2901.2653 - val_loss: 5349.1001\n",
      "Epoch 468/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2986.3023 - val_loss: 5433.3750\n",
      "Epoch 469/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3030.4637 - val_loss: 4401.5864\n",
      "Epoch 470/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3030.5538 - val_loss: 4825.2271\n",
      "Epoch 471/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2934.1803 - val_loss: 4833.3403\n",
      "Epoch 472/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2941.4202 - val_loss: 4927.4761\n",
      "Epoch 473/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2919.1036 - val_loss: 4873.6523\n",
      "Epoch 474/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2975.7972 - val_loss: 4592.4590\n",
      "Epoch 475/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2934.5211 - val_loss: 5011.5771\n",
      "Epoch 476/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2921.6288 - val_loss: 5315.7173\n",
      "Epoch 477/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2884.5401 - val_loss: 5043.1675\n",
      "Epoch 478/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2937.8165 - val_loss: 5156.3101\n",
      "Epoch 479/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2897.8052 - val_loss: 5083.1294\n",
      "Epoch 480/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2910.2474 - val_loss: 4909.1812\n",
      "Epoch 481/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2954.0811 - val_loss: 4777.5186\n",
      "Epoch 482/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2903.0974 - val_loss: 5249.5220\n",
      "Epoch 483/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2945.4535 - val_loss: 5715.3726\n",
      "Epoch 484/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2996.1133 - val_loss: 4916.0415\n",
      "Epoch 485/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2906.1285 - val_loss: 5450.2222\n",
      "Epoch 486/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3093.2455 - val_loss: 5911.8789\n",
      "Epoch 487/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2926.6626 - val_loss: 4477.7017\n",
      "Epoch 488/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3085.2987 - val_loss: 4405.6650\n",
      "Epoch 489/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2978.7652 - val_loss: 5526.5601\n",
      "Epoch 490/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3041.4076 - val_loss: 6132.2695\n",
      "Epoch 491/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2904.5742 - val_loss: 4572.3594\n",
      "Epoch 492/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3024.8560 - val_loss: 4564.0513\n",
      "Epoch 493/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2925.3816 - val_loss: 5431.5479\n",
      "Epoch 494/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2951.6203 - val_loss: 5326.6499\n",
      "Epoch 495/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2920.7203 - val_loss: 4904.4023\n",
      "Epoch 496/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2863.4315 - val_loss: 5558.5273\n",
      "Epoch 497/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3118.7262 - val_loss: 6186.5542\n",
      "Epoch 498/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2916.9115 - val_loss: 4921.4058\n",
      "Epoch 499/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3100.9443 - val_loss: 4317.0986\n",
      "Epoch 500/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3050.6480 - val_loss: 5045.9170\n",
      "Epoch 501/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2981.3686 - val_loss: 6223.4927\n",
      "Epoch 502/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3007.6976 - val_loss: 5170.6904\n",
      "Epoch 503/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2907.9975 - val_loss: 4876.3711\n",
      "Epoch 504/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2926.6418 - val_loss: 4777.4321\n",
      "Epoch 505/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2931.4044 - val_loss: 4786.8530\n",
      "Epoch 506/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2916.5844 - val_loss: 5279.6074\n",
      "Epoch 507/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2921.4224 - val_loss: 5456.8257\n",
      "Epoch 508/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2921.7579 - val_loss: 5189.1245\n",
      "Epoch 509/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2897.6672 - val_loss: 5080.7314\n",
      "Epoch 510/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2917.1022 - val_loss: 4816.2598\n",
      "Epoch 511/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2903.3649 - val_loss: 5307.1079\n",
      "Epoch 512/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2904.7689 - val_loss: 5795.4414\n",
      "Epoch 513/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2969.2882 - val_loss: 5326.3555\n",
      "Epoch 514/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2978.4101 - val_loss: 5718.3696\n",
      "Epoch 515/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2976.9694 - val_loss: 4894.6177\n",
      "Epoch 516/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2917.3183 - val_loss: 4655.5273\n",
      "Epoch 517/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2947.1363 - val_loss: 4946.0430\n",
      "Epoch 518/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2915.7077 - val_loss: 5615.8936\n",
      "Epoch 519/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2902.5896 - val_loss: 5004.4521\n",
      "Epoch 520/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2926.8044 - val_loss: 4925.7852\n",
      "Epoch 521/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2907.9748 - val_loss: 4781.3721\n",
      "Epoch 522/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2968.1051 - val_loss: 4827.9868\n",
      "Epoch 523/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2920.7111 - val_loss: 4993.1318\n",
      "Epoch 524/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2881.3152 - val_loss: 5332.6152\n",
      "Epoch 525/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2894.3259 - val_loss: 5032.5874\n",
      "Epoch 526/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2943.8713 - val_loss: 4713.0723\n",
      "Epoch 527/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2933.6476 - val_loss: 5381.2891\n",
      "Epoch 528/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2913.9517 - val_loss: 5019.4580\n",
      "Epoch 529/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2920.3129 - val_loss: 5140.0601\n",
      "Epoch 530/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2895.2158 - val_loss: 5102.9629\n",
      "Epoch 531/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2878.0084 - val_loss: 5439.7402\n",
      "Epoch 532/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2946.0067 - val_loss: 5598.1958\n",
      "Epoch 533/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2948.6252 - val_loss: 4809.7036\n",
      "Epoch 534/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2988.4525 - val_loss: 4655.0742\n",
      "Epoch 535/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2920.3349 - val_loss: 5497.2480\n",
      "Epoch 536/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2989.5912 - val_loss: 5772.4570\n",
      "Epoch 537/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2925.9388 - val_loss: 4969.5073\n",
      "Epoch 538/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2968.0229 - val_loss: 4608.5098\n",
      "Epoch 539/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2928.4821 - val_loss: 5053.6807\n",
      "Epoch 540/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2915.4366 - val_loss: 5750.7476\n",
      "Epoch 541/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2966.1546 - val_loss: 5068.7437\n",
      "Epoch 542/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2958.0205 - val_loss: 5220.6313\n",
      "Epoch 543/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2913.9928 - val_loss: 5370.4229\n",
      "Epoch 544/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2882.6022 - val_loss: 5026.7192\n",
      "Epoch 545/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2889.8457 - val_loss: 4805.7251\n",
      "Epoch 546/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2921.5005 - val_loss: 4921.8447\n",
      "Epoch 547/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2903.1084 - val_loss: 4979.1191\n",
      "Epoch 548/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2876.8523 - val_loss: 5414.3809\n",
      "Epoch 549/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2944.1607 - val_loss: 5825.0986\n",
      "Epoch 550/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2970.3352 - val_loss: 5258.4907\n",
      "Epoch 551/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2923.3111 - val_loss: 4802.5122\n",
      "Epoch 552/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2938.5283 - val_loss: 4848.3120\n",
      "Epoch 553/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2909.1085 - val_loss: 5158.8799\n",
      "Epoch 554/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2895.1045 - val_loss: 5139.0088\n",
      "Epoch 555/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2910.0068 - val_loss: 5206.8262\n",
      "Epoch 556/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2878.8932 - val_loss: 5357.0527\n",
      "Epoch 557/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2925.2649 - val_loss: 5156.0732\n",
      "Epoch 558/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2935.5553 - val_loss: 4612.5762\n",
      "Epoch 559/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2959.1264 - val_loss: 5048.7959\n",
      "Epoch 560/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2928.7456 - val_loss: 4898.1680\n",
      "Epoch 561/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2893.1243 - val_loss: 5086.6167\n",
      "Epoch 562/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2893.6187 - val_loss: 4747.5454\n",
      "Epoch 563/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2925.1476 - val_loss: 5118.1597\n",
      "Epoch 564/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2922.7807 - val_loss: 5010.6953\n",
      "Epoch 565/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2910.3082 - val_loss: 5217.0605\n",
      "Epoch 566/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2880.7489 - val_loss: 5727.5703\n",
      "Epoch 567/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2975.9103 - val_loss: 5417.6187\n",
      "Epoch 568/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2908.4953 - val_loss: 5015.2407\n",
      "Epoch 569/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2900.7132 - val_loss: 5077.9614\n",
      "Epoch 570/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2898.5876 - val_loss: 4891.1694\n",
      "Epoch 571/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2970.2125 - val_loss: 4522.1470\n",
      "Epoch 572/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2954.3584 - val_loss: 5093.7227\n",
      "Epoch 573/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2930.2690 - val_loss: 5222.1968\n",
      "Epoch 574/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2903.1070 - val_loss: 4596.3867\n",
      "Epoch 575/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2950.7830 - val_loss: 4896.3970\n",
      "Epoch 576/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2927.4839 - val_loss: 5401.5435\n",
      "Epoch 577/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2971.0161 - val_loss: 5826.2124\n",
      "Epoch 578/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2963.2318 - val_loss: 5200.4678\n",
      "Epoch 579/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2912.2724 - val_loss: 5269.5396\n",
      "Epoch 580/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2973.3063 - val_loss: 5579.0762\n",
      "Epoch 581/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2906.4029 - val_loss: 4660.4482\n",
      "Epoch 582/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2955.7470 - val_loss: 4599.0278\n",
      "Epoch 583/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2960.4863 - val_loss: 5267.3159\n",
      "Epoch 584/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2920.5677 - val_loss: 5570.2104\n",
      "Epoch 585/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2951.2813 - val_loss: 5114.1772\n",
      "Epoch 586/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2938.6771 - val_loss: 4630.6548\n",
      "Epoch 587/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2920.9840 - val_loss: 5454.1665\n",
      "Epoch 588/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2985.5153 - val_loss: 6243.2778\n",
      "Epoch 589/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3011.1078 - val_loss: 4914.7832\n",
      "Epoch 590/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 [==============================] - 0s 1ms/step - loss: 2915.9704 - val_loss: 4653.0664\n",
      "Epoch 591/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2962.5214 - val_loss: 4950.3765\n",
      "Epoch 592/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2915.2852 - val_loss: 5229.0723\n",
      "Epoch 593/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2891.0291 - val_loss: 4817.7461\n",
      "Epoch 594/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3031.0136 - val_loss: 4480.5645\n",
      "Epoch 595/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2983.6126 - val_loss: 5226.9336\n",
      "Epoch 596/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2886.9540 - val_loss: 5317.9497\n",
      "Epoch 597/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2913.4535 - val_loss: 5521.3589\n",
      "Epoch 598/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2965.1752 - val_loss: 5523.3765\n",
      "Epoch 599/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2967.7656 - val_loss: 4855.4482\n",
      "Epoch 600/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2941.5938 - val_loss: 4866.7861\n",
      "Epoch 601/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2901.9167 - val_loss: 5130.5889\n",
      "Epoch 602/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2919.1044 - val_loss: 5332.9453\n",
      "Epoch 603/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2904.1210 - val_loss: 5258.3809\n",
      "Epoch 604/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2945.2245 - val_loss: 5165.0171\n",
      "Epoch 605/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2943.2666 - val_loss: 4551.7808\n",
      "Epoch 606/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2965.5899 - val_loss: 4955.3379\n",
      "Epoch 607/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2913.5230 - val_loss: 5364.4883\n",
      "Epoch 608/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2899.2511 - val_loss: 5077.7109\n",
      "Epoch 609/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2938.2804 - val_loss: 4938.1367\n",
      "Epoch 610/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2899.2438 - val_loss: 5093.5659\n",
      "Epoch 611/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2916.8909 - val_loss: 5168.4927\n",
      "Epoch 612/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2877.4878 - val_loss: 4834.7964\n",
      "Epoch 613/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2954.5959 - val_loss: 4930.6919\n",
      "Epoch 614/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2910.1164 - val_loss: 5755.5576\n",
      "Epoch 615/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2980.4321 - val_loss: 5332.7539\n",
      "Epoch 616/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2906.3806 - val_loss: 4633.6445\n",
      "Epoch 617/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2944.4429 - val_loss: 4870.7876\n",
      "Epoch 618/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2919.5401 - val_loss: 5195.0864\n",
      "Epoch 619/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2917.1668 - val_loss: 5074.2690\n",
      "Epoch 620/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2940.4185 - val_loss: 4776.7705\n",
      "Epoch 621/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2929.2740 - val_loss: 4849.6831\n",
      "Epoch 622/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2937.6363 - val_loss: 5216.5830\n",
      "Epoch 623/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2895.1163 - val_loss: 5045.9751\n",
      "Epoch 624/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2898.8774 - val_loss: 4814.6680\n",
      "Epoch 625/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2936.6979 - val_loss: 4847.3960\n",
      "Epoch 626/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2915.0223 - val_loss: 5216.3960\n",
      "Epoch 627/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2916.7650 - val_loss: 5248.0640\n",
      "Epoch 628/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2903.7965 - val_loss: 5018.4917\n",
      "Epoch 629/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2928.9283 - val_loss: 4881.5352\n",
      "Epoch 630/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2927.0386 - val_loss: 5162.2280\n",
      "Epoch 631/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2933.1522 - val_loss: 4748.3247\n",
      "Epoch 632/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2951.0384 - val_loss: 4909.8481\n",
      "Epoch 633/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2907.9363 - val_loss: 5141.2886\n",
      "Epoch 634/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2912.3543 - val_loss: 4715.5059\n",
      "Epoch 635/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2923.4362 - val_loss: 5050.0200\n",
      "Epoch 636/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2876.8534 - val_loss: 5653.0142\n",
      "Epoch 637/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2992.6923 - val_loss: 5703.9521\n",
      "Epoch 638/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2925.7773 - val_loss: 4714.7334\n",
      "Epoch 639/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3019.8516 - val_loss: 4534.5928\n",
      "Epoch 640/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2957.4249 - val_loss: 5133.1587\n",
      "Epoch 641/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2876.3088 - val_loss: 5089.7271\n",
      "Epoch 642/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2902.5336 - val_loss: 5653.5083\n",
      "Epoch 643/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3043.5887 - val_loss: 5823.3545\n",
      "Epoch 644/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2942.5957 - val_loss: 4679.8701\n",
      "Epoch 645/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2956.9406 - val_loss: 5091.0112\n",
      "Epoch 646/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2919.6396 - val_loss: 5309.0264\n",
      "Epoch 647/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2997.5543 - val_loss: 6566.6680\n",
      "Epoch 648/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3135.9557 - val_loss: 5481.6069\n",
      "Epoch 649/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2997.9100 - val_loss: 4747.8398\n",
      "Epoch 650/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2942.0005 - val_loss: 5351.2915\n",
      "Epoch 651/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2947.9690 - val_loss: 5812.4297\n",
      "Epoch 652/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2983.6908 - val_loss: 5441.0571\n",
      "Epoch 653/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2892.3093 - val_loss: 4788.4380\n",
      "Epoch 654/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2958.9517 - val_loss: 4656.2251\n",
      "Epoch 655/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2919.7012 - val_loss: 5046.9399\n",
      "Epoch 656/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2920.2870 - val_loss: 5482.1035\n",
      "Epoch 657/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2881.3725 - val_loss: 4540.6719\n",
      "Epoch 658/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2988.9605 - val_loss: 4991.2842\n",
      "Epoch 659/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2926.9940 - val_loss: 5697.8530\n",
      "Epoch 660/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2970.2250 - val_loss: 5273.6812\n",
      "Epoch 661/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2902.9385 - val_loss: 4922.2500\n",
      "Epoch 662/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2927.4818 - val_loss: 4856.7920\n",
      "Epoch 663/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2918.7109 - val_loss: 5321.4834\n",
      "Epoch 664/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2965.3293 - val_loss: 5485.7847\n",
      "Epoch 665/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2980.1192 - val_loss: 4654.6255\n",
      "Epoch 666/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2941.6772 - val_loss: 4900.9688\n",
      "Epoch 667/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2901.3709 - val_loss: 5332.1924\n",
      "Epoch 668/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3004.7104 - val_loss: 5713.3145\n",
      "Epoch 669/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2879.0397 - val_loss: 4795.4277\n",
      "Epoch 670/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3040.4877 - val_loss: 4583.1470\n",
      "Epoch 671/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2934.4398 - val_loss: 5379.1611\n",
      "Epoch 672/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2977.5839 - val_loss: 5747.7944\n",
      "Epoch 673/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2940.7873 - val_loss: 4894.4507\n",
      "Epoch 674/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2906.2755 - val_loss: 4713.1807\n",
      "Epoch 675/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2936.1455 - val_loss: 4861.9570\n",
      "Epoch 676/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2899.9944 - val_loss: 5179.9282\n",
      "Epoch 677/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2918.5204 - val_loss: 5272.3198\n",
      "Epoch 678/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2885.4309 - val_loss: 4876.2129\n",
      "Epoch 679/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2901.9660 - val_loss: 4853.9673\n",
      "Epoch 680/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2937.6120 - val_loss: 4838.4751\n",
      "Epoch 681/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2927.7377 - val_loss: 5063.6108\n",
      "Epoch 682/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2921.2284 - val_loss: 5112.2935\n",
      "Epoch 683/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2914.5971 - val_loss: 5011.5264\n",
      "Epoch 684/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2912.7653 - val_loss: 5312.5073\n",
      "Epoch 685/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2923.7857 - val_loss: 5056.0718\n",
      "Epoch 686/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2957.7866 - val_loss: 4631.7227\n",
      "Epoch 687/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2919.4173 - val_loss: 5073.0200\n",
      "Epoch 688/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2938.4040 - val_loss: 5513.7886\n",
      "Epoch 689/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2958.9210 - val_loss: 5015.5532\n",
      "Epoch 690/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2930.4131 - val_loss: 4949.7007\n",
      "Epoch 691/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2925.0358 - val_loss: 4801.0122\n",
      "Epoch 692/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2944.1696 - val_loss: 4983.7676\n",
      "Epoch 693/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2974.5605 - val_loss: 5242.0425\n",
      "Epoch 694/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2929.8659 - val_loss: 4804.5508\n",
      "Epoch 695/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2931.2831 - val_loss: 4934.2363\n",
      "Epoch 696/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2894.8662 - val_loss: 5278.4316\n",
      "Epoch 697/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2930.5568 - val_loss: 5093.5566\n",
      "Epoch 698/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2884.5332 - val_loss: 4970.6011\n",
      "Epoch 699/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2905.8393 - val_loss: 5094.1289\n",
      "Epoch 700/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2924.3132 - val_loss: 5794.8799\n",
      "Epoch 701/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2996.7838 - val_loss: 5473.0015\n",
      "Epoch 702/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2912.3860 - val_loss: 4813.3394\n",
      "Epoch 703/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2956.5966 - val_loss: 4729.3770\n",
      "Epoch 704/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2898.2747 - val_loss: 5290.1943\n",
      "Epoch 705/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2979.2645 - val_loss: 6001.3086\n",
      "Epoch 706/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3034.0081 - val_loss: 5322.7471\n",
      "Epoch 707/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2876.6520 - val_loss: 4482.6187\n",
      "Epoch 708/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3092.0385 - val_loss: 4545.6099\n",
      "Epoch 709/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2942.8993 - val_loss: 5523.3452\n",
      "Epoch 710/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2941.2007 - val_loss: 5558.5996\n",
      "Epoch 711/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2916.7951 - val_loss: 4947.5293\n",
      "Epoch 712/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2908.9179 - val_loss: 4747.2129\n",
      "Epoch 713/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2977.9980 - val_loss: 4697.1367\n",
      "Epoch 714/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2942.5327 - val_loss: 5323.2866\n",
      "Epoch 715/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2945.2190 - val_loss: 4884.7329\n",
      "Epoch 716/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2912.1922 - val_loss: 5308.3892\n",
      "Epoch 717/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2889.2230 - val_loss: 5376.3008\n",
      "Epoch 718/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2916.6295 - val_loss: 5173.4468\n",
      "Epoch 719/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2917.5027 - val_loss: 5091.4077\n",
      "Epoch 720/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2905.0697 - val_loss: 5150.2261\n",
      "Epoch 721/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2912.0846 - val_loss: 5406.9688\n",
      "Epoch 722/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2874.1934 - val_loss: 4942.6499\n",
      "Epoch 723/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2924.1254 - val_loss: 4619.8018\n",
      "Epoch 724/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2929.7012 - val_loss: 5598.5898\n",
      "Epoch 725/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2930.0403 - val_loss: 5313.4727\n",
      "Epoch 726/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2900.7365 - val_loss: 4914.8027\n",
      "Epoch 727/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2911.8855 - val_loss: 4856.0239\n",
      "Epoch 728/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2909.3339 - val_loss: 5423.8228\n",
      "Epoch 729/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2977.5026 - val_loss: 6134.9336\n",
      "Epoch 730/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2999.8554 - val_loss: 5087.3364\n",
      "Epoch 731/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2905.6246 - val_loss: 4763.6421\n",
      "Epoch 732/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2940.9776 - val_loss: 4913.5630\n",
      "Epoch 733/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2944.4504 - val_loss: 5020.1089\n",
      "Epoch 734/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2924.5892 - val_loss: 4986.7017\n",
      "Epoch 735/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2904.9048 - val_loss: 4919.1807\n",
      "Epoch 736/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2900.0435 - val_loss: 4820.7319\n",
      "Epoch 737/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2956.4732 - val_loss: 4555.7905\n",
      "Epoch 738/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 [==============================] - 0s 1ms/step - loss: 2964.4153 - val_loss: 4759.0879\n",
      "Epoch 739/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2960.7808 - val_loss: 4910.5640\n",
      "Epoch 740/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3008.2140 - val_loss: 5579.3760\n",
      "Epoch 741/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2904.7212 - val_loss: 4902.3926\n",
      "Epoch 742/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2908.5758 - val_loss: 4613.2178\n",
      "Epoch 743/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2961.2540 - val_loss: 5148.1255\n",
      "Epoch 744/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2893.3828 - val_loss: 5094.4937\n",
      "Epoch 745/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2881.6442 - val_loss: 4731.0190\n",
      "Epoch 746/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3034.1507 - val_loss: 4446.4180\n",
      "Epoch 747/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2900.2298 - val_loss: 5586.5361\n",
      "Epoch 748/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3067.7294 - val_loss: 6115.3330\n",
      "Epoch 749/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3104.9763 - val_loss: 4414.6948\n",
      "Epoch 750/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3120.4053 - val_loss: 4489.5986\n",
      "Epoch 751/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2912.6752 - val_loss: 5595.1641\n",
      "Epoch 752/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2985.7733 - val_loss: 5721.8076\n",
      "Epoch 753/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2961.7959 - val_loss: 4679.8672\n",
      "Epoch 754/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2958.3285 - val_loss: 4724.0029\n",
      "Epoch 755/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2923.1303 - val_loss: 5167.8242\n",
      "Epoch 756/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2901.8872 - val_loss: 5642.6587\n",
      "Epoch 757/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2934.0614 - val_loss: 4902.5742\n",
      "Epoch 758/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2926.5360 - val_loss: 4767.2881\n",
      "Epoch 759/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2926.3741 - val_loss: 5121.6699\n",
      "Epoch 760/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2875.2342 - val_loss: 5062.3081\n",
      "Epoch 761/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2926.4886 - val_loss: 5680.1812\n",
      "Epoch 762/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2956.6069 - val_loss: 4972.3062\n",
      "Epoch 763/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3044.6962 - val_loss: 4398.3594\n",
      "Epoch 764/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3030.4948 - val_loss: 4871.0142\n",
      "Epoch 765/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2933.0926 - val_loss: 5353.8125\n",
      "Epoch 766/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2930.1658 - val_loss: 5267.1704\n",
      "Epoch 767/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2892.6858 - val_loss: 5334.3218\n",
      "Epoch 768/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2941.5958 - val_loss: 4894.9155\n",
      "Epoch 769/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2955.0326 - val_loss: 5446.5527\n",
      "Epoch 770/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2929.2552 - val_loss: 5606.2280\n",
      "Epoch 771/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2913.8462 - val_loss: 5179.0723\n",
      "Epoch 772/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2920.5703 - val_loss: 4738.2515\n",
      "Epoch 773/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2926.0564 - val_loss: 5001.0820\n",
      "Epoch 774/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2888.6192 - val_loss: 5318.0181\n",
      "Epoch 775/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2886.9435 - val_loss: 4920.0278\n",
      "Epoch 776/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2903.7411 - val_loss: 5147.4761\n",
      "Epoch 777/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2914.4218 - val_loss: 4948.1968\n",
      "Epoch 778/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2970.8087 - val_loss: 4540.4629\n",
      "Epoch 779/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2992.8177 - val_loss: 4910.7827\n",
      "Epoch 780/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2886.2833 - val_loss: 5945.6836\n",
      "Epoch 781/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3080.4549 - val_loss: 5765.5913\n",
      "Epoch 782/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2942.5055 - val_loss: 4942.2090\n",
      "Epoch 783/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2946.8425 - val_loss: 4676.9360\n",
      "Epoch 784/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2964.3249 - val_loss: 5018.1709\n",
      "Epoch 785/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2875.3163 - val_loss: 5401.0845\n",
      "Epoch 786/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2944.9604 - val_loss: 5691.7485\n",
      "Epoch 787/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2977.5415 - val_loss: 5221.6401\n",
      "Epoch 788/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2918.4339 - val_loss: 4559.5322\n",
      "Epoch 789/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3000.1639 - val_loss: 4789.1665\n",
      "Epoch 790/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2963.0451 - val_loss: 4774.2812\n",
      "Epoch 791/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2931.7856 - val_loss: 4933.4805\n",
      "Epoch 792/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2917.1997 - val_loss: 5320.8765\n",
      "Epoch 793/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2928.7638 - val_loss: 5475.4902\n",
      "Epoch 794/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2907.3295 - val_loss: 4894.6108\n",
      "Epoch 795/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2974.9230 - val_loss: 4386.8452\n",
      "Epoch 796/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3055.2166 - val_loss: 4807.5977\n",
      "Epoch 797/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2919.5022 - val_loss: 5451.3374\n",
      "Epoch 798/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2959.7511 - val_loss: 5283.6479\n",
      "Epoch 799/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2913.9743 - val_loss: 4809.5137\n",
      "Epoch 800/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2932.7459 - val_loss: 4906.9819\n",
      "Epoch 801/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2917.1207 - val_loss: 4640.2617\n",
      "Epoch 802/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2939.6515 - val_loss: 5102.4507\n",
      "Epoch 803/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2971.3538 - val_loss: 5588.6079\n",
      "Epoch 804/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2927.3741 - val_loss: 4589.0698\n",
      "Epoch 805/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3011.8165 - val_loss: 4625.5625\n",
      "Epoch 806/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2902.8639 - val_loss: 5768.1445\n",
      "Epoch 807/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3070.3580 - val_loss: 6091.7773\n",
      "Epoch 808/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2969.4538 - val_loss: 5263.7017\n",
      "Epoch 809/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2908.7749 - val_loss: 4909.0415\n",
      "Epoch 810/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2883.9549 - val_loss: 5261.9795\n",
      "Epoch 811/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2956.7885 - val_loss: 5513.6934\n",
      "Epoch 812/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2965.4237 - val_loss: 4704.8032\n",
      "Epoch 813/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2934.4264 - val_loss: 4977.6621\n",
      "Epoch 814/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2942.4438 - val_loss: 4826.6343\n",
      "Epoch 815/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2975.0584 - val_loss: 4659.7871\n",
      "Epoch 816/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2936.7521 - val_loss: 5035.9399\n",
      "Epoch 817/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2895.2976 - val_loss: 4896.6313\n",
      "Epoch 818/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2906.4575 - val_loss: 5030.2383\n",
      "Epoch 819/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2947.1965 - val_loss: 5383.9795\n",
      "Epoch 820/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2893.3574 - val_loss: 5065.3687\n",
      "Epoch 821/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2948.0892 - val_loss: 5511.4458\n",
      "Epoch 822/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2966.5854 - val_loss: 5569.9937\n",
      "Epoch 823/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2923.1304 - val_loss: 5036.6099\n",
      "Epoch 824/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3008.6182 - val_loss: 4507.8252\n",
      "Epoch 825/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2932.9682 - val_loss: 5223.8604\n",
      "Epoch 826/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2948.1975 - val_loss: 5804.5171\n",
      "Epoch 827/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2982.4298 - val_loss: 5164.8164\n",
      "Epoch 828/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2915.9764 - val_loss: 4918.0361\n",
      "Epoch 829/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2940.6265 - val_loss: 4785.8423\n",
      "Epoch 830/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2926.0607 - val_loss: 4960.1680\n",
      "Epoch 831/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2917.2768 - val_loss: 4836.9722\n",
      "Epoch 832/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2894.3945 - val_loss: 5160.3159\n",
      "Epoch 833/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3009.1788 - val_loss: 6184.2837\n",
      "Epoch 834/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3007.8671 - val_loss: 5174.4351\n",
      "Epoch 835/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2922.3387 - val_loss: 4504.7266\n",
      "Epoch 836/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3104.7665 - val_loss: 4351.0718\n",
      "Epoch 837/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3064.3478 - val_loss: 4770.2012\n",
      "Epoch 838/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3047.2439 - val_loss: 5752.0347\n",
      "Epoch 839/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2916.6778 - val_loss: 4983.5825\n",
      "Epoch 840/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2889.9578 - val_loss: 4601.5898\n",
      "Epoch 841/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2965.0406 - val_loss: 4904.5703\n",
      "Epoch 842/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2917.4267 - val_loss: 5678.9204\n",
      "Epoch 843/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3042.7422 - val_loss: 5963.1562\n",
      "Epoch 844/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2957.6298 - val_loss: 5207.3354\n",
      "Epoch 845/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3004.5841 - val_loss: 4460.5908\n",
      "Epoch 846/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3008.6177 - val_loss: 4893.2290\n",
      "Epoch 847/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2916.8181 - val_loss: 5094.1499\n",
      "Epoch 848/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2882.8265 - val_loss: 5206.5259\n",
      "Epoch 849/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2892.8322 - val_loss: 4971.0610\n",
      "Epoch 850/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2946.1128 - val_loss: 4803.6069\n",
      "Epoch 851/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2942.6454 - val_loss: 5376.3916\n",
      "Epoch 852/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2939.1894 - val_loss: 5111.9077\n",
      "Epoch 853/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2892.5225 - val_loss: 5292.2969\n",
      "Epoch 854/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2914.9319 - val_loss: 5319.0708\n",
      "Epoch 855/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2922.3289 - val_loss: 5334.9072\n",
      "Epoch 856/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2921.8387 - val_loss: 5232.2007\n",
      "Epoch 857/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2905.5622 - val_loss: 5074.9341\n",
      "Epoch 858/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2932.3285 - val_loss: 4937.7954\n",
      "Epoch 859/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2900.7253 - val_loss: 5213.2202\n",
      "Epoch 860/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2948.9335 - val_loss: 4973.0371\n",
      "Epoch 861/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2954.7203 - val_loss: 5655.6782\n",
      "Epoch 862/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2924.1006 - val_loss: 5286.6372\n",
      "Epoch 863/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2959.8794 - val_loss: 5745.7178\n",
      "Epoch 864/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2963.4539 - val_loss: 5364.5195\n",
      "Epoch 865/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2901.8205 - val_loss: 4985.3799\n",
      "Epoch 866/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2917.6402 - val_loss: 4925.2500\n",
      "Epoch 867/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2914.4292 - val_loss: 4970.0151\n",
      "Epoch 868/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2902.9098 - val_loss: 5073.2144\n",
      "Epoch 869/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2916.5204 - val_loss: 5144.2734\n",
      "Epoch 870/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2909.1782 - val_loss: 5311.0854\n",
      "Epoch 871/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2916.9627 - val_loss: 5124.5405\n",
      "Epoch 872/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2940.1501 - val_loss: 4609.4365\n",
      "Epoch 873/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2943.8236 - val_loss: 4806.8271\n",
      "Epoch 874/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2901.5380 - val_loss: 4907.4614\n",
      "Epoch 875/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2927.5623 - val_loss: 4832.7349\n",
      "Epoch 876/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2901.0849 - val_loss: 5293.8320\n",
      "Epoch 877/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2918.3674 - val_loss: 4990.8867\n",
      "Epoch 878/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2905.6568 - val_loss: 5105.1313\n",
      "Epoch 879/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2962.9196 - val_loss: 5708.4507\n",
      "Epoch 880/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2971.5132 - val_loss: 5052.3843\n",
      "Epoch 881/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2959.8633 - val_loss: 5432.7334\n",
      "Epoch 882/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2962.6278 - val_loss: 4670.0215\n",
      "Epoch 883/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2953.9972 - val_loss: 4651.1670\n",
      "Epoch 884/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2925.5118 - val_loss: 5195.7407\n",
      "Epoch 885/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2908.9758 - val_loss: 5620.2017\n",
      "Epoch 886/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 [==============================] - 0s 1ms/step - loss: 2946.5451 - val_loss: 5281.9619\n",
      "Epoch 887/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3031.8341 - val_loss: 4594.8066\n",
      "Epoch 888/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2973.9580 - val_loss: 5198.1836\n",
      "Epoch 889/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2901.4081 - val_loss: 5499.0742\n",
      "Epoch 890/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2918.6302 - val_loss: 5059.6509\n",
      "Epoch 891/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2910.4251 - val_loss: 4934.0947\n",
      "Epoch 892/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2915.0682 - val_loss: 4913.6504\n",
      "Epoch 893/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2881.8249 - val_loss: 5273.4004\n",
      "Epoch 894/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2924.6244 - val_loss: 5333.4150\n",
      "Epoch 895/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2903.8680 - val_loss: 4725.8291\n",
      "Epoch 896/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2925.0229 - val_loss: 4878.6094\n",
      "Epoch 897/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2906.7167 - val_loss: 5263.1431\n",
      "Epoch 898/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2931.3115 - val_loss: 5827.4658\n",
      "Epoch 899/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2980.8990 - val_loss: 5668.6489\n",
      "Epoch 900/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2954.0879 - val_loss: 5083.1221\n",
      "Epoch 901/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2903.6401 - val_loss: 5228.2129\n",
      "Epoch 902/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2900.8168 - val_loss: 5322.2847\n",
      "Epoch 903/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2927.0057 - val_loss: 5220.9204\n",
      "Epoch 904/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2947.7416 - val_loss: 4712.3008\n",
      "Epoch 905/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2917.2605 - val_loss: 5448.6162\n",
      "Epoch 906/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2941.9730 - val_loss: 5341.6841\n",
      "Epoch 907/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2914.3876 - val_loss: 4778.2827\n",
      "Epoch 908/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2950.2039 - val_loss: 4504.7983\n",
      "Epoch 909/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2991.1587 - val_loss: 4725.6836\n",
      "Epoch 910/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2909.4121 - val_loss: 5191.0635\n",
      "Epoch 911/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2922.5337 - val_loss: 5762.7358\n",
      "Epoch 912/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2943.0131 - val_loss: 5025.8271\n",
      "Epoch 913/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2951.8548 - val_loss: 4441.0186\n",
      "Epoch 914/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3050.3725 - val_loss: 4692.4292\n",
      "Epoch 915/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2897.6176 - val_loss: 5691.6514\n",
      "Epoch 916/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3058.8435 - val_loss: 5885.3320\n",
      "Epoch 917/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2896.0628 - val_loss: 4861.9136\n",
      "Epoch 918/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2930.9145 - val_loss: 4806.7681\n",
      "Epoch 919/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2920.1037 - val_loss: 5172.2354\n",
      "Epoch 920/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2901.8686 - val_loss: 5903.4663\n",
      "Epoch 921/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3120.3390 - val_loss: 6096.2617\n",
      "Epoch 922/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2962.7405 - val_loss: 4786.1792\n",
      "Epoch 923/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2975.7948 - val_loss: 4380.4946\n",
      "Epoch 924/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2982.9072 - val_loss: 5127.0884\n",
      "Epoch 925/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2967.2500 - val_loss: 5752.3296\n",
      "Epoch 926/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2943.6366 - val_loss: 5078.3291\n",
      "Epoch 927/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2933.7039 - val_loss: 5203.4585\n",
      "Epoch 928/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2931.6088 - val_loss: 5621.1934\n",
      "Epoch 929/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2918.7290 - val_loss: 5094.4404\n",
      "Epoch 930/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2928.7149 - val_loss: 4779.7646\n",
      "Epoch 931/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2941.7958 - val_loss: 4904.0283\n",
      "Epoch 932/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2963.6787 - val_loss: 5389.1553\n",
      "Epoch 933/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2904.6646 - val_loss: 5289.9111\n",
      "Epoch 934/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2920.1131 - val_loss: 4838.5952\n",
      "Epoch 935/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2907.8693 - val_loss: 4810.4277\n",
      "Epoch 936/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2910.7768 - val_loss: 4841.0640\n",
      "Epoch 937/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2915.6850 - val_loss: 5088.8022\n",
      "Epoch 938/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2903.2357 - val_loss: 5293.4414\n",
      "Epoch 939/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2884.4905 - val_loss: 4953.1719\n",
      "Epoch 940/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2904.7596 - val_loss: 4966.9395\n",
      "Epoch 941/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2928.8350 - val_loss: 4805.3721\n",
      "Epoch 942/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2933.3108 - val_loss: 5009.5977\n",
      "Epoch 943/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2909.7208 - val_loss: 5775.9321\n",
      "Epoch 944/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3006.6629 - val_loss: 5459.0581\n",
      "Epoch 945/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2909.8280 - val_loss: 4932.7959\n",
      "Epoch 946/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2924.9573 - val_loss: 5168.7773\n",
      "Epoch 947/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2946.2655 - val_loss: 5640.2437\n",
      "Epoch 948/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2928.2913 - val_loss: 5162.3594\n",
      "Epoch 949/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2906.1887 - val_loss: 4725.9194\n",
      "Epoch 950/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2948.2527 - val_loss: 4729.0254\n",
      "Epoch 951/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2918.8604 - val_loss: 5551.0898\n",
      "Epoch 952/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2921.2277 - val_loss: 5397.8584\n",
      "Epoch 953/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2904.0210 - val_loss: 5215.6548\n",
      "Epoch 954/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2886.1725 - val_loss: 5026.1812\n",
      "Epoch 955/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2902.5034 - val_loss: 4959.7837\n",
      "Epoch 956/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2911.6385 - val_loss: 4975.4468\n",
      "Epoch 957/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2957.8346 - val_loss: 4738.7720\n",
      "Epoch 958/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2924.0073 - val_loss: 5356.9966\n",
      "Epoch 959/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2917.2417 - val_loss: 5256.3735\n",
      "Epoch 960/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2871.6764 - val_loss: 4713.1211\n",
      "Epoch 961/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2947.6479 - val_loss: 4809.0742\n",
      "Epoch 962/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2870.3826 - val_loss: 5436.8926\n",
      "Epoch 963/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2946.3546 - val_loss: 5499.9370\n",
      "Epoch 964/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2924.8040 - val_loss: 5257.7031\n",
      "Epoch 965/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2910.3914 - val_loss: 4767.7773\n",
      "Epoch 966/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2960.5098 - val_loss: 4685.6738\n",
      "Epoch 967/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2941.3788 - val_loss: 5399.6846\n",
      "Epoch 968/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2927.5079 - val_loss: 5337.4873\n",
      "Epoch 969/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2907.1428 - val_loss: 5382.0640\n",
      "Epoch 970/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2885.3909 - val_loss: 5165.1348\n",
      "Epoch 971/2000\n",
      "164/164 [==============================] - 0s 2ms/step - loss: 2875.7846 - val_loss: 4811.7515\n",
      "Epoch 972/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2941.0882 - val_loss: 4572.6553\n",
      "Epoch 973/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2966.4701 - val_loss: 5041.3164\n",
      "Epoch 974/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2918.2356 - val_loss: 5410.7979\n",
      "Epoch 975/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2927.0877 - val_loss: 5019.9624\n",
      "Epoch 976/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2947.1757 - val_loss: 4635.8379\n",
      "Epoch 977/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2989.4837 - val_loss: 4764.7915\n",
      "Epoch 978/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2932.1271 - val_loss: 5646.5674\n",
      "Epoch 979/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2985.7177 - val_loss: 5634.6025\n",
      "Epoch 980/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2942.6112 - val_loss: 4991.3008\n",
      "Epoch 981/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2885.9549 - val_loss: 5383.4883\n",
      "Epoch 982/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2984.9429 - val_loss: 5760.2451\n",
      "Epoch 983/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2896.0132 - val_loss: 4848.5659\n",
      "Epoch 984/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2953.3030 - val_loss: 4723.4951\n",
      "Epoch 985/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2886.8422 - val_loss: 5368.5781\n",
      "Epoch 986/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2950.5310 - val_loss: 5573.1870\n",
      "Epoch 987/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2912.3518 - val_loss: 4630.6572\n",
      "Epoch 988/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3066.1830 - val_loss: 4433.3623\n",
      "Epoch 989/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2953.1275 - val_loss: 5491.8560\n",
      "Epoch 990/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3056.8259 - val_loss: 6515.2534\n",
      "Epoch 991/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3095.6795 - val_loss: 5452.6479\n",
      "Epoch 992/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2987.6042 - val_loss: 4391.6938\n",
      "Epoch 993/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3092.3439 - val_loss: 4529.8428\n",
      "Epoch 994/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2985.5304 - val_loss: 4958.8315\n",
      "Epoch 995/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2907.0429 - val_loss: 4910.3135\n",
      "Epoch 996/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2938.2460 - val_loss: 4706.3115\n",
      "Epoch 997/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2932.6650 - val_loss: 4994.5015\n",
      "Epoch 998/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2886.3838 - val_loss: 5166.2695\n",
      "Epoch 999/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2941.0069 - val_loss: 5465.8569\n",
      "Epoch 1000/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2914.9331 - val_loss: 5176.2109\n",
      "Epoch 1001/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2896.9632 - val_loss: 5178.6582\n",
      "Epoch 1002/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2931.2967 - val_loss: 5327.9448\n",
      "Epoch 1003/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2926.5055 - val_loss: 5192.9297\n",
      "Epoch 1004/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2895.3248 - val_loss: 5161.8008\n",
      "Epoch 1005/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2917.0873 - val_loss: 5462.4658\n",
      "Epoch 1006/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2982.1631 - val_loss: 5867.1235\n",
      "Epoch 1007/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2918.9732 - val_loss: 5178.8296\n",
      "Epoch 1008/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2981.7605 - val_loss: 4568.8633\n",
      "Epoch 1009/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2969.4916 - val_loss: 4938.2871\n",
      "Epoch 1010/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2922.3972 - val_loss: 5462.6479\n",
      "Epoch 1011/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2902.2494 - val_loss: 4925.5352\n",
      "Epoch 1012/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2913.5684 - val_loss: 4892.8198\n",
      "Epoch 1013/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2951.2080 - val_loss: 4929.4702\n",
      "Epoch 1014/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2979.4688 - val_loss: 5549.5020\n",
      "Epoch 1015/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2904.2576 - val_loss: 4881.3701\n",
      "Epoch 1016/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2950.1639 - val_loss: 4649.8555\n",
      "Epoch 1017/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2941.0021 - val_loss: 4978.3813\n",
      "Epoch 1018/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2929.8644 - val_loss: 6061.5371\n",
      "Epoch 1019/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3034.9192 - val_loss: 5522.1836\n",
      "Epoch 1020/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2999.7313 - val_loss: 4478.5239\n",
      "Epoch 1021/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3041.5551 - val_loss: 4646.9512\n",
      "Epoch 1022/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2907.8085 - val_loss: 5320.1602\n",
      "Epoch 1023/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2911.0444 - val_loss: 5622.6836\n",
      "Epoch 1024/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2916.7219 - val_loss: 5067.8604\n",
      "Epoch 1025/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3024.6988 - val_loss: 4702.9536\n",
      "Epoch 1026/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2917.6262 - val_loss: 5520.2129\n",
      "Epoch 1027/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2980.1297 - val_loss: 5338.2036\n",
      "Epoch 1028/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2883.6547 - val_loss: 4497.7642\n",
      "Epoch 1029/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3093.5596 - val_loss: 4497.4448\n",
      "Epoch 1030/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2920.2756 - val_loss: 5539.8140\n",
      "Epoch 1031/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2938.2129 - val_loss: 5488.7178\n",
      "Epoch 1032/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2913.6355 - val_loss: 5154.9102\n",
      "Epoch 1033/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2914.2058 - val_loss: 4770.4824\n",
      "Epoch 1034/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 [==============================] - 0s 1ms/step - loss: 2927.6203 - val_loss: 5024.2754\n",
      "Epoch 1035/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2895.3274 - val_loss: 5124.4175\n",
      "Epoch 1036/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2949.9688 - val_loss: 5274.0562\n",
      "Epoch 1037/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2875.0289 - val_loss: 4860.7271\n",
      "Epoch 1038/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2943.2302 - val_loss: 5197.2959\n",
      "Epoch 1039/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2930.0430 - val_loss: 5422.6587\n",
      "Epoch 1040/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2894.3034 - val_loss: 5427.2876\n",
      "Epoch 1041/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2907.0659 - val_loss: 5215.7925\n",
      "Epoch 1042/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2904.2549 - val_loss: 5091.4956\n",
      "Epoch 1043/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2914.8255 - val_loss: 4955.0615\n",
      "Epoch 1044/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2897.7232 - val_loss: 4819.6934\n",
      "Epoch 1045/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2892.2642 - val_loss: 5363.4731\n",
      "Epoch 1046/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2933.0906 - val_loss: 5365.6421\n",
      "Epoch 1047/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2894.0097 - val_loss: 5023.2485\n",
      "Epoch 1048/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2913.3420 - val_loss: 5114.9185\n",
      "Epoch 1049/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2906.9629 - val_loss: 4992.8296\n",
      "Epoch 1050/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2916.1355 - val_loss: 5083.0186\n",
      "Epoch 1051/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2893.7190 - val_loss: 4828.8896\n",
      "Epoch 1052/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2918.7182 - val_loss: 5273.2222\n",
      "Epoch 1053/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2893.0577 - val_loss: 4906.1128\n",
      "Epoch 1054/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2893.5020 - val_loss: 5039.4277\n",
      "Epoch 1055/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2906.9377 - val_loss: 5095.8774\n",
      "Epoch 1056/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2915.2495 - val_loss: 5267.4180\n",
      "Epoch 1057/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2908.9062 - val_loss: 5126.9458\n",
      "Epoch 1058/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2909.4928 - val_loss: 4928.3164\n",
      "Epoch 1059/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2906.3440 - val_loss: 5096.9766\n",
      "Epoch 1060/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2914.5192 - val_loss: 5050.8486\n",
      "Epoch 1061/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2928.5691 - val_loss: 4682.4712\n",
      "Epoch 1062/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2935.7133 - val_loss: 4895.4746\n",
      "Epoch 1063/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2962.7321 - val_loss: 5719.8818\n",
      "Epoch 1064/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2980.3696 - val_loss: 5664.5552\n",
      "Epoch 1065/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2972.3413 - val_loss: 5621.4712\n",
      "Epoch 1066/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2939.8704 - val_loss: 5221.4414\n",
      "Epoch 1067/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2920.6019 - val_loss: 5234.0435\n",
      "Epoch 1068/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2977.1932 - val_loss: 4531.9771\n",
      "Epoch 1069/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2973.9558 - val_loss: 4672.8066\n",
      "Epoch 1070/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2914.2900 - val_loss: 5227.4858\n",
      "Epoch 1071/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2921.5664 - val_loss: 5532.7256\n",
      "Epoch 1072/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2939.8851 - val_loss: 5927.7935\n",
      "Epoch 1073/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3008.1460 - val_loss: 5616.0332\n",
      "Epoch 1074/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2966.4674 - val_loss: 4893.7065\n",
      "Epoch 1075/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2875.6444 - val_loss: 5187.7393\n",
      "Epoch 1076/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2903.7784 - val_loss: 5303.0298\n",
      "Epoch 1077/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2923.2943 - val_loss: 4921.2910\n",
      "Epoch 1078/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2902.5624 - val_loss: 4920.3608\n",
      "Epoch 1079/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2899.1364 - val_loss: 5494.9341\n",
      "Epoch 1080/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2989.0321 - val_loss: 5772.3667\n",
      "Epoch 1081/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2960.4479 - val_loss: 4867.6880\n",
      "Epoch 1082/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2944.9319 - val_loss: 4628.9390\n",
      "Epoch 1083/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2933.7301 - val_loss: 5115.5898\n",
      "Epoch 1084/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2909.0487 - val_loss: 5864.7715\n",
      "Epoch 1085/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2927.7820 - val_loss: 4843.6753\n",
      "Epoch 1086/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2940.5580 - val_loss: 4680.7627\n",
      "Epoch 1087/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2928.3383 - val_loss: 5044.5854\n",
      "Epoch 1088/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2917.3380 - val_loss: 5640.9048\n",
      "Epoch 1089/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2942.0120 - val_loss: 5090.8848\n",
      "Epoch 1090/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2901.1028 - val_loss: 4590.4565\n",
      "Epoch 1091/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2957.5538 - val_loss: 4830.9521\n",
      "Epoch 1092/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2939.9330 - val_loss: 4969.1616\n",
      "Epoch 1093/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2931.1105 - val_loss: 4739.7051\n",
      "Epoch 1094/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2941.6587 - val_loss: 5297.8271\n",
      "Epoch 1095/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2907.5546 - val_loss: 5355.8579\n",
      "Epoch 1096/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2922.5229 - val_loss: 5146.6968\n",
      "Epoch 1097/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2908.1102 - val_loss: 4969.2075\n",
      "Epoch 1098/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2946.5089 - val_loss: 4739.5112\n",
      "Epoch 1099/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2908.1427 - val_loss: 5288.7969\n",
      "Epoch 1100/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2936.0965 - val_loss: 5460.4800\n",
      "Epoch 1101/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2896.0245 - val_loss: 4748.5420\n",
      "Epoch 1102/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2931.1169 - val_loss: 4734.2900\n",
      "Epoch 1103/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2941.3600 - val_loss: 5158.7534\n",
      "Epoch 1104/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2896.0450 - val_loss: 5332.7549\n",
      "Epoch 1105/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2908.0271 - val_loss: 5533.0845\n",
      "Epoch 1106/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2925.9804 - val_loss: 5241.4922\n",
      "Epoch 1107/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2903.1956 - val_loss: 4640.8945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1108/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2992.5311 - val_loss: 4620.8286\n",
      "Epoch 1109/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2906.3274 - val_loss: 5160.8740\n",
      "Epoch 1110/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2937.4417 - val_loss: 5745.3555\n",
      "Epoch 1111/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2992.3328 - val_loss: 5598.7280\n",
      "Epoch 1112/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3052.1780 - val_loss: 4836.9741\n",
      "Epoch 1113/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2909.6841 - val_loss: 5139.3525\n",
      "Epoch 1114/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2914.8363 - val_loss: 5967.3315\n",
      "Epoch 1115/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3007.0062 - val_loss: 5439.1069\n",
      "Epoch 1116/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2911.5976 - val_loss: 5125.2051\n",
      "Epoch 1117/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2946.1338 - val_loss: 4727.3823\n",
      "Epoch 1118/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2893.0533 - val_loss: 5258.0171\n",
      "Epoch 1119/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2877.3705 - val_loss: 5274.5020\n",
      "Epoch 1120/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2900.9348 - val_loss: 5095.5869\n",
      "Epoch 1121/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2901.1517 - val_loss: 4825.7407\n",
      "Epoch 1122/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2922.9842 - val_loss: 5246.5034\n",
      "Epoch 1123/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2909.9366 - val_loss: 5373.0737\n",
      "Epoch 1124/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2878.4419 - val_loss: 5291.6724\n",
      "Epoch 1125/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2908.3549 - val_loss: 4978.9111\n",
      "Epoch 1126/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2886.0199 - val_loss: 5235.8584\n",
      "Epoch 1127/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2900.0648 - val_loss: 5239.4321\n",
      "Epoch 1128/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2897.8824 - val_loss: 5105.6055\n",
      "Epoch 1129/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2900.0419 - val_loss: 4997.1162\n",
      "Epoch 1130/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2905.7950 - val_loss: 4736.5088\n",
      "Epoch 1131/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2939.3357 - val_loss: 4855.6987\n",
      "Epoch 1132/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2913.1752 - val_loss: 5137.0059\n",
      "Epoch 1133/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2896.1879 - val_loss: 4857.8745\n",
      "Epoch 1134/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2910.2189 - val_loss: 5440.8379\n",
      "Epoch 1135/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2971.4747 - val_loss: 5662.4077\n",
      "Epoch 1136/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2909.2595 - val_loss: 4748.7236\n",
      "Epoch 1137/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2954.2402 - val_loss: 4751.5718\n",
      "Epoch 1138/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2914.4017 - val_loss: 5431.8032\n",
      "Epoch 1139/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2968.6528 - val_loss: 5645.3032\n",
      "Epoch 1140/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2926.8855 - val_loss: 5333.9106\n",
      "Epoch 1141/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2941.3685 - val_loss: 4901.0190\n",
      "Epoch 1142/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2918.1979 - val_loss: 4903.9746\n",
      "Epoch 1143/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2895.1269 - val_loss: 5107.2773\n",
      "Epoch 1144/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2903.1203 - val_loss: 5226.1768\n",
      "Epoch 1145/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2900.7642 - val_loss: 5011.3774\n",
      "Epoch 1146/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2894.7781 - val_loss: 4787.4072\n",
      "Epoch 1147/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3028.6222 - val_loss: 4600.8394\n",
      "Epoch 1148/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2922.8332 - val_loss: 5187.8145\n",
      "Epoch 1149/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2913.5107 - val_loss: 5153.0811\n",
      "Epoch 1150/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2890.8578 - val_loss: 4596.2910\n",
      "Epoch 1151/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3059.6495 - val_loss: 4558.3242\n",
      "Epoch 1152/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2920.5685 - val_loss: 5554.6504\n",
      "Epoch 1153/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2956.6170 - val_loss: 5637.5767\n",
      "Epoch 1154/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2946.7689 - val_loss: 5088.1826\n",
      "Epoch 1155/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3013.8367 - val_loss: 4625.6914\n",
      "Epoch 1156/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2923.8137 - val_loss: 5522.2075\n",
      "Epoch 1157/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2938.4855 - val_loss: 5756.7432\n",
      "Epoch 1158/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2945.3096 - val_loss: 5108.7534\n",
      "Epoch 1159/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2868.5851 - val_loss: 4877.3599\n",
      "Epoch 1160/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2908.7716 - val_loss: 4775.0854\n",
      "Epoch 1161/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2898.3244 - val_loss: 5211.9497\n",
      "Epoch 1162/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2904.7138 - val_loss: 5520.9043\n",
      "Epoch 1163/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2895.6274 - val_loss: 5056.9336\n",
      "Epoch 1164/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2953.2566 - val_loss: 4523.8403\n",
      "Epoch 1165/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2983.0523 - val_loss: 4713.7246\n",
      "Epoch 1166/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2895.8094 - val_loss: 5188.4155\n",
      "Epoch 1167/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2912.5435 - val_loss: 5266.5996\n",
      "Epoch 1168/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2915.0167 - val_loss: 5045.3652\n",
      "Epoch 1169/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2916.0138 - val_loss: 4987.5952\n",
      "Epoch 1170/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2899.0979 - val_loss: 4935.9238\n",
      "Epoch 1171/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2875.1867 - val_loss: 5592.2959\n",
      "Epoch 1172/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2968.8179 - val_loss: 5859.5215\n",
      "Epoch 1173/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2936.2434 - val_loss: 4858.5815\n",
      "Epoch 1174/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2898.0600 - val_loss: 4850.6445\n",
      "Epoch 1175/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2914.0498 - val_loss: 5597.8105\n",
      "Epoch 1176/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2933.2693 - val_loss: 5276.1821\n",
      "Epoch 1177/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2909.9679 - val_loss: 4871.8970\n",
      "Epoch 1178/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2908.8599 - val_loss: 4721.4028\n",
      "Epoch 1179/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2933.0371 - val_loss: 5072.4521\n",
      "Epoch 1180/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2914.5397 - val_loss: 5626.7998\n",
      "Epoch 1181/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2944.1590 - val_loss: 5786.3428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1182/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2976.0473 - val_loss: 5350.6650\n",
      "Epoch 1183/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2936.6474 - val_loss: 4751.6260\n",
      "Epoch 1184/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2892.9756 - val_loss: 5289.0806\n",
      "Epoch 1185/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2892.5362 - val_loss: 5089.9072\n",
      "Epoch 1186/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2890.2417 - val_loss: 4869.0815\n",
      "Epoch 1187/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2963.3928 - val_loss: 4621.3501\n",
      "Epoch 1188/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2977.8033 - val_loss: 4763.8008\n",
      "Epoch 1189/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2864.3544 - val_loss: 5693.5947\n",
      "Epoch 1190/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2957.0007 - val_loss: 5475.9795\n",
      "Epoch 1191/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2929.7924 - val_loss: 5268.4565\n",
      "Epoch 1192/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2901.4687 - val_loss: 5320.9009\n",
      "Epoch 1193/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2919.6494 - val_loss: 5385.6636\n",
      "Epoch 1194/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2917.1665 - val_loss: 5280.6284\n",
      "Epoch 1195/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2968.5626 - val_loss: 5483.8032\n",
      "Epoch 1196/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2897.5763 - val_loss: 5105.0181\n",
      "Epoch 1197/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2934.0788 - val_loss: 4592.7280\n",
      "Epoch 1198/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2945.7797 - val_loss: 4856.0801\n",
      "Epoch 1199/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2944.1228 - val_loss: 5198.1909\n",
      "Epoch 1200/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2884.4914 - val_loss: 4765.8887\n",
      "Epoch 1201/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2886.8884 - val_loss: 5385.8979\n",
      "Epoch 1202/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3011.3258 - val_loss: 5796.8169\n",
      "Epoch 1203/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2949.6427 - val_loss: 4675.6890\n",
      "Epoch 1204/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2920.6827 - val_loss: 4969.9097\n",
      "Epoch 1205/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2891.0186 - val_loss: 5088.0615\n",
      "Epoch 1206/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2906.1456 - val_loss: 5225.8843\n",
      "Epoch 1207/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2883.4532 - val_loss: 4765.1304\n",
      "Epoch 1208/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2951.9204 - val_loss: 4742.3882\n",
      "Epoch 1209/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2886.9108 - val_loss: 5371.9385\n",
      "Epoch 1210/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2955.1937 - val_loss: 5471.6670\n",
      "Epoch 1211/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2897.6504 - val_loss: 4770.5996\n",
      "Epoch 1212/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2908.1956 - val_loss: 4762.0444\n",
      "Epoch 1213/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2931.3764 - val_loss: 4964.1235\n",
      "Epoch 1214/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2930.0813 - val_loss: 5365.1304\n",
      "Epoch 1215/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2869.0433 - val_loss: 5064.1587\n",
      "Epoch 1216/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2908.1875 - val_loss: 4791.1104\n",
      "Epoch 1217/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2892.2893 - val_loss: 5140.4756\n",
      "Epoch 1218/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2886.4934 - val_loss: 5172.6440\n",
      "Epoch 1219/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2875.5420 - val_loss: 4690.8140\n",
      "Epoch 1220/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2985.2572 - val_loss: 4433.3398\n",
      "Epoch 1221/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 3007.8004 - val_loss: 4635.6143\n",
      "Epoch 1222/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2926.7120 - val_loss: 5092.4253\n",
      "Epoch 1223/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2876.5554 - val_loss: 5237.8555\n",
      "Epoch 1224/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2907.6112 - val_loss: 4724.1548\n",
      "Epoch 1225/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2907.4170 - val_loss: 4810.0088\n",
      "Epoch 1226/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2866.6342 - val_loss: 5346.7446\n",
      "Epoch 1227/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2967.7946 - val_loss: 5884.7739\n",
      "Epoch 1228/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2953.8842 - val_loss: 5116.1396\n",
      "Epoch 1229/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2847.8317 - val_loss: 4766.0166\n",
      "Epoch 1230/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2899.0700 - val_loss: 4732.9209\n",
      "Epoch 1231/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2934.4860 - val_loss: 4772.3262\n",
      "Epoch 1232/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2890.7573 - val_loss: 5055.3135\n",
      "Epoch 1233/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2859.7986 - val_loss: 5033.6567\n",
      "Epoch 1234/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2883.8702 - val_loss: 5301.8511\n",
      "Epoch 1235/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2891.8823 - val_loss: 5598.4624\n",
      "Epoch 1236/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2955.7408 - val_loss: 5530.7749\n",
      "Epoch 1237/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2885.8163 - val_loss: 4740.7983\n",
      "Epoch 1238/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2889.0558 - val_loss: 4877.4312\n",
      "Epoch 1239/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2823.7413 - val_loss: 5825.3140\n",
      "Epoch 1240/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2991.7858 - val_loss: 5583.2471\n",
      "Epoch 1241/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2874.6455 - val_loss: 4853.1943\n",
      "Epoch 1242/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2945.9134 - val_loss: 4480.6025\n",
      "Epoch 1243/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2917.0791 - val_loss: 5089.3027\n",
      "Epoch 1244/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2936.7651 - val_loss: 5798.2129\n",
      "Epoch 1245/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2938.5399 - val_loss: 5238.9053\n",
      "Epoch 1246/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2880.7673 - val_loss: 4547.4751\n",
      "Epoch 1247/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2959.4557 - val_loss: 4588.4487\n",
      "Epoch 1248/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2906.3344 - val_loss: 5113.2544\n",
      "Epoch 1249/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2882.9531 - val_loss: 5110.9927\n",
      "Epoch 1250/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2891.6084 - val_loss: 4881.8359\n",
      "Epoch 1251/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2865.9562 - val_loss: 5088.5562\n",
      "Epoch 1252/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2843.9667 - val_loss: 4845.3438\n",
      "Epoch 1253/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2898.5060 - val_loss: 4551.9624\n",
      "Epoch 1254/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2929.8402 - val_loss: 4985.3208\n",
      "Epoch 1255/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2958.0439 - val_loss: 6135.0674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1256/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2981.4971 - val_loss: 5083.1655\n",
      "Epoch 1257/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2852.3775 - val_loss: 4647.4546\n",
      "Epoch 1258/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2871.2841 - val_loss: 5330.2085\n",
      "Epoch 1259/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2989.1969 - val_loss: 5602.8931\n",
      "Epoch 1260/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2964.1391 - val_loss: 4632.7085\n",
      "Epoch 1261/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2877.4199 - val_loss: 5076.3667\n",
      "Epoch 1262/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2902.2639 - val_loss: 5331.5220\n",
      "Epoch 1263/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2867.8502 - val_loss: 4782.7427\n",
      "Epoch 1264/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2929.1802 - val_loss: 4687.5596\n",
      "Epoch 1265/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2867.6168 - val_loss: 5001.6748\n",
      "Epoch 1266/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2840.2316 - val_loss: 4858.5562\n",
      "Epoch 1267/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2886.0733 - val_loss: 4849.7617\n",
      "Epoch 1268/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2897.1950 - val_loss: 4524.6851\n",
      "Epoch 1269/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2893.8034 - val_loss: 5083.4756\n",
      "Epoch 1270/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2886.4068 - val_loss: 5098.4556\n",
      "Epoch 1271/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2840.0853 - val_loss: 4718.8120\n",
      "Epoch 1272/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2945.3490 - val_loss: 4424.2197\n",
      "Epoch 1273/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2948.6936 - val_loss: 5397.9375\n",
      "Epoch 1274/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2923.1838 - val_loss: 5707.3086\n",
      "Epoch 1275/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2902.9161 - val_loss: 5118.2500\n",
      "Epoch 1276/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2894.0811 - val_loss: 4756.1494\n",
      "Epoch 1277/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2870.5572 - val_loss: 4756.3804\n",
      "Epoch 1278/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2905.2340 - val_loss: 4700.4624\n",
      "Epoch 1279/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2866.2642 - val_loss: 4674.3716\n",
      "Epoch 1280/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2895.2790 - val_loss: 5192.9771\n",
      "Epoch 1281/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2871.8188 - val_loss: 5181.1182\n",
      "Epoch 1282/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2856.4313 - val_loss: 4885.4087\n",
      "Epoch 1283/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2866.4771 - val_loss: 4871.4883\n",
      "Epoch 1284/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2858.7189 - val_loss: 5149.8296\n",
      "Epoch 1285/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2860.0980 - val_loss: 4521.3921\n",
      "Epoch 1286/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2898.8207 - val_loss: 4734.3320\n",
      "Epoch 1287/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2863.1136 - val_loss: 5218.4556\n",
      "Epoch 1288/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2838.7860 - val_loss: 5142.0391\n",
      "Epoch 1289/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2830.7754 - val_loss: 5078.2031\n",
      "Epoch 1290/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2855.8058 - val_loss: 5325.0454\n",
      "Epoch 1291/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2871.3818 - val_loss: 4895.4756\n",
      "Epoch 1292/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2842.7705 - val_loss: 5186.1138\n",
      "Epoch 1293/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2860.6475 - val_loss: 4994.1357\n",
      "Epoch 1294/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2847.6043 - val_loss: 4945.5371\n",
      "Epoch 1295/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2866.6315 - val_loss: 5315.2739\n",
      "Epoch 1296/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2857.1969 - val_loss: 4883.8032\n",
      "Epoch 1297/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2892.3014 - val_loss: 4390.8242\n",
      "Epoch 1298/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2853.6359 - val_loss: 5137.5005\n",
      "Epoch 1299/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2839.8977 - val_loss: 5212.9189\n",
      "Epoch 1300/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2798.9156 - val_loss: 4905.6426\n",
      "Epoch 1301/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2822.0952 - val_loss: 4402.2329\n",
      "Epoch 1302/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2837.2138 - val_loss: 4861.0942\n",
      "Epoch 1303/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2851.5999 - val_loss: 5625.4458\n",
      "Epoch 1304/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2918.8668 - val_loss: 5162.9570\n",
      "Epoch 1305/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2814.6931 - val_loss: 4374.8423\n",
      "Epoch 1306/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2896.8361 - val_loss: 4345.2744\n",
      "Epoch 1307/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2817.7586 - val_loss: 5195.6729\n",
      "Epoch 1308/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2916.0189 - val_loss: 5277.6528\n",
      "Epoch 1309/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2817.2982 - val_loss: 4179.4277\n",
      "Epoch 1310/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2908.0830 - val_loss: 4339.5059\n",
      "Epoch 1311/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2771.7790 - val_loss: 5375.9141\n",
      "Epoch 1312/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2935.0962 - val_loss: 5341.2051\n",
      "Epoch 1313/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2849.2369 - val_loss: 4507.4502\n",
      "Epoch 1314/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2753.6547 - val_loss: 5098.0293\n",
      "Epoch 1315/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2782.7618 - val_loss: 4775.1157\n",
      "Epoch 1316/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2774.4956 - val_loss: 5288.1357\n",
      "Epoch 1317/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2799.3781 - val_loss: 4882.6934\n",
      "Epoch 1318/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2750.5079 - val_loss: 4574.3320\n",
      "Epoch 1319/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2747.7925 - val_loss: 4806.5063\n",
      "Epoch 1320/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2740.5850 - val_loss: 4149.2988\n",
      "Epoch 1321/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2770.1630 - val_loss: 5060.8970\n",
      "Epoch 1322/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2722.8648 - val_loss: 4511.0615\n",
      "Epoch 1323/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2756.5441 - val_loss: 4278.0210\n",
      "Epoch 1324/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2755.2387 - val_loss: 4526.9814\n",
      "Epoch 1325/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2730.6221 - val_loss: 5174.7622\n",
      "Epoch 1326/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2792.1539 - val_loss: 5066.3652\n",
      "Epoch 1327/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2786.2784 - val_loss: 4653.1841\n",
      "Epoch 1328/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2722.6337 - val_loss: 4692.6797\n",
      "Epoch 1329/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2699.7844 - val_loss: 4357.6045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1330/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2741.4626 - val_loss: 4311.9399\n",
      "Epoch 1331/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2769.6837 - val_loss: 5029.3291\n",
      "Epoch 1332/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2726.5650 - val_loss: 4302.8403\n",
      "Epoch 1333/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2761.9177 - val_loss: 5094.5854\n",
      "Epoch 1334/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2752.0700 - val_loss: 4427.5278\n",
      "Epoch 1335/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2747.3267 - val_loss: 4321.7944\n",
      "Epoch 1336/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2712.5158 - val_loss: 4876.3164\n",
      "Epoch 1337/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2719.3936 - val_loss: 3889.9407\n",
      "Epoch 1338/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2917.4942 - val_loss: 3989.2656\n",
      "Epoch 1339/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2727.0712 - val_loss: 5184.3848\n",
      "Epoch 1340/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2789.8738 - val_loss: 4616.6069\n",
      "Epoch 1341/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2679.6135 - val_loss: 4843.3843\n",
      "Epoch 1342/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2737.4739 - val_loss: 4558.8130\n",
      "Epoch 1343/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2692.7574 - val_loss: 4709.1562\n",
      "Epoch 1344/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2722.7660 - val_loss: 4559.8057\n",
      "Epoch 1345/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2699.9867 - val_loss: 3976.1514\n",
      "Epoch 1346/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2712.3336 - val_loss: 4688.3242\n",
      "Epoch 1347/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2682.0246 - val_loss: 4399.7905\n",
      "Epoch 1348/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2666.6413 - val_loss: 4073.8298\n",
      "Epoch 1349/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2719.3412 - val_loss: 3945.1538\n",
      "Epoch 1350/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2706.3658 - val_loss: 4043.6636\n",
      "Epoch 1351/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2676.1791 - val_loss: 4413.9360\n",
      "Epoch 1352/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2683.9973 - val_loss: 4501.7876\n",
      "Epoch 1353/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2621.2618 - val_loss: 3864.8220\n",
      "Epoch 1354/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2706.2668 - val_loss: 4154.2505\n",
      "Epoch 1355/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2633.6630 - val_loss: 4309.6313\n",
      "Epoch 1356/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2646.3429 - val_loss: 4036.4255\n",
      "Epoch 1357/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2663.7779 - val_loss: 4068.9194\n",
      "Epoch 1358/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2637.6036 - val_loss: 4066.0325\n",
      "Epoch 1359/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2632.3974 - val_loss: 4070.0103\n",
      "Epoch 1360/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2642.9587 - val_loss: 4407.4062\n",
      "Epoch 1361/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2667.6375 - val_loss: 4226.3140\n",
      "Epoch 1362/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2586.9846 - val_loss: 4912.7476\n",
      "Epoch 1363/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2633.2528 - val_loss: 4022.3547\n",
      "Epoch 1364/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2694.6064 - val_loss: 3593.4448\n",
      "Epoch 1365/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2622.3845 - val_loss: 4241.5854\n",
      "Epoch 1366/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2560.0946 - val_loss: 4035.6321\n",
      "Epoch 1367/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2548.8619 - val_loss: 3880.1204\n",
      "Epoch 1368/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2533.3737 - val_loss: 4076.4399\n",
      "Epoch 1369/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2555.5472 - val_loss: 4021.8635\n",
      "Epoch 1370/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2567.4791 - val_loss: 3745.6057\n",
      "Epoch 1371/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2476.9214 - val_loss: 4379.3589\n",
      "Epoch 1372/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2596.8790 - val_loss: 4291.8438\n",
      "Epoch 1373/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2500.4774 - val_loss: 3669.0667\n",
      "Epoch 1374/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2498.9190 - val_loss: 4185.6416\n",
      "Epoch 1375/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2617.4041 - val_loss: 4917.0664\n",
      "Epoch 1376/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2553.9312 - val_loss: 3817.2085\n",
      "Epoch 1377/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2514.3061 - val_loss: 3865.7573\n",
      "Epoch 1378/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2424.1001 - val_loss: 4092.4136\n",
      "Epoch 1379/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2419.4103 - val_loss: 3582.2039\n",
      "Epoch 1380/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2416.6415 - val_loss: 3826.5735\n",
      "Epoch 1381/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2425.6957 - val_loss: 4068.4746\n",
      "Epoch 1382/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2316.6150 - val_loss: 3552.1501\n",
      "Epoch 1383/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2317.0655 - val_loss: 3732.6016\n",
      "Epoch 1384/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2231.7920 - val_loss: 4255.1763\n",
      "Epoch 1385/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2247.9048 - val_loss: 3844.7314\n",
      "Epoch 1386/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2203.3392 - val_loss: 3374.6145\n",
      "Epoch 1387/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2162.4412 - val_loss: 3880.6436\n",
      "Epoch 1388/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2194.3194 - val_loss: 2905.2024\n",
      "Epoch 1389/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 2063.3670 - val_loss: 3391.3972\n",
      "Epoch 1390/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 1956.5946 - val_loss: 2819.7207\n",
      "Epoch 1391/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 1999.7306 - val_loss: 3074.8745\n",
      "Epoch 1392/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 1909.1309 - val_loss: 3235.3977\n",
      "Epoch 1393/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 1906.8439 - val_loss: 2782.5078\n",
      "Epoch 1394/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 1806.8396 - val_loss: 2481.3884\n",
      "Epoch 1395/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 1743.7464 - val_loss: 2777.7405\n",
      "Epoch 1396/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 1833.1964 - val_loss: 2385.7852\n",
      "Epoch 1397/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 1888.0172 - val_loss: 2375.8140\n",
      "Epoch 1398/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 1637.8020 - val_loss: 2798.2180\n",
      "Epoch 1399/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 1704.0087 - val_loss: 2748.3044\n",
      "Epoch 1400/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 1690.3479 - val_loss: 2131.8345\n",
      "Epoch 1401/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 1503.2882 - val_loss: 3913.2837\n",
      "Epoch 1402/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 1625.2481 - val_loss: 2244.0979\n",
      "Epoch 1403/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 1626.1324 - val_loss: 2474.8762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1404/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 1635.0558 - val_loss: 2917.1067\n",
      "Epoch 1405/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 1556.1527 - val_loss: 1556.8687\n",
      "Epoch 1406/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 1657.1650 - val_loss: 2707.9448\n",
      "Epoch 1407/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 1451.8342 - val_loss: 1852.8134\n",
      "Epoch 1408/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 1529.8435 - val_loss: 2702.9631\n",
      "Epoch 1409/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 1327.4586 - val_loss: 1977.2017\n",
      "Epoch 1410/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 1210.5121 - val_loss: 2374.7368\n",
      "Epoch 1411/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 1205.2891 - val_loss: 1913.2765\n",
      "Epoch 1412/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 1256.4391 - val_loss: 2350.7808\n",
      "Epoch 1413/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 1346.0568 - val_loss: 2749.6912\n",
      "Epoch 1414/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 1354.5661 - val_loss: 2388.5789\n",
      "Epoch 1415/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 1242.1583 - val_loss: 2765.5750\n",
      "Epoch 1416/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 1236.4472 - val_loss: 2507.1785\n",
      "Epoch 1417/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 1403.8808 - val_loss: 2208.2705\n",
      "Epoch 1418/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 1431.2203 - val_loss: 2680.3882\n",
      "Epoch 1419/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 1238.8120 - val_loss: 2285.9568\n",
      "Epoch 1420/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 1249.1362 - val_loss: 2243.6311\n",
      "Epoch 1421/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 1084.8190 - val_loss: 2820.1431\n",
      "Epoch 1422/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 1070.3637 - val_loss: 1769.3542\n",
      "Epoch 1423/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 1329.2498 - val_loss: 2193.3704\n",
      "Epoch 1424/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 1136.1689 - val_loss: 2890.8154\n",
      "Epoch 1425/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 1057.8521 - val_loss: 1887.2855\n",
      "Epoch 1426/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 1059.9678 - val_loss: 2039.9469\n",
      "Epoch 1427/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 1064.5573 - val_loss: 2804.5852\n",
      "Epoch 1428/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 982.5499 - val_loss: 1642.9153\n",
      "Epoch 1429/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 1028.8448 - val_loss: 2440.3066\n",
      "Epoch 1430/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 1119.4155 - val_loss: 2514.7000\n",
      "Epoch 1431/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 1051.2513 - val_loss: 1893.7527\n",
      "Epoch 1432/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 976.9380 - val_loss: 2674.1177\n",
      "Epoch 1433/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 927.3691 - val_loss: 2275.6387\n",
      "Epoch 1434/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 919.1785 - val_loss: 2435.7854\n",
      "Epoch 1435/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 910.6052 - val_loss: 2309.6130\n",
      "Epoch 1436/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 814.3178 - val_loss: 1940.7566\n",
      "Epoch 1437/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 788.0380 - val_loss: 2761.5623\n",
      "Epoch 1438/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 986.4377 - val_loss: 2305.6958\n",
      "Epoch 1439/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 852.8472 - val_loss: 2048.5330\n",
      "Epoch 1440/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 836.3120 - val_loss: 1989.5283\n",
      "Epoch 1441/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 920.0736 - val_loss: 1983.1863\n",
      "Epoch 1442/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 996.4704 - val_loss: 1989.2236\n",
      "Epoch 1443/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 858.3677 - val_loss: 1953.2290\n",
      "Epoch 1444/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 829.4875 - val_loss: 2167.5474\n",
      "Epoch 1445/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 875.5432 - val_loss: 1978.3635\n",
      "Epoch 1446/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 946.7693 - val_loss: 2084.3018\n",
      "Epoch 1447/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 802.4328 - val_loss: 2184.9136\n",
      "Epoch 1448/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 816.9676 - val_loss: 1815.3787\n",
      "Epoch 1449/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 739.1540 - val_loss: 2002.4667\n",
      "Epoch 1450/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 715.5971 - val_loss: 1994.4907\n",
      "Epoch 1451/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 740.4164 - val_loss: 1925.5393\n",
      "Epoch 1452/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 709.7621 - val_loss: 2428.2764\n",
      "Epoch 1453/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 728.1738 - val_loss: 2204.7468\n",
      "Epoch 1454/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 633.5481 - val_loss: 2093.7571\n",
      "Epoch 1455/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 643.8025 - val_loss: 2065.8154\n",
      "Epoch 1456/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 783.7163 - val_loss: 1953.0656\n",
      "Epoch 1457/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 640.6198 - val_loss: 2306.1262\n",
      "Epoch 1458/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 667.2761 - val_loss: 2138.2805\n",
      "Epoch 1459/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 706.1677 - val_loss: 1920.1689\n",
      "Epoch 1460/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 734.0224 - val_loss: 1974.4739\n",
      "Epoch 1461/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 635.7793 - val_loss: 1839.0701\n",
      "Epoch 1462/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 577.6036 - val_loss: 2048.0015\n",
      "Epoch 1463/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 589.3802 - val_loss: 2482.7751\n",
      "Epoch 1464/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 553.4072 - val_loss: 1891.5890\n",
      "Epoch 1465/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 577.1875 - val_loss: 2097.9673\n",
      "Epoch 1466/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 559.8278 - val_loss: 1948.5211\n",
      "Epoch 1467/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 586.5884 - val_loss: 1755.9276\n",
      "Epoch 1468/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 745.5534 - val_loss: 1942.7804\n",
      "Epoch 1469/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 641.2217 - val_loss: 1935.9131\n",
      "Epoch 1470/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 754.2826 - val_loss: 1804.2776\n",
      "Epoch 1471/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 696.0776 - val_loss: 1721.6925\n",
      "Epoch 1472/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 683.1701 - val_loss: 2017.7704\n",
      "Epoch 1473/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 725.9884 - val_loss: 2460.9646\n",
      "Epoch 1474/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 604.5131 - val_loss: 2104.0159\n",
      "Epoch 1475/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 537.7075 - val_loss: 1541.1846\n",
      "Epoch 1476/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 538.3293 - val_loss: 1611.1627\n",
      "Epoch 1477/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 524.7930 - val_loss: 1785.8851\n",
      "Epoch 1478/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 460.5340 - val_loss: 1874.2677\n",
      "Epoch 1479/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 467.8769 - val_loss: 1990.0250\n",
      "Epoch 1480/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 492.0877 - val_loss: 1301.4913\n",
      "Epoch 1481/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 518.2747 - val_loss: 1330.2589\n",
      "Epoch 1482/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 472.0930 - val_loss: 1523.1215\n",
      "Epoch 1483/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 458.7900 - val_loss: 1328.2256\n",
      "Epoch 1484/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 446.6375 - val_loss: 1448.1051\n",
      "Epoch 1485/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 461.7166 - val_loss: 1544.6001\n",
      "Epoch 1486/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 496.0050 - val_loss: 1674.4706\n",
      "Epoch 1487/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 679.5908 - val_loss: 1869.3748\n",
      "Epoch 1488/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 824.1168 - val_loss: 1857.8663\n",
      "Epoch 1489/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 711.7221 - val_loss: 1412.4047\n",
      "Epoch 1490/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 862.5440 - val_loss: 1474.4928\n",
      "Epoch 1491/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 677.9512 - val_loss: 1486.3925\n",
      "Epoch 1492/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 674.4425 - val_loss: 1266.0870\n",
      "Epoch 1493/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 647.9515 - val_loss: 2011.0378\n",
      "Epoch 1494/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 578.1976 - val_loss: 1891.6727\n",
      "Epoch 1495/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 522.6723 - val_loss: 1772.3612\n",
      "Epoch 1496/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 541.9354 - val_loss: 1545.5684\n",
      "Epoch 1497/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 530.9668 - val_loss: 1966.8594\n",
      "Epoch 1498/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 495.5335 - val_loss: 1627.3812\n",
      "Epoch 1499/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 458.3210 - val_loss: 1501.7416\n",
      "Epoch 1500/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 506.7368 - val_loss: 2067.2688\n",
      "Epoch 1501/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 450.1452 - val_loss: 2103.5664\n",
      "Epoch 1502/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 412.4217 - val_loss: 1991.1682\n",
      "Epoch 1503/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 467.7881 - val_loss: 1841.3951\n",
      "Epoch 1504/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 423.4811 - val_loss: 1847.0594\n",
      "Epoch 1505/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 499.6661 - val_loss: 1795.9402\n",
      "Epoch 1506/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 449.4428 - val_loss: 1963.8357\n",
      "Epoch 1507/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 475.4760 - val_loss: 2052.1387\n",
      "Epoch 1508/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 370.3173 - val_loss: 2052.3896\n",
      "Epoch 1509/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 363.6678 - val_loss: 1835.2656\n",
      "Epoch 1510/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 363.0825 - val_loss: 1961.8787\n",
      "Epoch 1511/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 335.1467 - val_loss: 2124.7502\n",
      "Epoch 1512/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 323.7379 - val_loss: 1946.4344\n",
      "Epoch 1513/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 318.1954 - val_loss: 2136.6116\n",
      "Epoch 1514/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 313.2230 - val_loss: 1791.2794\n",
      "Epoch 1515/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 317.1786 - val_loss: 1698.5562\n",
      "Epoch 1516/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 300.1032 - val_loss: 1800.6163\n",
      "Epoch 1517/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 288.9747 - val_loss: 2114.9187\n",
      "Epoch 1518/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 297.4720 - val_loss: 2081.1074\n",
      "Epoch 1519/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 394.9735 - val_loss: 1894.8062\n",
      "Epoch 1520/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 426.9473 - val_loss: 2100.0913\n",
      "Epoch 1521/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 428.7568 - val_loss: 1925.4556\n",
      "Epoch 1522/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 365.3104 - val_loss: 1822.4390\n",
      "Epoch 1523/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 519.4530 - val_loss: 1428.8142\n",
      "Epoch 1524/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 552.0376 - val_loss: 1398.9521\n",
      "Epoch 1525/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 559.7023 - val_loss: 1324.9619\n",
      "Epoch 1526/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 513.9977 - val_loss: 1701.6470\n",
      "Epoch 1527/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 694.3646 - val_loss: 1341.8710\n",
      "Epoch 1528/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 494.3389 - val_loss: 1534.1079\n",
      "Epoch 1529/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 418.7175 - val_loss: 1322.1123\n",
      "Epoch 1530/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 391.4479 - val_loss: 1458.0680\n",
      "Epoch 1531/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 334.2643 - val_loss: 1566.3470\n",
      "Epoch 1532/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 318.9134 - val_loss: 1582.5948\n",
      "Epoch 1533/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 331.0582 - val_loss: 1727.2371\n",
      "Epoch 1534/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 345.2309 - val_loss: 1559.2725\n",
      "Epoch 1535/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 343.0291 - val_loss: 2035.4673\n",
      "Epoch 1536/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 291.9929 - val_loss: 1943.0541\n",
      "Epoch 1537/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 276.0904 - val_loss: 1839.1776\n",
      "Epoch 1538/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 267.2159 - val_loss: 1689.9634\n",
      "Epoch 1539/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 251.3268 - val_loss: 1659.4312\n",
      "Epoch 1540/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 252.5150 - val_loss: 2213.6436\n",
      "Epoch 1541/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 232.6797 - val_loss: 1966.4507\n",
      "Epoch 1542/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 248.1440 - val_loss: 2023.9120\n",
      "Epoch 1543/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 262.9658 - val_loss: 2199.6018\n",
      "Epoch 1544/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 242.8710 - val_loss: 1865.5739\n",
      "Epoch 1545/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 218.2067 - val_loss: 2101.5840\n",
      "Epoch 1546/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 243.2655 - val_loss: 1796.5806\n",
      "Epoch 1547/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 222.3009 - val_loss: 1880.4170\n",
      "Epoch 1548/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 201.5206 - val_loss: 1875.0096\n",
      "Epoch 1549/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 204.8544 - val_loss: 2101.9236\n",
      "Epoch 1550/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 211.6409 - val_loss: 1989.9573\n",
      "Epoch 1551/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 314.6251 - val_loss: 2312.3298\n",
      "Epoch 1552/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 [==============================] - 0s 1ms/step - loss: 342.7615 - val_loss: 1926.0551\n",
      "Epoch 1553/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 305.3361 - val_loss: 1741.7906\n",
      "Epoch 1554/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 281.1913 - val_loss: 1902.8687\n",
      "Epoch 1555/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 225.8260 - val_loss: 2018.4907\n",
      "Epoch 1556/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 212.1307 - val_loss: 1942.6569\n",
      "Epoch 1557/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 197.1556 - val_loss: 1971.9679\n",
      "Epoch 1558/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 204.6823 - val_loss: 2484.9207\n",
      "Epoch 1559/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 198.9290 - val_loss: 2140.0867\n",
      "Epoch 1560/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 256.7912 - val_loss: 1771.1581\n",
      "Epoch 1561/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 206.5630 - val_loss: 2425.3672\n",
      "Epoch 1562/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 262.6799 - val_loss: 1745.3456\n",
      "Epoch 1563/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 231.4979 - val_loss: 2492.2805\n",
      "Epoch 1564/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 264.3231 - val_loss: 2061.6729\n",
      "Epoch 1565/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 233.8924 - val_loss: 2159.8445\n",
      "Epoch 1566/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 275.5726 - val_loss: 2296.9160\n",
      "Epoch 1567/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 346.5190 - val_loss: 2208.6660\n",
      "Epoch 1568/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 442.4984 - val_loss: 2068.0239\n",
      "Epoch 1569/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 437.7406 - val_loss: 2204.1882\n",
      "Epoch 1570/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 328.2379 - val_loss: 2412.9092\n",
      "Epoch 1571/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 320.5403 - val_loss: 2037.6355\n",
      "Epoch 1572/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 274.9512 - val_loss: 2083.4517\n",
      "Epoch 1573/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 212.1238 - val_loss: 2650.1587\n",
      "Epoch 1574/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 253.0206 - val_loss: 2625.9172\n",
      "Epoch 1575/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 224.9323 - val_loss: 2333.6152\n",
      "Epoch 1576/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 215.7177 - val_loss: 2432.6160\n",
      "Epoch 1577/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 209.1547 - val_loss: 2655.0671\n",
      "Epoch 1578/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 189.1055 - val_loss: 2595.4785\n",
      "Epoch 1579/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 192.0645 - val_loss: 2756.7156\n",
      "Epoch 1580/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 182.9603 - val_loss: 2176.2351\n",
      "Epoch 1581/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 180.8003 - val_loss: 2366.3086\n",
      "Epoch 1582/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 191.9630 - val_loss: 2241.7009\n",
      "Epoch 1583/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 187.8663 - val_loss: 2384.9849\n",
      "Epoch 1584/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 163.5972 - val_loss: 2678.0176\n",
      "Epoch 1585/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 246.8341 - val_loss: 2330.2654\n",
      "Epoch 1586/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 313.3747 - val_loss: 2448.8271\n",
      "Epoch 1587/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 265.9716 - val_loss: 2344.1965\n",
      "Epoch 1588/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 258.7604 - val_loss: 2452.9983\n",
      "Epoch 1589/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 253.7860 - val_loss: 2566.9678\n",
      "Epoch 1590/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 217.2917 - val_loss: 2460.0085\n",
      "Epoch 1591/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 181.5921 - val_loss: 2728.7063\n",
      "Epoch 1592/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 195.0033 - val_loss: 2667.5320\n",
      "Epoch 1593/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 174.8713 - val_loss: 2204.1306\n",
      "Epoch 1594/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 201.4196 - val_loss: 2381.0310\n",
      "Epoch 1595/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 171.1914 - val_loss: 2524.4036\n",
      "Epoch 1596/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 175.1850 - val_loss: 2175.2019\n",
      "Epoch 1597/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 164.2236 - val_loss: 2528.3782\n",
      "Epoch 1598/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 141.3809 - val_loss: 2463.9658\n",
      "Epoch 1599/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 144.4853 - val_loss: 2321.4019\n",
      "Epoch 1600/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 159.1487 - val_loss: 2409.0742\n",
      "Epoch 1601/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 160.5264 - val_loss: 2541.9690\n",
      "Epoch 1602/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 173.9838 - val_loss: 2846.4661\n",
      "Epoch 1603/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 196.9641 - val_loss: 2135.6094\n",
      "Epoch 1604/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 183.2220 - val_loss: 2270.9395\n",
      "Epoch 1605/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 236.6049 - val_loss: 2211.5774\n",
      "Epoch 1606/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 154.1741 - val_loss: 2542.2827\n",
      "Epoch 1607/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 134.2190 - val_loss: 2566.1213\n",
      "Epoch 1608/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 143.6755 - val_loss: 2632.7964\n",
      "Epoch 1609/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 154.6635 - val_loss: 3169.1111\n",
      "Epoch 1610/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 175.8649 - val_loss: 2563.5137\n",
      "Epoch 1611/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 241.9723 - val_loss: 3044.3884\n",
      "Epoch 1612/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 233.9432 - val_loss: 2378.8538\n",
      "Epoch 1613/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 168.7711 - val_loss: 2337.9612\n",
      "Epoch 1614/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 162.0013 - val_loss: 2555.8022\n",
      "Epoch 1615/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 153.3321 - val_loss: 2642.4133\n",
      "Epoch 1616/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 127.9734 - val_loss: 2464.8237\n",
      "Epoch 1617/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 125.8186 - val_loss: 2785.1963\n",
      "Epoch 1618/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 130.8799 - val_loss: 2249.1152\n",
      "Epoch 1619/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 138.9295 - val_loss: 3258.9580\n",
      "Epoch 1620/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 144.7229 - val_loss: 2481.3066\n",
      "Epoch 1621/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 147.5677 - val_loss: 2755.9541\n",
      "Epoch 1622/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 135.7026 - val_loss: 3114.4849\n",
      "Epoch 1623/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 150.8417 - val_loss: 3038.3867\n",
      "Epoch 1624/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 160.0976 - val_loss: 2550.7859\n",
      "Epoch 1625/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 135.5511 - val_loss: 2834.5095\n",
      "Epoch 1626/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 123.6432 - val_loss: 2826.6179\n",
      "Epoch 1627/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 150.3278 - val_loss: 2840.0254\n",
      "Epoch 1628/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 158.9307 - val_loss: 2445.4253\n",
      "Epoch 1629/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 133.9892 - val_loss: 2423.5774\n",
      "Epoch 1630/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 154.4701 - val_loss: 2717.3804\n",
      "Epoch 1631/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 201.1799 - val_loss: 2142.7297\n",
      "Epoch 1632/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 335.9704 - val_loss: 3004.1357\n",
      "Epoch 1633/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 980.1864 - val_loss: 1936.8344\n",
      "Epoch 1634/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 692.9839 - val_loss: 1527.7983\n",
      "Epoch 1635/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 597.9504 - val_loss: 2145.0540\n",
      "Epoch 1636/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 389.8719 - val_loss: 2431.9824\n",
      "Epoch 1637/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 334.5055 - val_loss: 2051.3369\n",
      "Epoch 1638/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 387.5208 - val_loss: 1897.4143\n",
      "Epoch 1639/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 334.3139 - val_loss: 1988.2440\n",
      "Epoch 1640/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 263.4667 - val_loss: 2007.5192\n",
      "Epoch 1641/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 212.1117 - val_loss: 2184.5068\n",
      "Epoch 1642/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 189.0477 - val_loss: 2326.5986\n",
      "Epoch 1643/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 176.2788 - val_loss: 2015.4814\n",
      "Epoch 1644/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 149.2427 - val_loss: 2148.0015\n",
      "Epoch 1645/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 143.8076 - val_loss: 2515.2720\n",
      "Epoch 1646/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 139.6173 - val_loss: 2278.5325\n",
      "Epoch 1647/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 138.0641 - val_loss: 2445.0188\n",
      "Epoch 1648/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 123.1210 - val_loss: 2359.2861\n",
      "Epoch 1649/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 118.4987 - val_loss: 1954.4092\n",
      "Epoch 1650/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 147.2928 - val_loss: 2313.9592\n",
      "Epoch 1651/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 139.3015 - val_loss: 2428.7852\n",
      "Epoch 1652/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 108.5698 - val_loss: 2211.8245\n",
      "Epoch 1653/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 117.3505 - val_loss: 2307.9573\n",
      "Epoch 1654/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 99.1386 - val_loss: 2511.8267\n",
      "Epoch 1655/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 113.2158 - val_loss: 2803.7061\n",
      "Epoch 1656/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 107.2179 - val_loss: 2544.5537\n",
      "Epoch 1657/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 121.5505 - val_loss: 2696.7253\n",
      "Epoch 1658/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 103.6946 - val_loss: 2425.7361\n",
      "Epoch 1659/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 127.6742 - val_loss: 2526.2473\n",
      "Epoch 1660/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 124.8379 - val_loss: 2870.3320\n",
      "Epoch 1661/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 136.6879 - val_loss: 2408.1794\n",
      "Epoch 1662/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 134.2004 - val_loss: 2367.6370\n",
      "Epoch 1663/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 127.0170 - val_loss: 2807.2810\n",
      "Epoch 1664/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 121.3383 - val_loss: 2866.4272\n",
      "Epoch 1665/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 100.4344 - val_loss: 2441.6379\n",
      "Epoch 1666/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 98.9513 - val_loss: 2697.6328\n",
      "Epoch 1667/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 93.8227 - val_loss: 2174.1250\n",
      "Epoch 1668/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 111.4881 - val_loss: 2775.5256\n",
      "Epoch 1669/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 97.1270 - val_loss: 3067.8616\n",
      "Epoch 1670/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 88.0850 - val_loss: 2741.0234\n",
      "Epoch 1671/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 80.8203 - val_loss: 2537.6772\n",
      "Epoch 1672/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 139.4030 - val_loss: 2805.7920\n",
      "Epoch 1673/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 127.3482 - val_loss: 3265.5906\n",
      "Epoch 1674/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 122.0532 - val_loss: 2729.0442\n",
      "Epoch 1675/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 125.4051 - val_loss: 2577.6970\n",
      "Epoch 1676/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 102.3453 - val_loss: 2574.4819\n",
      "Epoch 1677/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 125.5479 - val_loss: 2778.2993\n",
      "Epoch 1678/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 109.4684 - val_loss: 2735.5225\n",
      "Epoch 1679/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 103.6213 - val_loss: 2585.2058\n",
      "Epoch 1680/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 110.0623 - val_loss: 2626.9749\n",
      "Epoch 1681/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 113.8536 - val_loss: 2421.2576\n",
      "Epoch 1682/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 118.1001 - val_loss: 2464.1909\n",
      "Epoch 1683/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 84.1246 - val_loss: 2373.2751\n",
      "Epoch 1684/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 84.4702 - val_loss: 2388.8955\n",
      "Epoch 1685/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 71.3526 - val_loss: 2584.6829\n",
      "Epoch 1686/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 79.8948 - val_loss: 2440.8425\n",
      "Epoch 1687/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 76.6706 - val_loss: 2319.5173\n",
      "Epoch 1688/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 74.6330 - val_loss: 2512.4082\n",
      "Epoch 1689/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 71.9761 - val_loss: 2569.1978\n",
      "Epoch 1690/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 75.4176 - val_loss: 2469.5603\n",
      "Epoch 1691/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 77.9478 - val_loss: 2634.1106\n",
      "Epoch 1692/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 75.4953 - val_loss: 2661.5393\n",
      "Epoch 1693/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 69.9433 - val_loss: 2665.0999\n",
      "Epoch 1694/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 74.3341 - val_loss: 2548.9766\n",
      "Epoch 1695/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 94.4554 - val_loss: 2825.9685\n",
      "Epoch 1696/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 95.9255 - val_loss: 2776.9434\n",
      "Epoch 1697/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 76.5207 - val_loss: 2524.4304\n",
      "Epoch 1698/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 98.7612 - val_loss: 2916.2942\n",
      "Epoch 1699/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 67.5880 - val_loss: 2881.7871\n",
      "Epoch 1700/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 59.3014 - val_loss: 2457.3699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1701/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 58.1690 - val_loss: 2545.3770\n",
      "Epoch 1702/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 58.0098 - val_loss: 2449.2544\n",
      "Epoch 1703/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 78.3129 - val_loss: 2679.0830\n",
      "Epoch 1704/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 71.5552 - val_loss: 2570.9678\n",
      "Epoch 1705/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 57.9617 - val_loss: 2545.4133\n",
      "Epoch 1706/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 67.2725 - val_loss: 2467.3730\n",
      "Epoch 1707/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 86.1544 - val_loss: 2317.8335\n",
      "Epoch 1708/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 77.0264 - val_loss: 2803.6765\n",
      "Epoch 1709/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 72.9875 - val_loss: 2314.0981\n",
      "Epoch 1710/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 75.8262 - val_loss: 2691.5911\n",
      "Epoch 1711/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 75.5354 - val_loss: 2575.3074\n",
      "Epoch 1712/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 77.2988 - val_loss: 2386.7471\n",
      "Epoch 1713/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 150.2305 - val_loss: 1453.4912\n",
      "Epoch 1714/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 127.1095 - val_loss: 2104.3123\n",
      "Epoch 1715/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 107.8135 - val_loss: 2032.4014\n",
      "Epoch 1716/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 156.8826 - val_loss: 2334.2549\n",
      "Epoch 1717/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 113.7653 - val_loss: 2676.8867\n",
      "Epoch 1718/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 97.5583 - val_loss: 2370.5647\n",
      "Epoch 1719/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 89.4528 - val_loss: 2457.3796\n",
      "Epoch 1720/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 107.7659 - val_loss: 2428.8394\n",
      "Epoch 1721/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 87.0316 - val_loss: 2467.4395\n",
      "Epoch 1722/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 79.4662 - val_loss: 2444.5547\n",
      "Epoch 1723/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 80.4857 - val_loss: 2466.3164\n",
      "Epoch 1724/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 405.6398 - val_loss: 3518.6245\n",
      "Epoch 1725/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 641.2787 - val_loss: 1584.5720\n",
      "Epoch 1726/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 556.5609 - val_loss: 1379.9000\n",
      "Epoch 1727/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 770.7278 - val_loss: 1155.6982\n",
      "Epoch 1728/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 630.8437 - val_loss: 1823.6898\n",
      "Epoch 1729/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 476.3177 - val_loss: 2284.6492\n",
      "Epoch 1730/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 421.8807 - val_loss: 2041.4369\n",
      "Epoch 1731/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 300.7391 - val_loss: 2427.3547\n",
      "Epoch 1732/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 349.3719 - val_loss: 2516.1130\n",
      "Epoch 1733/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 275.7801 - val_loss: 2548.0991\n",
      "Epoch 1734/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 242.4711 - val_loss: 2037.5607\n",
      "Epoch 1735/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 180.1284 - val_loss: 2455.7764\n",
      "Epoch 1736/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 166.3741 - val_loss: 2194.5554\n",
      "Epoch 1737/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 145.1830 - val_loss: 2328.2688\n",
      "Epoch 1738/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 129.1773 - val_loss: 2371.1768\n",
      "Epoch 1739/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 124.9918 - val_loss: 2525.3079\n",
      "Epoch 1740/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 126.5363 - val_loss: 2550.3809\n",
      "Epoch 1741/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 125.3963 - val_loss: 2344.6763\n",
      "Epoch 1742/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 127.2165 - val_loss: 2358.1140\n",
      "Epoch 1743/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 97.6310 - val_loss: 2370.2483\n",
      "Epoch 1744/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 87.7829 - val_loss: 2302.5203\n",
      "Epoch 1745/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 80.7201 - val_loss: 2173.9421\n",
      "Epoch 1746/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 74.5620 - val_loss: 2224.7920\n",
      "Epoch 1747/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 85.2291 - val_loss: 2296.7629\n",
      "Epoch 1748/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 105.6077 - val_loss: 2233.9951\n",
      "Epoch 1749/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 89.1740 - val_loss: 2437.7222\n",
      "Epoch 1750/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 95.2414 - val_loss: 2266.9199\n",
      "Epoch 1751/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 112.8715 - val_loss: 2104.6589\n",
      "Epoch 1752/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 94.0209 - val_loss: 2180.1809\n",
      "Epoch 1753/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 93.1022 - val_loss: 2356.6284\n",
      "Epoch 1754/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 100.6028 - val_loss: 2432.6379\n",
      "Epoch 1755/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 83.8828 - val_loss: 2271.7637\n",
      "Epoch 1756/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 174.8844 - val_loss: 2161.6953\n",
      "Epoch 1757/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 111.5021 - val_loss: 2538.5398\n",
      "Epoch 1758/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 88.2779 - val_loss: 2279.9243\n",
      "Epoch 1759/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 73.2015 - val_loss: 2443.4194\n",
      "Epoch 1760/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 63.0739 - val_loss: 2395.4224\n",
      "Epoch 1761/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 68.6312 - val_loss: 2237.9246\n",
      "Epoch 1762/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 55.6293 - val_loss: 2299.5488\n",
      "Epoch 1763/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 50.0416 - val_loss: 2251.9697\n",
      "Epoch 1764/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 51.8437 - val_loss: 2116.4250\n",
      "Epoch 1765/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 66.6028 - val_loss: 2394.1011\n",
      "Epoch 1766/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 69.7604 - val_loss: 2461.5759\n",
      "Epoch 1767/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 63.8828 - val_loss: 2254.8445\n",
      "Epoch 1768/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 60.7524 - val_loss: 2481.7488\n",
      "Epoch 1769/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 61.7642 - val_loss: 2431.5352\n",
      "Epoch 1770/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 76.4082 - val_loss: 2347.0239\n",
      "Epoch 1771/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 65.1891 - val_loss: 2364.6755\n",
      "Epoch 1772/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 48.3777 - val_loss: 2442.4177\n",
      "Epoch 1773/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 45.8466 - val_loss: 2237.1277\n",
      "Epoch 1774/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 41.6235 - val_loss: 2397.4495\n",
      "Epoch 1775/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 39.1109 - val_loss: 2343.7231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1776/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 41.1827 - val_loss: 2411.3701\n",
      "Epoch 1777/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 57.2128 - val_loss: 2414.5906\n",
      "Epoch 1778/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 49.6344 - val_loss: 2213.6567\n",
      "Epoch 1779/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 43.4126 - val_loss: 2616.8337\n",
      "Epoch 1780/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 48.0848 - val_loss: 2358.8223\n",
      "Epoch 1781/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 40.4928 - val_loss: 2176.0527\n",
      "Epoch 1782/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 46.0629 - val_loss: 2354.1526\n",
      "Epoch 1783/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 54.5924 - val_loss: 2282.0195\n",
      "Epoch 1784/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 58.4580 - val_loss: 2406.8938\n",
      "Epoch 1785/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 50.1689 - val_loss: 2485.4629\n",
      "Epoch 1786/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 50.6206 - val_loss: 2422.6160\n",
      "Epoch 1787/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 44.4232 - val_loss: 2459.4031\n",
      "Epoch 1788/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 36.8205 - val_loss: 2347.5312\n",
      "Epoch 1789/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 45.0270 - val_loss: 2283.8379\n",
      "Epoch 1790/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 39.5249 - val_loss: 2328.4875\n",
      "Epoch 1791/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 71.7747 - val_loss: 2547.3665\n",
      "Epoch 1792/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 71.9113 - val_loss: 2918.3242\n",
      "Epoch 1793/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 88.6225 - val_loss: 2189.7766\n",
      "Epoch 1794/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 84.8989 - val_loss: 1902.4375\n",
      "Epoch 1795/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 77.6728 - val_loss: 2372.7549\n",
      "Epoch 1796/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 59.6107 - val_loss: 2300.1084\n",
      "Epoch 1797/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 88.3060 - val_loss: 2201.8108\n",
      "Epoch 1798/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 87.8584 - val_loss: 2548.4172\n",
      "Epoch 1799/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 69.4410 - val_loss: 2406.7090\n",
      "Epoch 1800/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 77.0989 - val_loss: 2421.1541\n",
      "Epoch 1801/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 81.4045 - val_loss: 2602.9736\n",
      "Epoch 1802/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 79.1069 - val_loss: 2447.7598\n",
      "Epoch 1803/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 73.1554 - val_loss: 2549.2827\n",
      "Epoch 1804/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 66.7187 - val_loss: 2369.9014\n",
      "Epoch 1805/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 46.9192 - val_loss: 2596.0857\n",
      "Epoch 1806/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 53.1083 - val_loss: 2400.3152\n",
      "Epoch 1807/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 44.9854 - val_loss: 2309.0369\n",
      "Epoch 1808/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 41.3336 - val_loss: 2483.9553\n",
      "Epoch 1809/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 43.1604 - val_loss: 2312.2156\n",
      "Epoch 1810/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 38.5439 - val_loss: 2373.8171\n",
      "Epoch 1811/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 54.0842 - val_loss: 2667.6177\n",
      "Epoch 1812/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 57.1837 - val_loss: 2295.1072\n",
      "Epoch 1813/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 50.1509 - val_loss: 2324.7969\n",
      "Epoch 1814/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 53.9501 - val_loss: 2809.5715\n",
      "Epoch 1815/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 59.2516 - val_loss: 2672.8662\n",
      "Epoch 1816/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 49.8158 - val_loss: 2382.7759\n",
      "Epoch 1817/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 50.6382 - val_loss: 2396.0151\n",
      "Epoch 1818/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 47.6458 - val_loss: 2269.4402\n",
      "Epoch 1819/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 42.3715 - val_loss: 2450.1550\n",
      "Epoch 1820/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 42.4825 - val_loss: 2193.1157\n",
      "Epoch 1821/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 47.1578 - val_loss: 2359.4446\n",
      "Epoch 1822/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 56.0432 - val_loss: 2380.4304\n",
      "Epoch 1823/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 38.3368 - val_loss: 2417.7808\n",
      "Epoch 1824/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 34.4650 - val_loss: 2511.5686\n",
      "Epoch 1825/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 50.1476 - val_loss: 2420.4460\n",
      "Epoch 1826/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 37.3440 - val_loss: 2273.6318\n",
      "Epoch 1827/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 36.8030 - val_loss: 2429.7024\n",
      "Epoch 1828/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 32.1214 - val_loss: 2344.5115\n",
      "Epoch 1829/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 28.2692 - val_loss: 2419.2122\n",
      "Epoch 1830/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 27.8318 - val_loss: 2322.3730\n",
      "Epoch 1831/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 27.1565 - val_loss: 2448.0090\n",
      "Epoch 1832/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 31.0575 - val_loss: 2434.0986\n",
      "Epoch 1833/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 37.1128 - val_loss: 2465.2920\n",
      "Epoch 1834/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 31.3002 - val_loss: 2477.4451\n",
      "Epoch 1835/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 32.3237 - val_loss: 2532.1167\n",
      "Epoch 1836/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 34.1070 - val_loss: 2288.5083\n",
      "Epoch 1837/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 44.2209 - val_loss: 2399.9097\n",
      "Epoch 1838/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 46.9553 - val_loss: 2707.3538\n",
      "Epoch 1839/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 59.5191 - val_loss: 2600.5190\n",
      "Epoch 1840/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 48.4967 - val_loss: 2460.8157\n",
      "Epoch 1841/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 44.8017 - val_loss: 2509.4531\n",
      "Epoch 1842/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 40.2309 - val_loss: 2306.8210\n",
      "Epoch 1843/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 37.0702 - val_loss: 2350.8438\n",
      "Epoch 1844/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 36.6951 - val_loss: 2426.9541\n",
      "Epoch 1845/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 41.2712 - val_loss: 2476.2622\n",
      "Epoch 1846/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 43.3111 - val_loss: 2509.6155\n",
      "Epoch 1847/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 40.9350 - val_loss: 2338.1831\n",
      "Epoch 1848/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 49.5438 - val_loss: 2587.3574\n",
      "Epoch 1849/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 42.9336 - val_loss: 2475.9116\n",
      "Epoch 1850/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 40.2225 - val_loss: 2457.1868\n",
      "Epoch 1851/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 40.4296 - val_loss: 2225.0100\n",
      "Epoch 1852/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 47.4117 - val_loss: 2824.8296\n",
      "Epoch 1853/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 41.9443 - val_loss: 2507.3210\n",
      "Epoch 1854/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 38.0463 - val_loss: 2536.2217\n",
      "Epoch 1855/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 33.9841 - val_loss: 2692.7847\n",
      "Epoch 1856/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 36.6789 - val_loss: 2548.1587\n",
      "Epoch 1857/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 29.4076 - val_loss: 2585.6184\n",
      "Epoch 1858/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 24.3873 - val_loss: 2744.3840\n",
      "Epoch 1859/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 26.2610 - val_loss: 2541.6919\n",
      "Epoch 1860/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 22.9101 - val_loss: 2572.0789\n",
      "Epoch 1861/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 28.4994 - val_loss: 2596.5605\n",
      "Epoch 1862/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 23.8746 - val_loss: 2376.9814\n",
      "Epoch 1863/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 31.8399 - val_loss: 2499.2419\n",
      "Epoch 1864/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 22.7565 - val_loss: 2594.2012\n",
      "Epoch 1865/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 25.1530 - val_loss: 2326.5576\n",
      "Epoch 1866/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 25.3312 - val_loss: 2453.4680\n",
      "Epoch 1867/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 27.3710 - val_loss: 2521.2070\n",
      "Epoch 1868/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 41.9951 - val_loss: 2315.2937\n",
      "Epoch 1869/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 47.2837 - val_loss: 2485.5107\n",
      "Epoch 1870/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 60.4707 - val_loss: 2050.9785\n",
      "Epoch 1871/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 50.1021 - val_loss: 2155.2434\n",
      "Epoch 1872/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 41.7409 - val_loss: 2166.3301\n",
      "Epoch 1873/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 40.9792 - val_loss: 2411.6763\n",
      "Epoch 1874/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 38.9598 - val_loss: 2349.3223\n",
      "Epoch 1875/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 38.3763 - val_loss: 2226.1672\n",
      "Epoch 1876/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 43.2302 - val_loss: 2403.3479\n",
      "Epoch 1877/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 50.4039 - val_loss: 2263.5701\n",
      "Epoch 1878/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 73.7411 - val_loss: 2286.5999\n",
      "Epoch 1879/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 91.5158 - val_loss: 2541.7214\n",
      "Epoch 1880/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 72.0739 - val_loss: 2353.7195\n",
      "Epoch 1881/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 60.2120 - val_loss: 2106.2556\n",
      "Epoch 1882/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 47.3067 - val_loss: 2443.6335\n",
      "Epoch 1883/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 69.0461 - val_loss: 2582.7988\n",
      "Epoch 1884/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 59.5522 - val_loss: 2648.0508\n",
      "Epoch 1885/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 34.6847 - val_loss: 2642.7061\n",
      "Epoch 1886/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 54.6168 - val_loss: 2487.6694\n",
      "Epoch 1887/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 42.2516 - val_loss: 2404.9761\n",
      "Epoch 1888/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 51.8651 - val_loss: 2496.1013\n",
      "Epoch 1889/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 55.6638 - val_loss: 2241.8257\n",
      "Epoch 1890/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 51.2417 - val_loss: 2452.3696\n",
      "Epoch 1891/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 70.2433 - val_loss: 2256.5901\n",
      "Epoch 1892/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 88.9938 - val_loss: 2640.4004\n",
      "Epoch 1893/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 55.6563 - val_loss: 2235.4946\n",
      "Epoch 1894/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 44.3886 - val_loss: 2100.5581\n",
      "Epoch 1895/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 44.4233 - val_loss: 2321.3936\n",
      "Epoch 1896/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 60.4032 - val_loss: 2424.6543\n",
      "Epoch 1897/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 51.5107 - val_loss: 2355.1958\n",
      "Epoch 1898/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 35.3383 - val_loss: 2480.9141\n",
      "Epoch 1899/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 42.8702 - val_loss: 2447.8926\n",
      "Epoch 1900/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 51.0362 - val_loss: 2396.9497\n",
      "Epoch 1901/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 46.5526 - val_loss: 2134.3848\n",
      "Epoch 1902/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 46.4147 - val_loss: 2909.6304\n",
      "Epoch 1903/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 281.3638 - val_loss: 2723.3660\n",
      "Epoch 1904/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 282.9015 - val_loss: 2363.2625\n",
      "Epoch 1905/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 189.8915 - val_loss: 2306.6140\n",
      "Epoch 1906/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 285.6783 - val_loss: 1491.6492\n",
      "Epoch 1907/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 424.1057 - val_loss: 2778.3606\n",
      "Epoch 1908/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 464.4577 - val_loss: 2170.0989\n",
      "Epoch 1909/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 359.7916 - val_loss: 1850.0393\n",
      "Epoch 1910/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 471.7398 - val_loss: 2333.4102\n",
      "Epoch 1911/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 371.0032 - val_loss: 2578.2886\n",
      "Epoch 1912/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 264.1076 - val_loss: 2354.5449\n",
      "Epoch 1913/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 205.3354 - val_loss: 2049.9226\n",
      "Epoch 1914/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 178.5951 - val_loss: 2363.4314\n",
      "Epoch 1915/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 129.1274 - val_loss: 2133.4363\n",
      "Epoch 1916/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 84.8552 - val_loss: 2287.0762\n",
      "Epoch 1917/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 78.3971 - val_loss: 2250.2544\n",
      "Epoch 1918/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 72.8670 - val_loss: 2282.6309\n",
      "Epoch 1919/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 61.5306 - val_loss: 2081.4309\n",
      "Epoch 1920/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 54.8930 - val_loss: 2223.9805\n",
      "Epoch 1921/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 52.3970 - val_loss: 2306.9382\n",
      "Epoch 1922/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 54.7642 - val_loss: 2229.5098\n",
      "Epoch 1923/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 56.5185 - val_loss: 2291.2625\n",
      "Epoch 1924/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 49.3168 - val_loss: 2296.5317\n",
      "Epoch 1925/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 50.8214 - val_loss: 2243.6289\n",
      "Epoch 1926/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 [==============================] - 0s 1ms/step - loss: 44.9717 - val_loss: 2313.3433\n",
      "Epoch 1927/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 40.7045 - val_loss: 2189.8391\n",
      "Epoch 1928/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 37.4626 - val_loss: 2315.0137\n",
      "Epoch 1929/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 35.5484 - val_loss: 2289.0037\n",
      "Epoch 1930/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 33.8950 - val_loss: 2467.3757\n",
      "Epoch 1931/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 31.4986 - val_loss: 2363.3035\n",
      "Epoch 1932/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 27.2913 - val_loss: 2344.8821\n",
      "Epoch 1933/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 28.2955 - val_loss: 2423.2896\n",
      "Epoch 1934/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 29.9729 - val_loss: 2395.0449\n",
      "Epoch 1935/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 41.5910 - val_loss: 2510.2261\n",
      "Epoch 1936/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 34.8393 - val_loss: 2587.5630\n",
      "Epoch 1937/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 47.3380 - val_loss: 2505.4280\n",
      "Epoch 1938/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 43.0239 - val_loss: 2559.0396\n",
      "Epoch 1939/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 35.8611 - val_loss: 2649.2297\n",
      "Epoch 1940/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 29.2290 - val_loss: 2716.5999\n",
      "Epoch 1941/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 29.7779 - val_loss: 2664.4724\n",
      "Epoch 1942/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 31.6462 - val_loss: 2382.1399\n",
      "Epoch 1943/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 32.7918 - val_loss: 2586.8821\n",
      "Epoch 1944/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 27.4843 - val_loss: 2617.4553\n",
      "Epoch 1945/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 25.7564 - val_loss: 2702.4822\n",
      "Epoch 1946/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 25.5617 - val_loss: 2676.3320\n",
      "Epoch 1947/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 24.3595 - val_loss: 2667.8870\n",
      "Epoch 1948/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 25.5453 - val_loss: 2563.5239\n",
      "Epoch 1949/2000\n",
      "164/164 [==============================] - 0s 2ms/step - loss: 20.5314 - val_loss: 2562.0195\n",
      "Epoch 1950/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 27.4899 - val_loss: 2685.5708\n",
      "Epoch 1951/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 23.0690 - val_loss: 2559.5256\n",
      "Epoch 1952/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 28.8241 - val_loss: 2603.2559\n",
      "Epoch 1953/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 28.4103 - val_loss: 2743.6130\n",
      "Epoch 1954/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 33.2744 - val_loss: 2533.0601\n",
      "Epoch 1955/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 66.4414 - val_loss: 2719.5081\n",
      "Epoch 1956/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 70.0750 - val_loss: 2258.3059\n",
      "Epoch 1957/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 59.2180 - val_loss: 2467.9890\n",
      "Epoch 1958/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 158.1556 - val_loss: 2547.8652\n",
      "Epoch 1959/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 82.3232 - val_loss: 2122.0500\n",
      "Epoch 1960/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 103.6204 - val_loss: 2543.0723\n",
      "Epoch 1961/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 473.1404 - val_loss: 2070.9419\n",
      "Epoch 1962/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 747.7195 - val_loss: 2084.7114\n",
      "Epoch 1963/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 646.6074 - val_loss: 2690.6665\n",
      "Epoch 1964/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 496.2755 - val_loss: 2174.4199\n",
      "Epoch 1965/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 488.9873 - val_loss: 2681.8569\n",
      "Epoch 1966/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 355.7949 - val_loss: 2386.1636\n",
      "Epoch 1967/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 392.7689 - val_loss: 3199.7595\n",
      "Epoch 1968/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 377.0579 - val_loss: 1824.0303\n",
      "Epoch 1969/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 311.6966 - val_loss: 2545.4802\n",
      "Epoch 1970/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 270.4219 - val_loss: 1947.6737\n",
      "Epoch 1971/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 220.0063 - val_loss: 2524.5669\n",
      "Epoch 1972/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 147.7907 - val_loss: 2197.4709\n",
      "Epoch 1973/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 153.3569 - val_loss: 2617.9082\n",
      "Epoch 1974/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 131.8776 - val_loss: 2180.1909\n",
      "Epoch 1975/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 152.6697 - val_loss: 2624.4001\n",
      "Epoch 1976/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 160.6239 - val_loss: 1996.9696\n",
      "Epoch 1977/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 112.7814 - val_loss: 2380.1328\n",
      "Epoch 1978/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 94.7064 - val_loss: 2279.6309\n",
      "Epoch 1979/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 98.1827 - val_loss: 2237.4717\n",
      "Epoch 1980/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 85.9009 - val_loss: 2427.4478\n",
      "Epoch 1981/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 106.4300 - val_loss: 2570.7659\n",
      "Epoch 1982/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 81.9595 - val_loss: 2115.0957\n",
      "Epoch 1983/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 87.1653 - val_loss: 2067.8979\n",
      "Epoch 1984/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 74.8900 - val_loss: 2293.9827\n",
      "Epoch 1985/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 65.3656 - val_loss: 2430.2036\n",
      "Epoch 1986/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 72.2901 - val_loss: 2601.8289\n",
      "Epoch 1987/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 62.6953 - val_loss: 2497.0374\n",
      "Epoch 1988/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 58.3238 - val_loss: 2419.3359\n",
      "Epoch 1989/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 57.8747 - val_loss: 2311.9565\n",
      "Epoch 1990/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 56.3202 - val_loss: 2127.0652\n",
      "Epoch 1991/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 68.1899 - val_loss: 2048.0681\n",
      "Epoch 1992/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 72.4228 - val_loss: 2055.2063\n",
      "Epoch 1993/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 61.1876 - val_loss: 2233.7688\n",
      "Epoch 1994/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 51.5365 - val_loss: 2206.9946\n",
      "Epoch 1995/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 50.5458 - val_loss: 2218.1404\n",
      "Epoch 1996/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 40.4305 - val_loss: 2399.3208\n",
      "Epoch 1997/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 42.2424 - val_loss: 2295.4412\n",
      "Epoch 1998/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 37.8736 - val_loss: 2503.6987\n",
      "Epoch 1999/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 36.6771 - val_loss: 2412.3613\n",
      "Epoch 2000/2000\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 30.6248 - val_loss: 2252.8071\n",
      "Training Model took:  402.879088640213\n"
     ]
    }
   ],
   "source": [
    "#import tensorflow as tf\n",
    "d = 0.01\n",
    "model = Sequential()\n",
    "input_shape=(101,29)\n",
    "model.add(Bidirectional(GRU(64, input_shape=(101,29), return_sequences=False)))\n",
    "model.add(Dropout(d))\n",
    "model.add(SelfAttention(64))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(SelfAttention(32))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(SelfAttention(32))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(SelfAttention(16))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(SelfAttention(16))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(SelfAttention(8))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(SelfAttention(8))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(SelfAttention(4))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(SelfAttention(4))\n",
    "model.add(Dense(2, activation='relu'))\n",
    "model.add(SelfAttention(2))\n",
    "model.add(Dense(2, activation='relu'))\n",
    "model.add(SelfAttention(2))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "#model = load_model('C:/Users/Danny Lee/Desktop/motion hw/final/LSTM model performance/try_best_nodropout/Regression.h5')\n",
    "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss='mean_squared_error', optimizer= opt)\n",
    "start_fitting = time.time()\n",
    "#model.load_weights('C:/Users/Danny Lee/Desktop/motion hw/final/LSTM model performance/try_best_nodropout/Regression_weights.h5'.encode('utf-8'))\n",
    "#model = tf.keras.models.load_model('C:/Users/Danny Lee/Desktop/motion hw/final/LSTM model performance/try_best_nodropout/Regression_weights.h5')\n",
    "model.fit(X_train, y_train, epochs=2000, batch_size=32,validation_data=(X_val, y_val))\n",
    "fitting_model_time = time.time()\n",
    "print('Training Model took: ', fitting_model_time - start_fitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66f013a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_1 (Bidirection (None, 128)               36096     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "self_attention_1 (SelfAttent (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "self_attention_2 (SelfAttent (None, 32)                1088      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "self_attention_3 (SelfAttent (None, 32)                1088      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "self_attention_4 (SelfAttent (None, 16)                288       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "self_attention_5 (SelfAttent (None, 16)                288       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "self_attention_6 (SelfAttent (None, 8)                 80        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "self_attention_7 (SelfAttent (None, 8)                 80        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "self_attention_8 (SelfAttent (None, 4)                 24        \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "self_attention_9 (SelfAttent (None, 4)                 24        \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "self_attention_10 (SelfAtten (None, 2)                 8         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "self_attention_11 (SelfAtten (None, 2)                 8         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 53,659\n",
      "Trainable params: 53,659\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.build(input_shape)\n",
    "print(model.summary())\n",
    "with open('./LSTM model performance/try_0612_dropout/modelsummary.txt', 'w') as f:\n",
    "\n",
    "    model.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
    "\n",
    "#earlystopping\n",
    "#monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=50, verbose=2, mode='auto', restore_best_weights=True)\n",
    "#model.fit(X_train, y_train, nb_epoch = 1000, batch_size = 32,validation_data=(X_val, y_val),callbacks=[monitor]) #训练模型1000次\n",
    "#epochxxx =  monitor.stopped_epoch+1   #len(model.history.history['loss'])\n",
    "#print(epochxxx)    \n",
    "\n",
    "#保存模型和權重\n",
    "saved = model.save('./LSTM model performance/try_0612_dropout/Regression.h5')    \n",
    "model.save_weights('./LSTM model performance/try_0612_dropout/Regression_weights.h5')  # to store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cea8a172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#画出迭代loss和acc曲线\n",
    "pd.DataFrame(model.history.history).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f19d61aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16484\\1431047897.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#在训练集上的拟合结果\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0my_train_predict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0my_train_predict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train_predict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "#在训练集上的拟合结果\n",
    "\n",
    "y_train_predict=model.predict(X_train)\n",
    "y_train_predict=y_train_predict[:,0]\n",
    "\n",
    "\n",
    "plt.plot(y_train, label='True Values')\n",
    "plt.plot(y_train_predict, label='Predictions')\n",
    "plt.xlabel('Training Data')\n",
    "plt.ylabel('Value(mm)')\n",
    "plt.title('True Values vs Predictions')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "'''\n",
    "draw=pd.concat([pd.DataFrame(y_train),pd.DataFrame(y_train_predict)],axis=1)\n",
    "draw.iloc[100:150,0].plot(figsize=(12,6))\n",
    "draw.iloc[100:150,1].plot(figsize=(12,6))\n",
    "plt.legend(('real', 'predict'),fontsize='15')\n",
    "plt.title(\"Training Data\",fontsize='30') #添加标题\n",
    "#plt.show()\n",
    "#fig.savefig('./LSTM model performance/Regression_heel_test/train_Validation_loss.png')\n",
    "#展示在训练集上的表现 \n",
    "'''\n",
    "'''\n",
    "epocha=range(len(y_train))\n",
    "epochb=range(len(y_train_predict))\n",
    "plt.plot(epocha, y_train, 'g', label='real')\n",
    "plt.plot(epochb, y_train_predict, 'b', label='predict')\n",
    "plt.legend(('real', 'predict'),fontsize='15')\n",
    "plt.title(\"Train Data\",fontsize='30') #添加标题\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f005cd15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e67779",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07dc0c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\nepochc=range(len(y_test))\\nepochd=range(len(y_test_predict))\\n\\nplt.plot(epochc, y_test, \\'g\\', label=\\'real\\')\\nplt.plot(epochd, y_test_predict, \\'b\\', label=\\'predict\\')\\nplt.title(\"Test Data\",fontsize=\\'30\\') #添加标题\\nplt.legend((\\'real\\', \\'predict\\'),loc=\\'upper right\\',fontsize=\\'15\\')\\nplt.show()\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_predict=model.predict(X_test)\n",
    "y_test_predict=y_test_predict[:,0]\n",
    "# Plot the true values and predictions\n",
    "plt.plot(y_test, label='True Values')\n",
    "plt.plot(y_test_predict, label='Predictions')\n",
    "plt.xlabel('Testing Data')\n",
    "plt.ylabel('Value(mm)')\n",
    "plt.title('True Values vs Predictions')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "'''\n",
    "#在测试集上的预测\n",
    "y_test_predict=model.predict(X_test)\n",
    "y_test_predict=y_test_predict[:,0]\n",
    "draw=pd.concat([pd.DataFrame(y_test),pd.DataFrame(y_test_predict)],axis=1);\n",
    "draw.iloc[200:250,0].plot(figsize=(12,6))\n",
    "draw.iloc[200:250,1].plot(figsize=(12,6))\n",
    "plt.legend(('real', 'predict'),loc='upper right',fontsize='15')\n",
    "plt.title(\"Test Data\",fontsize='30') #添加标题\n",
    "#展示在测试集上的表现 \n",
    "\n",
    "y_test_predict = model.predict(X_test).flatten()\n",
    "y_test_predict=y_test_predict[:,0]\n",
    "a = plt.axes(aspect='equal')\n",
    "plt.scatter(y_test, y_test_predict)\n",
    "plt.xlabel('True Values [MPG]')\n",
    "plt.ylabel('Predictions [MPG]')\n",
    "lims = [0, 100]\n",
    "plt.xlim(lims)\n",
    "plt.ylim(lims)\n",
    "_ = plt.plot(lims, lims)\n",
    "'''\n",
    "'''\n",
    "epochc=range(len(y_test))\n",
    "epochd=range(len(y_test_predict))\n",
    "\n",
    "plt.plot(epochc, y_test, 'g', label='real')\n",
    "plt.plot(epochd, y_test_predict, 'b', label='predict')\n",
    "plt.title(\"Test Data\",fontsize='30') #添加标题\n",
    "plt.legend(('real', 'predict'),loc='upper right',fontsize='15')\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca6cf74d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練集上的MAE/MSE/MAPE\n",
      "4.233958471141748\n",
      "38.67353497459289\n",
      "2.616606989869932\n",
      "測試集上的MAE/MSE/MAPE\n",
      "32.53770780442721\n",
      "1477.621822486476\n",
      "19.37228165886674\n",
      "預測漲跌正確: 0.65\n",
      "Training Model took:  402.879088640213\n",
      "TOTAL time spent 701.3327374458313\n"
     ]
    }
   ],
   "source": [
    "#輸出结果\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "def mape(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_pred - y_true) / y_true)) * 100\n",
    "print('訓練集上的MAE/MSE/MAPE')\n",
    "print(mean_absolute_error(y_train_predict, y_train))\n",
    "print(mean_squared_error(y_train_predict, y_train) )\n",
    "print(mape(y_train_predict, y_train) )\n",
    "print('測試集上的MAE/MSE/MAPE')\n",
    "print(mean_absolute_error(y_test_predict, y_test))\n",
    "print(mean_squared_error(y_test_predict, y_test) )\n",
    "print(mape(y_test_predict,  y_test) )\n",
    "y_var_test=y_test[1:]-y_test[:len(y_test)-1]\n",
    "y_var_predict=y_test_predict[1:]-y_test_predict[:len(y_test_predict)-1]\n",
    "txt=np.zeros(len(y_var_test))\n",
    "for i in range(len(y_var_test-1)):\n",
    "    txt[i]=np.sign(y_var_test[i])==np.sign(y_var_predict[i])\n",
    "result=sum(txt)/len(txt)\n",
    "print('預測漲跌正確:',result)\n",
    "print('Training Model took: ', fitting_model_time - start_fitting)\n",
    "#print('训练时间（秒）:',54.56)\n",
    "\n",
    "end = time.time()\n",
    "print('TOTAL time spent', end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d8642d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
