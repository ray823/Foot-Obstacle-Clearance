{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0feb1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "#import sympy as sp\n",
    "import random\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import scipy.io\n",
    "from mat4py import loadmat\n",
    "import keras\n",
    "from keras.callbacks import History,EarlyStopping\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.recurrent import GRU\n",
    "from keras.layers import Bidirectional\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.layers import Reshape\n",
    "import time\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45844247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E01\\OC10\\Trial40\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E01\\OC10\\Trial41\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E01\\OC10\\Trial49\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E01\\OC10\\Trial50\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E01\\OC20\\Trial100\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E01\\OC20\\Trial109\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E01\\OC20\\Trial110\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E01\\OC20\\Trial99\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E01\\OC30\\Trial113\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E01\\OC30\\Trial114\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E01\\OC30\\Trial116\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E01\\OC30\\Trial121\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E02\\OC10\\Trial110\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E02\\OC10\\Trial111\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E02\\OC10\\Trial115\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E02\\OC10\\Trial116\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E02\\OC20\\Trial152\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E02\\OC20\\Trial153\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E02\\OC20\\Trial157\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E02\\OC20\\Trial158\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E02\\OC30\\Trial173\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E02\\OC30\\Trial174\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E02\\OC30\\Trial177\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E02\\OC30\\Trial178\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E03\\OC10\\Trial20\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E03\\OC10\\Trial21\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E03\\OC10\\Trial25\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E03\\OC10\\Trial26\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E03\\OC20\\Trial71\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E03\\OC20\\Trial72\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E03\\OC20\\Trial77\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E03\\OC20\\Trial78\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E03\\OC30\\Trial81\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E03\\OC30\\Trial82\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E03\\OC30\\Trial87\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E03\\OC30\\Trial88\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E04\\OC10\\Trial45\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E04\\OC10\\Trial46\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E04\\OC10\\Trial50\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E04\\OC10\\Trial52\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E04\\OC20\\Trial70\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E04\\OC20\\Trial71\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E04\\OC20\\Trial74\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E04\\OC20\\Trial75\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E04\\OC30\\Trial90\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E04\\OC30\\Trial91\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E04\\OC30\\Trial98\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E04\\OC30\\Trial99\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E05\\OC10\\Trial41\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E05\\OC10\\Trial42\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E05\\OC10\\Trial45\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E05\\OC10\\Trial46\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E05\\OC20\\Trial81\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E05\\OC20\\Trial82\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E05\\OC20\\Trial86\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E05\\OC20\\Trial87\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E05\\OC30\\Trial110\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E05\\OC30\\Trial111\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E05\\OC30\\Trial114\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E05\\OC30\\Trial115\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E06\\OC10\\Trial24\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E06\\OC10\\Trial25\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E06\\OC10\\Trial30\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E06\\OC10\\Trial32\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E06\\OC20\\Trial72\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E06\\OC20\\Trial74\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E06\\OC20\\Trial76\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E06\\OC20\\Trial77\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E06\\OC30\\Trial130\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E06\\OC30\\Trial132\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E06\\OC30\\Trial138\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E06\\OC30\\Trial142\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E07\\OC10\\Trial46\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E07\\OC10\\Trial47\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E07\\OC10\\Trial48\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E07\\OC10\\Trial50\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E07\\OC20\\Trial67\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E07\\OC20\\Trial69\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E07\\OC20\\Trial73\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E07\\OC20\\Trial75\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E07\\OC30\\Trial100\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E07\\OC30\\Trial104\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E07\\OC30\\Trial105\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E07\\OC30\\Trial97\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E09\\OC10\\Trial54\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E09\\OC10\\Trial55\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E09\\OC10\\Trial56\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E09\\OC10\\Trial60\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E09\\OC20\\Trial78\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E09\\OC20\\Trial81\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E09\\OC20\\Trial83\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E09\\OC20\\Trial88\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E09\\OC30\\Trial102\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E09\\OC30\\Trial105\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E09\\OC30\\Trial111\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E09\\OC30\\Trial112\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E10\\OC10\\Trial55\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E10\\OC10\\Trial56\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E10\\OC10\\Trial58\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E10\\OC10\\Trial60\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E10\\OC20\\Trial85\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E10\\OC20\\Trial87\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E10\\OC20\\Trial92\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E10\\OC20\\Trial93\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E10\\OC30\\Trial110\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E10\\OC30\\Trial112\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E10\\OC30\\Trial120\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E10\\OC30\\Trial122\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E11\\OC10\\Trial47\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E11\\OC10\\Trial48\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E11\\OC10\\Trial55\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E11\\OC10\\Trial56\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E11\\OC20\\Trial70\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E11\\OC20\\Trial71\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E11\\OC20\\Trial74\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E11\\OC20\\Trial75\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E11\\OC30\\Trial127\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E11\\OC30\\Trial128\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E11\\OC30\\Trial134\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E11\\OC30\\Trial135\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E12\\OC10\\Trial27\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E12\\OC10\\Trial30\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E12\\OC10\\Trial34\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E12\\OC10\\Trial35\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E12\\OC20\\Trial101\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E12\\OC20\\Trial82\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E12\\OC20\\Trial94\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E12\\OC20\\Trial96\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E12\\OC30\\Trial121\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E12\\OC30\\Trial122\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E12\\OC30\\Trial123\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E12\\OC30\\Trial126\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E13\\OC10\\Trial49\\Results.mat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E13\\OC10\\Trial50\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E13\\OC10\\Trial52\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E13\\OC10\\Trial54\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E13\\OC20\\Trial87\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E13\\OC20\\Trial88\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E13\\OC20\\Trial90\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E13\\OC20\\Trial91\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E13\\OC30\\Trial107\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E13\\OC30\\Trial108\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E13\\OC30\\Trial113\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E13\\OC30\\Trial116\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E14\\OC10\\Trial48\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E14\\OC10\\Trial49\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E14\\OC10\\Trial50\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E14\\OC10\\Trial52\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E14\\OC20\\Trial58\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E14\\OC20\\Trial59\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E14\\OC20\\Trial60\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E14\\OC20\\Trial62\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E14\\OC30\\Trial92\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E14\\OC30\\Trial93\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E14\\OC30\\Trial95\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E14\\OC30\\Trial96\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E15\\OC10\\Trial36\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E15\\OC10\\Trial38\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E15\\OC10\\Trial39\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E15\\OC10\\Trial45\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E15\\OC20\\Trial59\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E15\\OC20\\Trial60\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E15\\OC20\\Trial65\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E15\\OC20\\Trial66\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E15\\OC30\\Trial111\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E15\\OC30\\Trial112\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E15\\OC30\\Trial115\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E15\\OC30\\Trial117\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E16\\OC10\\Trial36\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E16\\OC10\\Trial37\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E16\\OC10\\Trial39\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E16\\OC10\\Trial40\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E16\\OC20\\Trial72\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E16\\OC20\\Trial73\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E16\\OC20\\Trial79\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E16\\OC20\\Trial80\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E16\\OC30\\Trial122\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E16\\OC30\\Trial123\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E16\\OC30\\Trial126\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E16\\OC30\\Trial128\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E17\\OC10\\Trial50\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E17\\OC10\\Trial52\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E17\\OC10\\Trial54\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E17\\OC10\\Trial57\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E17\\OC20\\Trial74\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E17\\OC20\\Trial75\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E17\\OC20\\Trial80\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E17\\OC20\\Trial81\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E17\\OC30\\Trial127\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E17\\OC30\\Trial129\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E17\\OC30\\Trial138\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E17\\OC30\\Trial139\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E18\\OC10\\Trial73\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E18\\OC10\\Trial74\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E18\\OC10\\Trial77\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E18\\OC10\\Trial87\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E18\\OC20\\Trial100\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E18\\OC20\\Trial97\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E18\\OC20\\Trial98\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E18\\OC20\\Trial99\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E18\\OC30\\Trial162\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E18\\OC30\\Trial163\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E18\\OC30\\Trial164\\Results.mat\n",
      "C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/E18\\OC30\\Trial165\\Results.mat\n",
      "[[[-1.85592973e+01 -1.90803045e+01 -1.87862629e+01 ... -3.76789879e+00\n",
      "   -6.07677844e+00 -7.29325804e+00]\n",
      "  [-3.84781590e+00 -3.20896126e+00 -2.57869571e+00 ... -5.51788470e+00\n",
      "   -4.58697359e+00 -3.49665725e+00]\n",
      "  [-2.93677355e+00 -2.57873037e+00 -2.59398353e+00 ... -1.42303724e+00\n",
      "   -1.92032046e+00 -2.18092033e+00]\n",
      "  ...\n",
      "  [ 2.22474176e+02  2.22474176e+02  2.22474176e+02 ...  2.22474176e+02\n",
      "    2.22474176e+02  2.22474176e+02]\n",
      "  [ 3.32924076e+02  3.32924076e+02  3.32924076e+02 ...  3.32924076e+02\n",
      "    3.32924076e+02  3.32924076e+02]\n",
      "  [ 3.25739195e+02  3.25739195e+02  3.25739195e+02 ...  3.25739195e+02\n",
      "    3.25739195e+02  3.25739195e+02]]\n",
      "\n",
      " [[-9.70035625e+00 -1.00515583e+01 -9.34058876e+00 ... -3.93716714e+00\n",
      "   -6.02556767e+00 -7.27759620e+00]\n",
      "  [-5.75983350e+00 -4.63195053e+00 -4.14533811e+00 ... -6.21241577e+00\n",
      "   -5.67477095e+00 -4.99240690e+00]\n",
      "  [-2.12273165e+00 -2.18466607e+00 -2.01615504e+00 ... -7.76796907e-01\n",
      "   -1.63168535e+00 -2.36125927e+00]\n",
      "  ...\n",
      "  [ 2.22474176e+02  2.22474176e+02  2.22474176e+02 ...  2.22474176e+02\n",
      "    2.22474176e+02  2.22474176e+02]\n",
      "  [ 3.32924076e+02  3.32924076e+02  3.32924076e+02 ...  3.32924076e+02\n",
      "    3.32924076e+02  3.32924076e+02]\n",
      "  [ 3.25739195e+02  3.25739195e+02  3.25739195e+02 ...  3.25739195e+02\n",
      "    3.25739195e+02  3.25739195e+02]]\n",
      "\n",
      " [[-1.15720778e+01 -1.18184826e+01 -1.10173601e+01 ... -3.21166943e+00\n",
      "   -5.00608685e+00 -5.84269981e+00]\n",
      "  [-5.24339811e+00 -4.27596528e+00 -3.80558949e+00 ... -5.52233219e+00\n",
      "   -4.49130297e+00 -3.24554597e+00]\n",
      "  [-9.02272083e-01 -1.40903206e+00 -1.35969266e+00 ... -1.58003337e-01\n",
      "   -7.84037030e-01 -1.17809700e+00]\n",
      "  ...\n",
      "  [ 2.22474176e+02  2.22474176e+02  2.22474176e+02 ...  2.22474176e+02\n",
      "    2.22474176e+02  2.22474176e+02]\n",
      "  [ 3.32924076e+02  3.32924076e+02  3.32924076e+02 ...  3.32924076e+02\n",
      "    3.32924076e+02  3.32924076e+02]\n",
      "  [ 3.25739195e+02  3.25739195e+02  3.25739195e+02 ...  3.25739195e+02\n",
      "    3.25739195e+02  3.25739195e+02]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-2.07408275e+01 -2.09021243e+01 -1.97168390e+01 ... -4.72394034e+00\n",
      "   -1.00307593e+01 -1.46406110e+01]\n",
      "  [ 1.07871773e+01  9.45764403e+00  8.31552635e+00 ...  1.05886919e+01\n",
      "    1.16722240e+01  1.19547547e+01]\n",
      "  [ 7.73964087e+00  6.69745325e+00  5.86342167e+00 ...  3.57434719e+00\n",
      "    5.11534105e+00  6.11314475e+00]\n",
      "  ...\n",
      "  [ 1.93898408e+02  1.93898408e+02  1.93898408e+02 ...  1.93898408e+02\n",
      "    1.93898408e+02  1.93898408e+02]\n",
      "  [ 3.62922007e+02  3.62922007e+02  3.62922007e+02 ...  3.62922007e+02\n",
      "    3.62922007e+02  3.62922007e+02]\n",
      "  [ 3.87272353e+02  3.87272353e+02  3.87272353e+02 ...  3.87272353e+02\n",
      "    3.87272353e+02  3.87272353e+02]]\n",
      "\n",
      " [[-1.28739509e+01 -1.33402629e+01 -1.29871391e+01 ... -2.98799166e+00\n",
      "   -6.31792698e+00 -8.42909099e+00]\n",
      "  [-1.06409276e+01 -8.81700980e+00 -7.02750342e+00 ... -8.11231115e+00\n",
      "   -9.27487174e+00 -9.11097310e+00]\n",
      "  [-4.40589134e+00 -4.03574491e+00 -3.42930058e+00 ... -1.18276493e+00\n",
      "   -2.14412190e+00 -2.70831465e+00]\n",
      "  ...\n",
      "  [ 1.93898408e+02  1.93898408e+02  1.93898408e+02 ...  1.93898408e+02\n",
      "    1.93898408e+02  1.93898408e+02]\n",
      "  [ 3.62922007e+02  3.62922007e+02  3.62922007e+02 ...  3.62922007e+02\n",
      "    3.62922007e+02  3.62922007e+02]\n",
      "  [ 3.87272353e+02  3.87272353e+02  3.87272353e+02 ...  3.87272353e+02\n",
      "    3.87272353e+02  3.87272353e+02]]\n",
      "\n",
      " [[-1.72287511e+01 -1.67588093e+01 -1.57690390e+01 ... -2.29825144e+00\n",
      "   -5.23610949e+00 -7.48081982e+00]\n",
      "  [-1.05007562e+01 -8.82734832e+00 -7.58036133e+00 ... -7.05032678e+00\n",
      "   -7.73207731e+00 -7.53453948e+00]\n",
      "  [-6.29765750e+00 -5.55503514e+00 -4.76536345e+00 ... -1.04179268e+00\n",
      "   -2.00764950e+00 -2.72531339e+00]\n",
      "  ...\n",
      "  [ 1.93898408e+02  1.93898408e+02  1.93898408e+02 ...  1.93898408e+02\n",
      "    1.93898408e+02  1.93898408e+02]\n",
      "  [ 3.62922007e+02  3.62922007e+02  3.62922007e+02 ...  3.62922007e+02\n",
      "    3.62922007e+02  3.62922007e+02]\n",
      "  [ 3.87272353e+02  3.87272353e+02  3.87272353e+02 ...  3.87272353e+02\n",
      "    3.87272353e+02  3.87272353e+02]]]\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "Results_cross = []\n",
    "\n",
    "def findAllFile_cross(base):\n",
    "    for root, ds, fs in os.walk(base):\n",
    "        for f in fs:\n",
    "            if f.endswith('.mat'):\n",
    "                fullname = os.path.join(root, f)\n",
    "                mat = loadmat(fullname) \n",
    "                Results_cross.append(mat)\n",
    "                yield fullname\n",
    "\n",
    "#build temp list for crossing\n",
    "IKlist = []\n",
    "IAlist = []\n",
    "GVlist = []\n",
    "EPlist = []\n",
    "EP_OBSlist = []\n",
    "AP_01list = []\n",
    "AP_02list = []\n",
    "AP_03list = []\n",
    "AP_04list = []\n",
    "AP_05list = []\n",
    "AP_06list = []\n",
    "\n",
    "\n",
    "AP_01_array = np.empty((1,101))\n",
    "AP_02_array = np.empty((1,101))\n",
    "AP_03_array = np.empty((1,101))\n",
    "AP_04_array = np.empty((1,101))\n",
    "AP_05_array = np.empty((1,101))\n",
    "AP_06_array = np.empty((1,101))\n",
    "\n",
    "IK_array = np.empty((6,101,3))\n",
    "IK_tay = np.empty((3,101))\n",
    "IK_toay = np.empty((6,3,101))\n",
    "\n",
    "\n",
    "IA_array = np.empty((4,101,1))\n",
    "IA_tay = np.empty((1,101))\n",
    "IA_toay = np.empty((4,1,101))\n",
    "\n",
    "GV_array = np.empty((1,101,1))\n",
    "GV_tay = np.empty((1,101))\n",
    "GV_toay = np.empty((1,1,101))\n",
    "\n",
    "\n",
    "\n",
    "Feature = np.empty((29,101))\n",
    "\n",
    "\n",
    "\n",
    "def getfeature(value):\n",
    "    \n",
    "    \n",
    "    #EP_array = np.empty((1))\n",
    "    o = Results_cross[value]['Results']['EP']\n",
    "    EPlist.append(o)\n",
    "    \n",
    "    EP_array = np.array(EPlist[value]['LeadingToeClearance'])\n",
    "    Feature_obstacles1 = EP_array\n",
    "    \n",
    "    \n",
    "    x = Results_cross[value]['Results']['IK']\n",
    "    IKlist.append(x)\n",
    "    \n",
    "    IK_array[0,:,:] = np.array(IKlist[value]['LeadingAnkle'])\n",
    "    IK_array[1,:,:] = np.array(IKlist[value]['LeadingHip'])\n",
    "    IK_array[2,:,:] = np.array(IKlist[value]['LeadingKnee'])\n",
    "    IK_array[3,:,:] = np.array(IKlist[value]['TrailingAnkle'])\n",
    "    IK_array[4,:,:] = np.array(IKlist[value]['TrailingHip'])\n",
    "    IK_array[5,:,:] = np.array(IKlist[value]['TrailingKnee'])\n",
    "    \n",
    "    \n",
    "   \n",
    "    for i in range(IK_toay.shape[0]):  \n",
    "        IK_tay = np.transpose(IK_array[i])\n",
    "        IK_toay[i,:,:] = IK_tay\n",
    "   \n",
    "\n",
    "    k = 0\n",
    "    for i in range(IK_toay.shape[0]):\n",
    "        for j in range(IK_toay.shape[1]):\n",
    "            Feature[k,:] = IK_toay[i,j,:] #k = 3*i+j\n",
    "            k += 1\n",
    "    \n",
    "    y = Results_cross[value]['Results']['IA']\n",
    "    IAlist.append(y)\n",
    "    IA_array[0,:,:] = np.array(IAlist[value]['FrontalIA'])\n",
    "    IA_array[1,:,:] = np.array(IAlist[value]['FrontalRCIA'])\n",
    "    IA_array[2,:,:] = np.array(IAlist[value]['SagittalIA'])\n",
    "    IA_array[3,:,:] = np.array(IAlist[value]['SagittalRCIA'])\n",
    "    \n",
    "    for i in range(IA_array.shape[0]):\n",
    "      IA_tay = np.transpose(IA_array[i])\n",
    "      IA_toay[i,:,:] = IA_tay\n",
    "      \n",
    "\n",
    "    for i in range(IA_toay.shape[0]):\n",
    "        for j in range(IA_toay.shape[1]):\n",
    "            Feature[k,:] = IA_toay[i,j,:] #k = 3*i+j\n",
    "            k += 1\n",
    "    \n",
    "    z = Results_cross[value]['Results']['SelfDefinedVariables']\n",
    "    GVlist.append(z)\n",
    "    GV_array[0,:,:] = np.array(GVlist[value]['GaitVelocity'])\n",
    "    GV_tay = np.transpose(GV_array[0])\n",
    "    GV_toay[0,:,:] = GV_tay\n",
    "    Feature[22,:] = GV_toay[0,0,:]\n",
    "    '''\n",
    "    #從EP取出障礙物高度並與Clearance相加取得toe離地高度\n",
    "    A = Results_cross[value]['Results']['EP']\n",
    "    EP_OBSlist.append(A)\n",
    "    \n",
    "    EP_OBS_array = np.array(EP_OBSlist[value]['OBS']+EP_OBSlist[value]['LeadingToeClearance'])\n",
    "    Feature_obstacles1 = EP_OBS_array\n",
    "    '''\n",
    "    \n",
    "    #取出AP單一值資料並變成序列資料\n",
    "    B = Results_cross[value]['Results']['AP']['BodyHeight']\n",
    "    AP_01list.append(B)\n",
    "    for i in range(101):\n",
    "        AP_01_array[:,i] = np.array(AP_01list[value])\n",
    "        Feature[23,:] = AP_01_array[:,i]\n",
    "    \n",
    "    C = Results_cross[value]['Results']['AP']['BW']\n",
    "    AP_02list.append(C)\n",
    "    for i in range(101):\n",
    "        AP_02_array[:,i] = np.array(AP_02list[value])\n",
    "        Feature[24,:] = AP_02_array[:,i]\n",
    "    \n",
    "    D = Results_cross[value]['Results']['AP']['FootLength']\n",
    "    AP_03list.append(D)\n",
    "    for i in range(101):\n",
    "        AP_03_array[:,i] = np.array(AP_03list[value])\n",
    "        Feature[25,:] = AP_03_array[:,i]\n",
    "        \n",
    "    E = Results_cross[value]['Results']['AP']['HipWidth']\n",
    "    AP_04list.append(E)\n",
    "    for i in range(101):\n",
    "        AP_04_array[:,i] = np.array(AP_04list[value])\n",
    "        Feature[26,:] = AP_04_array[:,i]\n",
    "    \n",
    "    F = Results_cross[value]['Results']['AP']['ShankLength']\n",
    "    AP_05list.append(F)\n",
    "    for i in range(101):\n",
    "        AP_05_array[:,i] = np.array(AP_05list[value])\n",
    "        Feature[27,:] = AP_05_array[:,i]\n",
    "    \n",
    "    G = Results_cross[value]['Results']['AP']['ThighLength']\n",
    "    AP_06list.append(G)\n",
    "    for i in range(101):\n",
    "        AP_06_array[:,i] = np.array(AP_06list[value])\n",
    "        Feature[28,:] = AP_06_array[:,i]\n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "    return Feature,Feature_obstacles1\n",
    "\n",
    "Feature_cross = np.empty((204,29,101))\n",
    "Feature_obstacles = np.empty((204))\n",
    "FEATUREccc = np.empty((29,101))\n",
    "\n",
    "\n",
    "\n",
    "base = r\"C:/Users/Danny Lee/Desktop/motion hw/final/Results_cross/\"\n",
    "\n",
    "\n",
    "for i in findAllFile_cross(base):\n",
    "    print(i)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(Results_cross)):\n",
    "    FEATUREccc,Feature_obs= getfeature(i)\n",
    "    Feature_cross[i,:,:] = FEATUREccc\n",
    "    Feature_obstacles[i] = Feature_obs\n",
    "\n",
    "    \n",
    "print(Feature_cross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9309940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122 122\n",
      "41 41\n",
      "41 41\n"
     ]
    }
   ],
   "source": [
    "X_normalized = (Feature_cross - Feature_cross.mean()) / Feature_cross.std()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_normalized, Feature_obstacles, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
    "print(len(X_train),len(y_train))\n",
    "print(len(X_val),len(y_val))\n",
    "print(len(X_test),len(y_test))\n",
    "#train=0.8，val=0.1，test=0.1\n",
    "\n",
    "# reshape input to be [samples, time steps, features] which is required for LSTM\n",
    "X_train =X_train.reshape(X_train.shape[0],X_train.shape[2] , X_train.shape[1])\n",
    "X_val =X_val.reshape(X_val.shape[0],X_val.shape[2] , X_val.shape[1])\n",
    "X_test = X_test.reshape(X_test.shape[0],X_test.shape[2] , X_test.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebccfc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(keras.layers.Layer):\n",
    "        def __init__(self, attention_units):\n",
    "            super(SelfAttention, self).__init__()\n",
    "            self.attention_units = attention_units\n",
    "\n",
    "        def build(self, input_shape):\n",
    "            self.W = self.add_weight(\n",
    "                shape=(input_shape[-1], self.attention_units),\n",
    "                initializer=\"glorot_uniform\",\n",
    "                trainable=True\n",
    "            )\n",
    "            self.b = self.add_weight(\n",
    "                shape=(self.attention_units,),\n",
    "                initializer=\"zeros\",\n",
    "                trainable=True\n",
    "            )\n",
    "            self.V = self.add_weight(\n",
    "                shape=(self.attention_units, 1),\n",
    "                initializer=\"glorot_uniform\",\n",
    "                trainable=True\n",
    "            )\n",
    "    \n",
    "        def call(self, inputs):\n",
    "            score = keras.activations.tanh(keras.backend.dot(inputs, self.W) + self.b)\n",
    "            attention_weights = keras.activations.softmax(keras.backend.dot(score, self.V), axis=1)\n",
    "            attended_input = inputs * attention_weights\n",
    "            return attended_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8d19b9c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Attention' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-61cbd371d6ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:/Users/Danny Lee/Desktop/motion hw/final/LSTM model performance/try_0612_dropout/Regression.h5'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'Attention'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mAttention\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Attention' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "model = load_model('C:/Users/Danny Lee/Desktop/motion hw/final/LSTM model performance/try_0612_dropout/Regression.h5',custom_objects={'Attention':Attention})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "366d3ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Users\\Ray Lee\\anaconda3\\envs\\tf1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 122 samples, validate on 41 samples\n",
      "Epoch 1/2000\n",
      "122/122 [==============================] - 1s 10ms/step - loss: 32350.0562 - val_loss: 36101.7703\n",
      "Epoch 2/2000\n",
      "122/122 [==============================] - 0s 965us/step - loss: 32348.3335 - val_loss: 36098.6680\n",
      "Epoch 3/2000\n",
      "122/122 [==============================] - 0s 940us/step - loss: 32344.7725 - val_loss: 36093.7489\n",
      "Epoch 4/2000\n",
      "122/122 [==============================] - 0s 932us/step - loss: 32339.0286 - val_loss: 36085.5034\n",
      "Epoch 5/2000\n",
      "122/122 [==============================] - 0s 916us/step - loss: 32329.6782 - val_loss: 36072.4417\n",
      "Epoch 6/2000\n",
      "122/122 [==============================] - 0s 883us/step - loss: 32314.7738 - val_loss: 36051.7772\n",
      "Epoch 7/2000\n",
      "122/122 [==============================] - 0s 875us/step - loss: 32291.0052 - val_loss: 36018.2790\n",
      "Epoch 8/2000\n",
      "122/122 [==============================] - 0s 867us/step - loss: 32251.8726 - val_loss: 35961.6623\n",
      "Epoch 9/2000\n",
      "122/122 [==============================] - 0s 860us/step - loss: 32180.4684 - val_loss: 35846.3303\n",
      "Epoch 10/2000\n",
      "122/122 [==============================] - 0s 883us/step - loss: 32047.4478 - val_loss: 35667.2207\n",
      "Epoch 11/2000\n",
      "122/122 [==============================] - 0s 899us/step - loss: 31852.7091 - val_loss: 35417.9112\n",
      "Epoch 12/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 31586.4785 - val_loss: 35059.8828\n",
      "Epoch 13/2000\n",
      "122/122 [==============================] - 0s 904us/step - loss: 31184.8756 - val_loss: 34539.2987\n",
      "Epoch 14/2000\n",
      "122/122 [==============================] - 0s 875us/step - loss: 30611.6711 - val_loss: 33786.9165\n",
      "Epoch 15/2000\n",
      "122/122 [==============================] - 0s 867us/step - loss: 29798.9960 - val_loss: 32708.7128\n",
      "Epoch 16/2000\n",
      "122/122 [==============================] - 0s 867us/step - loss: 28643.8433 - val_loss: 31183.3977\n",
      "Epoch 17/2000\n",
      "122/122 [==============================] - 0s 883us/step - loss: 26972.2578 - val_loss: 29068.3605\n",
      "Epoch 18/2000\n",
      "122/122 [==============================] - 0s 891us/step - loss: 24735.2217 - val_loss: 26190.6347\n",
      "Epoch 19/2000\n",
      "122/122 [==============================] - 0s 867us/step - loss: 21681.3026 - val_loss: 22416.5491\n",
      "Epoch 20/2000\n",
      "122/122 [==============================] - 0s 891us/step - loss: 17905.9212 - val_loss: 17697.7949\n",
      "Epoch 21/2000\n",
      "122/122 [==============================] - 0s 883us/step - loss: 13146.4521 - val_loss: 12308.4427\n",
      "Epoch 22/2000\n",
      "122/122 [==============================] - 0s 867us/step - loss: 8226.9169 - val_loss: 7136.5557\n",
      "Epoch 23/2000\n",
      "122/122 [==============================] - 0s 871us/step - loss: 4226.4119 - val_loss: 3967.6645\n",
      "Epoch 24/2000\n",
      "122/122 [==============================] - 0s 871us/step - loss: 2908.3264 - val_loss: 4094.4479\n",
      "Epoch 25/2000\n",
      "122/122 [==============================] - 0s 883us/step - loss: 3939.8258 - val_loss: 4582.9025\n",
      "Epoch 26/2000\n",
      "122/122 [==============================] - 0s 899us/step - loss: 3933.3680 - val_loss: 3900.9589\n",
      "Epoch 27/2000\n",
      "122/122 [==============================] - 0s 871us/step - loss: 3126.1664 - val_loss: 3717.4343\n",
      "Epoch 28/2000\n",
      "122/122 [==============================] - 0s 863us/step - loss: 2813.1357 - val_loss: 4046.1443\n",
      "Epoch 29/2000\n",
      "122/122 [==============================] - 0s 875us/step - loss: 2861.1237 - val_loss: 4151.3188\n",
      "Epoch 30/2000\n",
      "122/122 [==============================] - 0s 875us/step - loss: 2956.8060 - val_loss: 4095.6461\n",
      "Epoch 31/2000\n",
      "122/122 [==============================] - 0s 867us/step - loss: 2894.0163 - val_loss: 3900.6795\n",
      "Epoch 32/2000\n",
      "122/122 [==============================] - 0s 867us/step - loss: 2781.0624 - val_loss: 3744.2337\n",
      "Epoch 33/2000\n",
      "122/122 [==============================] - 0s 875us/step - loss: 2771.4150 - val_loss: 3695.2401\n",
      "Epoch 34/2000\n",
      "122/122 [==============================] - 0s 875us/step - loss: 2778.0837 - val_loss: 3691.6690\n",
      "Epoch 35/2000\n",
      "122/122 [==============================] - 0s 858us/step - loss: 2799.5797 - val_loss: 3701.0298\n",
      "Epoch 36/2000\n",
      "122/122 [==============================] - 0s 858us/step - loss: 2781.7781 - val_loss: 3730.9111\n",
      "Epoch 37/2000\n",
      "122/122 [==============================] - 0s 899us/step - loss: 2767.2498 - val_loss: 3774.8701\n",
      "Epoch 38/2000\n",
      "122/122 [==============================] - 0s 883us/step - loss: 2794.4802 - val_loss: 3782.1089\n",
      "Epoch 39/2000\n",
      "122/122 [==============================] - 0s 931us/step - loss: 2773.0585 - val_loss: 3768.7358\n",
      "Epoch 40/2000\n",
      "122/122 [==============================] - 0s 891us/step - loss: 2761.3220 - val_loss: 3755.6168\n",
      "Epoch 41/2000\n",
      "122/122 [==============================] - 0s 863us/step - loss: 2795.0459 - val_loss: 3739.5111\n",
      "Epoch 42/2000\n",
      "122/122 [==============================] - 0s 883us/step - loss: 2787.7140 - val_loss: 3730.9125\n",
      "Epoch 43/2000\n",
      "122/122 [==============================] - 0s 883us/step - loss: 2771.3558 - val_loss: 3737.0306\n",
      "Epoch 44/2000\n",
      "122/122 [==============================] - 0s 875us/step - loss: 2776.9405 - val_loss: 3747.5803\n",
      "Epoch 45/2000\n",
      "122/122 [==============================] - 0s 858us/step - loss: 2747.4723 - val_loss: 3759.0710\n",
      "Epoch 46/2000\n",
      "122/122 [==============================] - 0s 875us/step - loss: 2776.1919 - val_loss: 3756.6615\n",
      "Epoch 47/2000\n",
      "122/122 [==============================] - 0s 875us/step - loss: 2756.4643 - val_loss: 3742.2353\n",
      "Epoch 48/2000\n",
      "122/122 [==============================] - 0s 875us/step - loss: 2771.4218 - val_loss: 3729.7906\n",
      "Epoch 49/2000\n",
      "122/122 [==============================] - 0s 867us/step - loss: 2766.7525 - val_loss: 3739.6453\n",
      "Epoch 50/2000\n",
      "122/122 [==============================] - 0s 883us/step - loss: 2753.6062 - val_loss: 3738.5671\n",
      "Epoch 51/2000\n",
      "122/122 [==============================] - 0s 875us/step - loss: 2778.4817 - val_loss: 3742.2470\n",
      "Epoch 52/2000\n",
      "122/122 [==============================] - 0s 907us/step - loss: 2771.6084 - val_loss: 3744.0905\n",
      "Epoch 53/2000\n",
      "122/122 [==============================] - 0s 867us/step - loss: 2764.5143 - val_loss: 3753.6594\n",
      "Epoch 54/2000\n",
      "122/122 [==============================] - 0s 896us/step - loss: 2760.4675 - val_loss: 3756.4036\n",
      "Epoch 55/2000\n",
      "122/122 [==============================] - 0s 888us/step - loss: 2759.6646 - val_loss: 3760.8163\n",
      "Epoch 56/2000\n",
      "122/122 [==============================] - 0s 893us/step - loss: 2788.3433 - val_loss: 3744.9713\n",
      "Epoch 57/2000\n",
      "122/122 [==============================] - 0s 899us/step - loss: 2771.3939 - val_loss: 3744.7197\n",
      "Epoch 58/2000\n",
      "122/122 [==============================] - 0s 875us/step - loss: 2784.4605 - val_loss: 3736.3295\n",
      "Epoch 59/2000\n",
      "122/122 [==============================] - 0s 883us/step - loss: 2770.4946 - val_loss: 3735.6663\n",
      "Epoch 60/2000\n",
      "122/122 [==============================] - 0s 891us/step - loss: 2759.0677 - val_loss: 3744.1576\n",
      "Epoch 61/2000\n",
      "122/122 [==============================] - 0s 875us/step - loss: 2753.8356 - val_loss: 3734.5150\n",
      "Epoch 62/2000\n",
      "122/122 [==============================] - 0s 875us/step - loss: 2756.4818 - val_loss: 3741.7454\n",
      "Epoch 63/2000\n",
      "122/122 [==============================] - 0s 883us/step - loss: 2769.4049 - val_loss: 3752.6740\n",
      "Epoch 64/2000\n",
      "122/122 [==============================] - 0s 883us/step - loss: 2777.1640 - val_loss: 3748.0569\n",
      "Epoch 65/2000\n",
      "122/122 [==============================] - 0s 899us/step - loss: 2785.0508 - val_loss: 3728.6571\n",
      "Epoch 66/2000\n",
      "122/122 [==============================] - 0s 867us/step - loss: 2781.3555 - val_loss: 3740.4979\n",
      "Epoch 67/2000\n",
      "122/122 [==============================] - 0s 858us/step - loss: 2768.2290 - val_loss: 3760.8716\n",
      "Epoch 68/2000\n",
      "122/122 [==============================] - 0s 875us/step - loss: 2778.8100 - val_loss: 3760.2523\n",
      "Epoch 69/2000\n",
      "122/122 [==============================] - 0s 864us/step - loss: 2797.6892 - val_loss: 3775.3040\n",
      "Epoch 70/2000\n",
      "122/122 [==============================] - 0s 875us/step - loss: 2756.5918 - val_loss: 3749.1988\n",
      "Epoch 71/2000\n",
      "122/122 [==============================] - 0s 891us/step - loss: 2765.2663 - val_loss: 3742.0091\n",
      "Epoch 72/2000\n",
      "122/122 [==============================] - 0s 867us/step - loss: 2765.6876 - val_loss: 3730.4382\n",
      "Epoch 73/2000\n",
      "122/122 [==============================] - 0s 883us/step - loss: 2745.4512 - val_loss: 3728.2190\n",
      "Epoch 74/2000\n",
      "122/122 [==============================] - 0s 867us/step - loss: 2768.1477 - val_loss: 3733.2408\n",
      "Epoch 75/2000\n",
      "122/122 [==============================] - 0s 858us/step - loss: 2795.6527 - val_loss: 3765.2859\n",
      "Epoch 76/2000\n",
      "122/122 [==============================] - 0s 867us/step - loss: 2767.1765 - val_loss: 3756.3782\n",
      "Epoch 77/2000\n",
      "122/122 [==============================] - 0s 858us/step - loss: 2759.0238 - val_loss: 3735.5971\n",
      "Epoch 78/2000\n",
      "122/122 [==============================] - 0s 883us/step - loss: 2761.8707 - val_loss: 3723.3944\n",
      "Epoch 79/2000\n",
      "122/122 [==============================] - 0s 883us/step - loss: 2777.2139 - val_loss: 3731.6792\n",
      "Epoch 80/2000\n",
      "122/122 [==============================] - 0s 904us/step - loss: 2759.1408 - val_loss: 3744.6009\n",
      "Epoch 81/2000\n",
      "122/122 [==============================] - 0s 895us/step - loss: 2771.9339 - val_loss: 3734.3696\n",
      "Epoch 82/2000\n",
      "122/122 [==============================] - 0s 875us/step - loss: 2760.3365 - val_loss: 3750.3879\n",
      "Epoch 83/2000\n",
      "122/122 [==============================] - 0s 888us/step - loss: 2806.4142 - val_loss: 3755.4509\n",
      "Epoch 84/2000\n",
      "122/122 [==============================] - 0s 863us/step - loss: 2754.5637 - val_loss: 3760.1869\n",
      "Epoch 85/2000\n",
      "122/122 [==============================] - 0s 858us/step - loss: 2771.6884 - val_loss: 3760.8325\n",
      "Epoch 86/2000\n",
      "122/122 [==============================] - 0s 867us/step - loss: 2775.5173 - val_loss: 3745.8480\n",
      "Epoch 87/2000\n",
      "122/122 [==============================] - 0s 858us/step - loss: 2781.7868 - val_loss: 3738.7658\n",
      "Epoch 88/2000\n",
      "122/122 [==============================] - 0s 858us/step - loss: 2755.2957 - val_loss: 3748.0798\n",
      "Epoch 89/2000\n",
      "122/122 [==============================] - 0s 875us/step - loss: 2763.9335 - val_loss: 3745.2159\n",
      "Epoch 90/2000\n",
      "122/122 [==============================] - 0s 875us/step - loss: 2769.8346 - val_loss: 3735.1199\n",
      "Epoch 91/2000\n",
      "122/122 [==============================] - 0s 867us/step - loss: 2778.0926 - val_loss: 3721.7623\n",
      "Epoch 92/2000\n",
      "122/122 [==============================] - 0s 883us/step - loss: 2777.3070 - val_loss: 3754.8966\n",
      "Epoch 93/2000\n",
      "122/122 [==============================] - 0s 858us/step - loss: 2749.2605 - val_loss: 3758.8057\n",
      "Epoch 94/2000\n",
      "122/122 [==============================] - 0s 899us/step - loss: 2777.6206 - val_loss: 3753.5900\n",
      "Epoch 95/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2821.5821 - val_loss: 3717.4733\n",
      "Epoch 96/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2795.7017 - val_loss: 3754.7676\n",
      "Epoch 97/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2763.3227 - val_loss: 3754.2420\n",
      "Epoch 98/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2780.4455 - val_loss: 3749.7963\n",
      "Epoch 99/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2768.3165 - val_loss: 3770.6170\n",
      "Epoch 100/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2780.4686 - val_loss: 3769.0582\n",
      "Epoch 101/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2795.8769 - val_loss: 3737.2536\n",
      "Epoch 102/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2757.8838 - val_loss: 3728.0138\n",
      "Epoch 103/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2766.9652 - val_loss: 3741.2380\n",
      "Epoch 104/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2770.1839 - val_loss: 3753.6720\n",
      "Epoch 105/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2771.1533 - val_loss: 3753.9186\n",
      "Epoch 106/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2771.8111 - val_loss: 3717.1895\n",
      "Epoch 107/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2769.3191 - val_loss: 3743.6122\n",
      "Epoch 108/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2766.3326 - val_loss: 3737.0816\n",
      "Epoch 109/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2783.1196 - val_loss: 3742.3329\n",
      "Epoch 110/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2760.9978 - val_loss: 3760.0000\n",
      "Epoch 111/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2741.6092 - val_loss: 3766.1851\n",
      "Epoch 112/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2785.4718 - val_loss: 3752.8641\n",
      "Epoch 113/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2775.0945 - val_loss: 3733.2624\n",
      "Epoch 114/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2788.3176 - val_loss: 3726.4946\n",
      "Epoch 115/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2769.1504 - val_loss: 3738.4982\n",
      "Epoch 116/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2751.5514 - val_loss: 3771.8292\n",
      "Epoch 117/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2802.8656 - val_loss: 3771.6919\n",
      "Epoch 118/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2773.9751 - val_loss: 3758.2494\n",
      "Epoch 119/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2790.4565 - val_loss: 3761.8788\n",
      "Epoch 120/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2773.3189 - val_loss: 3735.7010\n",
      "Epoch 121/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2760.3501 - val_loss: 3744.2399\n",
      "Epoch 122/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2739.4687 - val_loss: 3748.9487\n",
      "Epoch 123/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2789.1101 - val_loss: 3738.8545\n",
      "Epoch 124/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2757.3834 - val_loss: 3741.5094\n",
      "Epoch 125/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2789.3520 - val_loss: 3759.3430\n",
      "Epoch 126/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2770.4551 - val_loss: 3734.5354\n",
      "Epoch 127/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2776.7519 - val_loss: 3720.1615\n",
      "Epoch 128/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2774.3644 - val_loss: 3759.3848\n",
      "Epoch 129/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2811.0149 - val_loss: 3805.0539\n",
      "Epoch 130/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2748.8567 - val_loss: 3761.3733\n",
      "Epoch 131/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2758.6505 - val_loss: 3713.0441\n",
      "Epoch 132/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2768.7095 - val_loss: 3711.3614\n",
      "Epoch 133/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2758.3909 - val_loss: 3751.9598\n",
      "Epoch 134/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2782.2570 - val_loss: 3791.6288\n",
      "Epoch 135/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2775.5578 - val_loss: 3771.4557\n",
      "Epoch 136/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2782.9240 - val_loss: 3728.0665\n",
      "Epoch 137/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2791.7177 - val_loss: 3708.1777\n",
      "Epoch 138/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2781.8247 - val_loss: 3713.4937\n",
      "Epoch 139/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2731.0505 - val_loss: 3778.3473\n",
      "Epoch 140/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2773.3522 - val_loss: 3812.8713\n",
      "Epoch 141/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2780.9000 - val_loss: 3800.8758\n",
      "Epoch 142/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2772.8429 - val_loss: 3726.0838\n",
      "Epoch 143/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2766.1199 - val_loss: 3701.7508\n",
      "Epoch 144/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2779.0510 - val_loss: 3704.1060\n",
      "Epoch 145/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2786.8371 - val_loss: 3763.8631\n",
      "Epoch 146/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - 0s 1ms/step - loss: 2754.3942 - val_loss: 3787.7580\n",
      "Epoch 147/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2781.9036 - val_loss: 3798.1672\n",
      "Epoch 148/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2738.1698 - val_loss: 3743.3171\n",
      "Epoch 149/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2747.6474 - val_loss: 3722.9484\n",
      "Epoch 150/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2785.2542 - val_loss: 3692.9790\n",
      "Epoch 151/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2800.0173 - val_loss: 3698.7063\n",
      "Epoch 152/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2795.1054 - val_loss: 3804.3931\n",
      "Epoch 153/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2789.9293 - val_loss: 3850.3494\n",
      "Epoch 154/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2782.1308 - val_loss: 3776.9512\n",
      "Epoch 155/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2730.0583 - val_loss: 3737.2961\n",
      "Epoch 156/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2802.9198 - val_loss: 3685.4832\n",
      "Epoch 157/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2776.3109 - val_loss: 3704.9918\n",
      "Epoch 158/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2791.5112 - val_loss: 3761.1799\n",
      "Epoch 159/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2788.6570 - val_loss: 3810.0880\n",
      "Epoch 160/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2760.6336 - val_loss: 3753.1704\n",
      "Epoch 161/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2770.6188 - val_loss: 3740.3414\n",
      "Epoch 162/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2782.2333 - val_loss: 3730.7723\n",
      "Epoch 163/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2760.3648 - val_loss: 3739.9920\n",
      "Epoch 164/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2774.2471 - val_loss: 3732.7478\n",
      "Epoch 165/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2788.2799 - val_loss: 3768.6665\n",
      "Epoch 166/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2801.3912 - val_loss: 3770.5216\n",
      "Epoch 167/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2775.1461 - val_loss: 3751.6707\n",
      "Epoch 168/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2798.5062 - val_loss: 3721.5161\n",
      "Epoch 169/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2764.6966 - val_loss: 3741.9947\n",
      "Epoch 170/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2799.9779 - val_loss: 3742.4471\n",
      "Epoch 171/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2773.7392 - val_loss: 3758.9353\n",
      "Epoch 172/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2736.9787 - val_loss: 3763.4861\n",
      "Epoch 173/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2786.2247 - val_loss: 3757.0463\n",
      "Epoch 174/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2767.9878 - val_loss: 3717.1660\n",
      "Epoch 175/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2773.5281 - val_loss: 3719.7139\n",
      "Epoch 176/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2770.9621 - val_loss: 3735.6965\n",
      "Epoch 177/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2781.6512 - val_loss: 3772.9962\n",
      "Epoch 178/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2773.9857 - val_loss: 3783.1145\n",
      "Epoch 179/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2769.9426 - val_loss: 3784.0932\n",
      "Epoch 180/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2771.7717 - val_loss: 3749.5307\n",
      "Epoch 181/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2769.1038 - val_loss: 3742.3160\n",
      "Epoch 182/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2796.0640 - val_loss: 3735.7188\n",
      "Epoch 183/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2750.1626 - val_loss: 3723.6815\n",
      "Epoch 184/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2784.4600 - val_loss: 3756.2309\n",
      "Epoch 185/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2760.9386 - val_loss: 3776.6498\n",
      "Epoch 186/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2782.7883 - val_loss: 3766.7728\n",
      "Epoch 187/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2770.4068 - val_loss: 3725.0550\n",
      "Epoch 188/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2749.9523 - val_loss: 3747.2300\n",
      "Epoch 189/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2778.5427 - val_loss: 3781.9468\n",
      "Epoch 190/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2788.4392 - val_loss: 3743.2278\n",
      "Epoch 191/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2776.4474 - val_loss: 3741.2213\n",
      "Epoch 192/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2758.7787 - val_loss: 3767.5484\n",
      "Epoch 193/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2798.0596 - val_loss: 3794.1123\n",
      "Epoch 194/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2770.5951 - val_loss: 3723.3665\n",
      "Epoch 195/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2764.6060 - val_loss: 3709.2815\n",
      "Epoch 196/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2771.6655 - val_loss: 3732.6550\n",
      "Epoch 197/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2771.6755 - val_loss: 3805.3257\n",
      "Epoch 198/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2742.4135 - val_loss: 3796.1818\n",
      "Epoch 199/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2766.0713 - val_loss: 3753.1746\n",
      "Epoch 200/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2744.6937 - val_loss: 3743.5776\n",
      "Epoch 201/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2804.6467 - val_loss: 3706.2674\n",
      "Epoch 202/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2768.8474 - val_loss: 3809.7655\n",
      "Epoch 203/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2755.0204 - val_loss: 3852.2097\n",
      "Epoch 204/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2755.5836 - val_loss: 3773.8119\n",
      "Epoch 205/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2759.3781 - val_loss: 3746.6157\n",
      "Epoch 206/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2761.3527 - val_loss: 3712.8656\n",
      "Epoch 207/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2751.1531 - val_loss: 3752.5929\n",
      "Epoch 208/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2733.3838 - val_loss: 3828.5305\n",
      "Epoch 209/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2728.1828 - val_loss: 3910.6119\n",
      "Epoch 210/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2743.7552 - val_loss: 3797.4536\n",
      "Epoch 211/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2777.5054 - val_loss: 3747.6531\n",
      "Epoch 212/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2783.8116 - val_loss: 3981.6857\n",
      "Epoch 213/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2761.8570 - val_loss: 3743.1524\n",
      "Epoch 214/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2698.5152 - val_loss: 3860.8100\n",
      "Epoch 215/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2705.0026 - val_loss: 4041.2863\n",
      "Epoch 216/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2651.7503 - val_loss: 3839.0783\n",
      "Epoch 217/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2672.0650 - val_loss: 3804.7725\n",
      "Epoch 218/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2566.5969 - val_loss: 3890.8325\n",
      "Epoch 219/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2558.5036 - val_loss: 3692.1137\n",
      "Epoch 220/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2578.9943 - val_loss: 3886.3179\n",
      "Epoch 221/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2535.9077 - val_loss: 3896.0180\n",
      "Epoch 222/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2589.4006 - val_loss: 3826.2119\n",
      "Epoch 223/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2522.2479 - val_loss: 3833.5608\n",
      "Epoch 224/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2501.0123 - val_loss: 3886.2833\n",
      "Epoch 225/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2492.3576 - val_loss: 3874.6227\n",
      "Epoch 226/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2467.4904 - val_loss: 3705.9249\n",
      "Epoch 227/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2465.8318 - val_loss: 3756.7634\n",
      "Epoch 228/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2433.8573 - val_loss: 4097.8426\n",
      "Epoch 229/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2435.3732 - val_loss: 3900.3305\n",
      "Epoch 230/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2371.0390 - val_loss: 3785.2207\n",
      "Epoch 231/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2361.9391 - val_loss: 3617.7084\n",
      "Epoch 232/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2388.6267 - val_loss: 3489.5615\n",
      "Epoch 233/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2374.4137 - val_loss: 4208.2859\n",
      "Epoch 234/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2378.4388 - val_loss: 4102.8675\n",
      "Epoch 235/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2254.6545 - val_loss: 3835.9862\n",
      "Epoch 236/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2271.0639 - val_loss: 3813.9701\n",
      "Epoch 237/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2199.4159 - val_loss: 3929.6701\n",
      "Epoch 238/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2227.8610 - val_loss: 3442.7436\n",
      "Epoch 239/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2563.1081 - val_loss: 4183.7482\n",
      "Epoch 240/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2877.4584 - val_loss: 3948.5310\n",
      "Epoch 241/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2795.2471 - val_loss: 3913.7740\n",
      "Epoch 242/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2613.6828 - val_loss: 4286.4015\n",
      "Epoch 243/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2766.3668 - val_loss: 4141.0642\n",
      "Epoch 244/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2648.6537 - val_loss: 3875.6689\n",
      "Epoch 245/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2617.9006 - val_loss: 3808.0221\n",
      "Epoch 246/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2609.8446 - val_loss: 3857.6644\n",
      "Epoch 247/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2577.0604 - val_loss: 3921.9826\n",
      "Epoch 248/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2551.1148 - val_loss: 3929.5910\n",
      "Epoch 249/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2557.9803 - val_loss: 3968.3609\n",
      "Epoch 250/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2516.9782 - val_loss: 3980.5895\n",
      "Epoch 251/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2511.9457 - val_loss: 4026.4527\n",
      "Epoch 252/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2473.3397 - val_loss: 3921.8557\n",
      "Epoch 253/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2457.5588 - val_loss: 3906.3285\n",
      "Epoch 254/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2444.0883 - val_loss: 3985.0735\n",
      "Epoch 255/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2454.3380 - val_loss: 3979.2313\n",
      "Epoch 256/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2484.1259 - val_loss: 3894.0130\n",
      "Epoch 257/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2417.6860 - val_loss: 3860.0177\n",
      "Epoch 258/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2410.5361 - val_loss: 3938.5274\n",
      "Epoch 259/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2408.5607 - val_loss: 3990.8946\n",
      "Epoch 260/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2362.8317 - val_loss: 3812.0952\n",
      "Epoch 261/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2396.7755 - val_loss: 3804.5278\n",
      "Epoch 262/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2274.7432 - val_loss: 3914.4034\n",
      "Epoch 263/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2299.2000 - val_loss: 3668.5985\n",
      "Epoch 264/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2277.0442 - val_loss: 3612.2428\n",
      "Epoch 265/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2222.4424 - val_loss: 3677.2730\n",
      "Epoch 266/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2147.4069 - val_loss: 3567.7447\n",
      "Epoch 267/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2078.6526 - val_loss: 3469.8502\n",
      "Epoch 268/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2083.6211 - val_loss: 3560.0454\n",
      "Epoch 269/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2030.1757 - val_loss: 4016.9691\n",
      "Epoch 270/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2020.8983 - val_loss: 3340.7828\n",
      "Epoch 271/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2125.5047 - val_loss: 4009.0279\n",
      "Epoch 272/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2027.6580 - val_loss: 4153.3951\n",
      "Epoch 273/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2055.2975 - val_loss: 3847.8136\n",
      "Epoch 274/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2026.0240 - val_loss: 3363.0660\n",
      "Epoch 275/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2154.5559 - val_loss: 3695.5289\n",
      "Epoch 276/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2028.6586 - val_loss: 4318.0198\n",
      "Epoch 277/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2014.3075 - val_loss: 3432.2281\n",
      "Epoch 278/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2199.5291 - val_loss: 3792.6448\n",
      "Epoch 279/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2187.5109 - val_loss: 3465.0677\n",
      "Epoch 280/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2477.4804 - val_loss: 3483.3586\n",
      "Epoch 281/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2290.2594 - val_loss: 3736.3082\n",
      "Epoch 282/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2375.7399 - val_loss: 3883.2559\n",
      "Epoch 283/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2399.7381 - val_loss: 3799.7380\n",
      "Epoch 284/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2369.4960 - val_loss: 3715.3632\n",
      "Epoch 285/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2362.1943 - val_loss: 3682.3139\n",
      "Epoch 286/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2362.3039 - val_loss: 3683.3648\n",
      "Epoch 287/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2366.1380 - val_loss: 3749.7941\n",
      "Epoch 288/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2327.3499 - val_loss: 3619.6601\n",
      "Epoch 289/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2288.3332 - val_loss: 3535.4569\n",
      "Epoch 290/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2252.4781 - val_loss: 3558.4774\n",
      "Epoch 291/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2279.8790 - val_loss: 3627.6715\n",
      "Epoch 292/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2234.2566 - val_loss: 3616.9404\n",
      "Epoch 293/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2208.3060 - val_loss: 3651.4661\n",
      "Epoch 294/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - 0s 1ms/step - loss: 2177.1838 - val_loss: 3773.0349\n",
      "Epoch 295/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2090.8703 - val_loss: 3742.7882\n",
      "Epoch 296/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2070.4559 - val_loss: 3627.3737\n",
      "Epoch 297/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1981.0432 - val_loss: 3693.4902\n",
      "Epoch 298/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1959.9124 - val_loss: 3965.2809\n",
      "Epoch 299/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2071.2737 - val_loss: 3797.6138\n",
      "Epoch 300/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2006.7969 - val_loss: 3686.3919\n",
      "Epoch 301/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1952.8695 - val_loss: 3649.8283\n",
      "Epoch 302/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1997.1471 - val_loss: 3794.7725\n",
      "Epoch 303/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1906.4734 - val_loss: 3947.1012\n",
      "Epoch 304/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1862.2936 - val_loss: 3923.8249\n",
      "Epoch 305/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2012.6675 - val_loss: 3763.8904\n",
      "Epoch 306/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2494.9014 - val_loss: 4120.5167\n",
      "Epoch 307/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2432.3951 - val_loss: 3976.0630\n",
      "Epoch 308/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2403.5605 - val_loss: 3891.4962\n",
      "Epoch 309/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2475.0429 - val_loss: 3953.0673\n",
      "Epoch 310/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2505.1597 - val_loss: 4156.7411\n",
      "Epoch 311/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2521.6223 - val_loss: 4097.4641\n",
      "Epoch 312/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2456.1847 - val_loss: 3974.4157\n",
      "Epoch 313/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2438.2177 - val_loss: 3917.5641\n",
      "Epoch 314/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2441.8913 - val_loss: 4021.2364\n",
      "Epoch 315/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2377.3413 - val_loss: 4216.2641\n",
      "Epoch 316/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2429.2002 - val_loss: 4032.8240\n",
      "Epoch 317/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2365.7459 - val_loss: 3998.8658\n",
      "Epoch 318/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2364.1348 - val_loss: 4028.0705\n",
      "Epoch 319/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2313.5734 - val_loss: 3901.6788\n",
      "Epoch 320/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2313.2208 - val_loss: 3836.5845\n",
      "Epoch 321/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2264.6994 - val_loss: 3782.1674\n",
      "Epoch 322/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2283.6121 - val_loss: 3759.2177\n",
      "Epoch 323/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2260.5555 - val_loss: 3707.8500\n",
      "Epoch 324/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2283.7608 - val_loss: 3728.8934\n",
      "Epoch 325/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2280.6037 - val_loss: 3671.1219\n",
      "Epoch 326/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2262.5173 - val_loss: 3657.0966\n",
      "Epoch 327/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2246.7072 - val_loss: 3714.8186\n",
      "Epoch 328/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2249.2659 - val_loss: 3743.7843\n",
      "Epoch 329/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2240.1343 - val_loss: 3740.2618\n",
      "Epoch 330/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2245.4537 - val_loss: 3740.0697\n",
      "Epoch 331/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2253.6139 - val_loss: 3735.5489\n",
      "Epoch 332/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2225.1090 - val_loss: 3716.3436\n",
      "Epoch 333/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2224.6807 - val_loss: 3713.1199\n",
      "Epoch 334/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2205.1494 - val_loss: 3686.9597\n",
      "Epoch 335/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2202.0692 - val_loss: 3693.3209\n",
      "Epoch 336/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2202.5911 - val_loss: 3727.1134\n",
      "Epoch 337/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2177.6366 - val_loss: 3713.5206\n",
      "Epoch 338/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2180.0965 - val_loss: 3659.8444\n",
      "Epoch 339/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2200.0487 - val_loss: 3727.1400\n",
      "Epoch 340/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2162.6909 - val_loss: 3681.2024\n",
      "Epoch 341/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2148.0463 - val_loss: 3561.2966\n",
      "Epoch 342/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2159.9012 - val_loss: 3518.3819\n",
      "Epoch 343/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2199.1288 - val_loss: 3692.4945\n",
      "Epoch 344/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2152.8564 - val_loss: 3525.5112\n",
      "Epoch 345/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2160.0506 - val_loss: 3529.9155\n",
      "Epoch 346/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2120.9486 - val_loss: 3445.1041\n",
      "Epoch 347/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2090.7907 - val_loss: 3590.1842\n",
      "Epoch 348/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2068.6767 - val_loss: 3480.3353\n",
      "Epoch 349/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2071.5410 - val_loss: 3512.4458\n",
      "Epoch 350/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2110.6129 - val_loss: 3226.4791\n",
      "Epoch 351/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2227.6095 - val_loss: 3190.1200\n",
      "Epoch 352/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2159.2786 - val_loss: 3385.3361\n",
      "Epoch 353/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2180.1967 - val_loss: 3384.9488\n",
      "Epoch 354/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2178.4936 - val_loss: 3357.5989\n",
      "Epoch 355/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2099.3549 - val_loss: 3409.7602\n",
      "Epoch 356/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2087.8298 - val_loss: 3493.7382\n",
      "Epoch 357/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2150.6739 - val_loss: 3511.4308\n",
      "Epoch 358/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2051.5886 - val_loss: 3440.2496\n",
      "Epoch 359/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2013.5548 - val_loss: 3429.4448\n",
      "Epoch 360/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1929.2121 - val_loss: 3507.1053\n",
      "Epoch 361/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1941.4606 - val_loss: 3527.2757\n",
      "Epoch 362/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2222.3860 - val_loss: 3998.4592\n",
      "Epoch 363/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2306.6433 - val_loss: 4001.7988\n",
      "Epoch 364/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2292.8789 - val_loss: 3887.4961\n",
      "Epoch 365/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2260.3775 - val_loss: 3872.7786\n",
      "Epoch 366/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2290.7475 - val_loss: 3991.8055\n",
      "Epoch 367/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2264.1239 - val_loss: 3971.6766\n",
      "Epoch 368/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2296.6321 - val_loss: 3860.9066\n",
      "Epoch 369/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2244.0894 - val_loss: 3902.4954\n",
      "Epoch 370/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2219.4702 - val_loss: 3919.5426\n",
      "Epoch 371/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2215.2436 - val_loss: 3876.2309\n",
      "Epoch 372/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2238.3180 - val_loss: 3843.1773\n",
      "Epoch 373/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2219.0632 - val_loss: 3834.5941\n",
      "Epoch 374/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2209.4069 - val_loss: 3819.0960\n",
      "Epoch 375/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2215.3092 - val_loss: 3797.0670\n",
      "Epoch 376/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2213.8548 - val_loss: 3754.6995\n",
      "Epoch 377/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2184.3232 - val_loss: 3740.9676\n",
      "Epoch 378/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2194.2964 - val_loss: 3705.8868\n",
      "Epoch 379/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2160.7028 - val_loss: 3692.1761\n",
      "Epoch 380/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2137.1640 - val_loss: 3651.6289\n",
      "Epoch 381/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2157.3272 - val_loss: 3632.0030\n",
      "Epoch 382/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2129.0729 - val_loss: 3606.3206\n",
      "Epoch 383/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2136.5984 - val_loss: 3562.9216\n",
      "Epoch 384/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2164.6881 - val_loss: 3578.4395\n",
      "Epoch 385/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2126.9532 - val_loss: 3512.6890\n",
      "Epoch 386/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2115.1943 - val_loss: 3494.3714\n",
      "Epoch 387/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2072.2509 - val_loss: 3534.4271\n",
      "Epoch 388/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2037.7503 - val_loss: 3641.4883\n",
      "Epoch 389/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2025.3194 - val_loss: 3535.6728\n",
      "Epoch 390/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2013.7983 - val_loss: 3515.4589\n",
      "Epoch 391/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1996.2881 - val_loss: 3633.3556\n",
      "Epoch 392/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1922.3777 - val_loss: 3629.9050\n",
      "Epoch 393/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1958.9840 - val_loss: 3762.5944\n",
      "Epoch 394/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1916.4806 - val_loss: 3757.6428\n",
      "Epoch 395/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1878.4947 - val_loss: 3831.4842\n",
      "Epoch 396/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1851.7746 - val_loss: 3905.7143\n",
      "Epoch 397/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1847.3590 - val_loss: 3901.8203\n",
      "Epoch 398/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1852.3982 - val_loss: 3785.2504\n",
      "Epoch 399/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2032.8689 - val_loss: 3607.3007\n",
      "Epoch 400/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2676.7314 - val_loss: 3556.0602\n",
      "Epoch 401/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2556.0806 - val_loss: 3793.9259\n",
      "Epoch 402/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2627.1659 - val_loss: 3824.6500\n",
      "Epoch 403/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2566.6563 - val_loss: 3583.0047\n",
      "Epoch 404/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2521.8613 - val_loss: 3572.4934\n",
      "Epoch 405/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2435.9891 - val_loss: 3730.5032\n",
      "Epoch 406/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2527.4301 - val_loss: 4651.5940\n",
      "Epoch 407/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2564.4190 - val_loss: 3513.5415\n",
      "Epoch 408/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2496.1496 - val_loss: 3561.0270\n",
      "Epoch 409/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2435.3900 - val_loss: 3519.2804\n",
      "Epoch 410/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2393.9134 - val_loss: 3380.5217\n",
      "Epoch 411/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2483.3608 - val_loss: 3599.7932\n",
      "Epoch 412/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2439.4898 - val_loss: 3972.8163\n",
      "Epoch 413/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2274.4518 - val_loss: 3863.9783\n",
      "Epoch 414/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2324.9295 - val_loss: 3868.6719\n",
      "Epoch 415/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2302.0245 - val_loss: 3792.0752\n",
      "Epoch 416/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2240.2344 - val_loss: 3915.9673\n",
      "Epoch 417/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2290.6992 - val_loss: 3771.9067\n",
      "Epoch 418/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2257.0752 - val_loss: 3626.0416\n",
      "Epoch 419/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2205.5777 - val_loss: 4131.0100\n",
      "Epoch 420/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2384.8162 - val_loss: 3511.4846\n",
      "Epoch 421/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2619.1337 - val_loss: 3406.5858\n",
      "Epoch 422/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2493.6778 - val_loss: 3655.2534\n",
      "Epoch 423/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2433.9346 - val_loss: 3805.7527\n",
      "Epoch 424/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2454.1053 - val_loss: 3615.2771\n",
      "Epoch 425/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2366.5911 - val_loss: 3448.0222\n",
      "Epoch 426/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2339.9085 - val_loss: 3406.9780\n",
      "Epoch 427/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2284.5631 - val_loss: 3489.1763\n",
      "Epoch 428/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2362.0055 - val_loss: 3819.4225\n",
      "Epoch 429/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2274.5886 - val_loss: 3698.5367\n",
      "Epoch 430/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2148.7738 - val_loss: 3641.0284\n",
      "Epoch 431/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2172.3521 - val_loss: 3586.5478\n",
      "Epoch 432/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2203.6286 - val_loss: 3724.9446\n",
      "Epoch 433/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2134.0863 - val_loss: 3493.4608\n",
      "Epoch 434/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2173.3275 - val_loss: 3620.9600\n",
      "Epoch 435/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2160.8280 - val_loss: 3674.1879\n",
      "Epoch 436/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2115.7388 - val_loss: 3581.2965\n",
      "Epoch 437/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2129.7983 - val_loss: 3563.5966\n",
      "Epoch 438/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2114.3658 - val_loss: 3570.6966\n",
      "Epoch 439/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2084.5113 - val_loss: 3585.5217\n",
      "Epoch 440/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2138.1869 - val_loss: 3526.0502\n",
      "Epoch 441/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2135.4513 - val_loss: 3577.0270\n",
      "Epoch 442/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - 0s 1ms/step - loss: 2200.1872 - val_loss: 3717.2981\n",
      "Epoch 443/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2131.6777 - val_loss: 3405.1219\n",
      "Epoch 444/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2197.2009 - val_loss: 3508.5118\n",
      "Epoch 445/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2104.9313 - val_loss: 3727.9218\n",
      "Epoch 446/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2123.0049 - val_loss: 3506.7520\n",
      "Epoch 447/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2124.1976 - val_loss: 3453.8106\n",
      "Epoch 448/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2096.3066 - val_loss: 3568.1204\n",
      "Epoch 449/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2152.7062 - val_loss: 3794.2626\n",
      "Epoch 450/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2104.1268 - val_loss: 3479.4758\n",
      "Epoch 451/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2120.5130 - val_loss: 3413.0219\n",
      "Epoch 452/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2084.4822 - val_loss: 3620.0685\n",
      "Epoch 453/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2118.8300 - val_loss: 3641.6690\n",
      "Epoch 454/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2063.4823 - val_loss: 3419.5759\n",
      "Epoch 455/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2104.2212 - val_loss: 3492.2889\n",
      "Epoch 456/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2078.5581 - val_loss: 3710.1739\n",
      "Epoch 457/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2036.4614 - val_loss: 3549.8285\n",
      "Epoch 458/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2005.5376 - val_loss: 3452.8199\n",
      "Epoch 459/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2028.7836 - val_loss: 3518.6113\n",
      "Epoch 460/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1978.9649 - val_loss: 3538.0122\n",
      "Epoch 461/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2004.1841 - val_loss: 3508.1443\n",
      "Epoch 462/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1971.7987 - val_loss: 3617.9392\n",
      "Epoch 463/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1993.1212 - val_loss: 3602.2615\n",
      "Epoch 464/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1968.7980 - val_loss: 3491.6012\n",
      "Epoch 465/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1961.4060 - val_loss: 3583.3409\n",
      "Epoch 466/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2005.2561 - val_loss: 3564.9033\n",
      "Epoch 467/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1924.3796 - val_loss: 3547.6275\n",
      "Epoch 468/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1940.7907 - val_loss: 3704.6120\n",
      "Epoch 469/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2108.9897 - val_loss: 3423.2056\n",
      "Epoch 470/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2169.2706 - val_loss: 3432.3776\n",
      "Epoch 471/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2080.4291 - val_loss: 3709.4288\n",
      "Epoch 472/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2079.6456 - val_loss: 3717.3062\n",
      "Epoch 473/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1908.2903 - val_loss: 3464.5143\n",
      "Epoch 474/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1983.1282 - val_loss: 3439.0069\n",
      "Epoch 475/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1951.2919 - val_loss: 3532.9615\n",
      "Epoch 476/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1917.6280 - val_loss: 3687.6247\n",
      "Epoch 477/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1998.2076 - val_loss: 3801.7498\n",
      "Epoch 478/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1914.7802 - val_loss: 3604.9150\n",
      "Epoch 479/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1932.0237 - val_loss: 3487.3907\n",
      "Epoch 480/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1972.2257 - val_loss: 3530.8349\n",
      "Epoch 481/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1916.6368 - val_loss: 3678.0168\n",
      "Epoch 482/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1953.0774 - val_loss: 3583.5075\n",
      "Epoch 483/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1880.7865 - val_loss: 3572.8842\n",
      "Epoch 484/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1868.3075 - val_loss: 3541.7234\n",
      "Epoch 485/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1889.1118 - val_loss: 3499.6500\n",
      "Epoch 486/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1867.7107 - val_loss: 3456.6898\n",
      "Epoch 487/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1885.8266 - val_loss: 3494.7344\n",
      "Epoch 488/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1799.0411 - val_loss: 3413.2615\n",
      "Epoch 489/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1843.2474 - val_loss: 3514.5186\n",
      "Epoch 490/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1815.3135 - val_loss: 3472.9187\n",
      "Epoch 491/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1914.1697 - val_loss: 3649.7395\n",
      "Epoch 492/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2011.9469 - val_loss: 3506.4025\n",
      "Epoch 493/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2199.1395 - val_loss: 3558.5673\n",
      "Epoch 494/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1905.4101 - val_loss: 3808.4954\n",
      "Epoch 495/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1998.3008 - val_loss: 3413.1302\n",
      "Epoch 496/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1899.0687 - val_loss: 3381.9272\n",
      "Epoch 497/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1854.0597 - val_loss: 3502.8105\n",
      "Epoch 498/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1832.9342 - val_loss: 3449.2068\n",
      "Epoch 499/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1779.9492 - val_loss: 3459.7418\n",
      "Epoch 500/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1797.9287 - val_loss: 3469.4700\n",
      "Epoch 501/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1802.4533 - val_loss: 3441.2360\n",
      "Epoch 502/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1781.7480 - val_loss: 3399.6328\n",
      "Epoch 503/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1787.4528 - val_loss: 3469.8945\n",
      "Epoch 504/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1707.2866 - val_loss: 3420.3005\n",
      "Epoch 505/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1711.4017 - val_loss: 3390.0901\n",
      "Epoch 506/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1786.7730 - val_loss: 3438.7843\n",
      "Epoch 507/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1825.6981 - val_loss: 3464.1329\n",
      "Epoch 508/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1819.0213 - val_loss: 3502.8011\n",
      "Epoch 509/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1835.7469 - val_loss: 3358.0605\n",
      "Epoch 510/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1777.7023 - val_loss: 3394.4000\n",
      "Epoch 511/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1749.6308 - val_loss: 3374.7465\n",
      "Epoch 512/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1758.9061 - val_loss: 3307.3359\n",
      "Epoch 513/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1736.3251 - val_loss: 3251.7109\n",
      "Epoch 514/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1731.5012 - val_loss: 3362.6503\n",
      "Epoch 515/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1720.9328 - val_loss: 3307.8408\n",
      "Epoch 516/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1716.8608 - val_loss: 3311.6327\n",
      "Epoch 517/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1652.0837 - val_loss: 3256.1950\n",
      "Epoch 518/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1733.3360 - val_loss: 3287.2933\n",
      "Epoch 519/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1854.7401 - val_loss: 3331.0646\n",
      "Epoch 520/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1898.9155 - val_loss: 3388.2205\n",
      "Epoch 521/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1894.8398 - val_loss: 3542.6886\n",
      "Epoch 522/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1800.0714 - val_loss: 3502.7340\n",
      "Epoch 523/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1783.2291 - val_loss: 3426.1401\n",
      "Epoch 524/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1864.5277 - val_loss: 3134.5007\n",
      "Epoch 525/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1893.3310 - val_loss: 3946.2056\n",
      "Epoch 526/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2080.6818 - val_loss: 4918.3848\n",
      "Epoch 527/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2212.6296 - val_loss: 3422.1430\n",
      "Epoch 528/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2542.5452 - val_loss: 3608.7238\n",
      "Epoch 529/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2432.0974 - val_loss: 3670.2372\n",
      "Epoch 530/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2476.9420 - val_loss: 3518.3854\n",
      "Epoch 531/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2196.1631 - val_loss: 3702.1943\n",
      "Epoch 532/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1991.8121 - val_loss: 3664.9923\n",
      "Epoch 533/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2005.6791 - val_loss: 3495.6202\n",
      "Epoch 534/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2110.3555 - val_loss: 3401.8177\n",
      "Epoch 535/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1964.5197 - val_loss: 3635.4213\n",
      "Epoch 536/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1940.8861 - val_loss: 3624.0306\n",
      "Epoch 537/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1921.8349 - val_loss: 3475.6041\n",
      "Epoch 538/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1905.2348 - val_loss: 3426.3823\n",
      "Epoch 539/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1929.0609 - val_loss: 3321.5602\n",
      "Epoch 540/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1887.4244 - val_loss: 3380.3046\n",
      "Epoch 541/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1877.6247 - val_loss: 3471.7162\n",
      "Epoch 542/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1827.0365 - val_loss: 3329.1785\n",
      "Epoch 543/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1827.7625 - val_loss: 3254.9043\n",
      "Epoch 544/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1801.1006 - val_loss: 3327.0691\n",
      "Epoch 545/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1805.2155 - val_loss: 3407.1112\n",
      "Epoch 546/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1830.2963 - val_loss: 3301.3598\n",
      "Epoch 547/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1768.2634 - val_loss: 3285.5851\n",
      "Epoch 548/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1776.9499 - val_loss: 3248.2568\n",
      "Epoch 549/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1720.8895 - val_loss: 3296.5880\n",
      "Epoch 550/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1757.7434 - val_loss: 3312.8288\n",
      "Epoch 551/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1778.2787 - val_loss: 3162.1092\n",
      "Epoch 552/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1717.6175 - val_loss: 3107.4948\n",
      "Epoch 553/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1661.7741 - val_loss: 3097.4795\n",
      "Epoch 554/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1661.6750 - val_loss: 3156.0061\n",
      "Epoch 555/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1647.3990 - val_loss: 3160.5264\n",
      "Epoch 556/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1918.4245 - val_loss: 3499.9168\n",
      "Epoch 557/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1953.6908 - val_loss: 3371.4950\n",
      "Epoch 558/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2091.2112 - val_loss: 3617.3571\n",
      "Epoch 559/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2012.1753 - val_loss: 3681.7574\n",
      "Epoch 560/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1810.5811 - val_loss: 3374.5385\n",
      "Epoch 561/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2206.3099 - val_loss: 3098.7893\n",
      "Epoch 562/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2007.7829 - val_loss: 3402.6731\n",
      "Epoch 563/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2189.4262 - val_loss: 3348.2713\n",
      "Epoch 564/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2012.8399 - val_loss: 3582.8677\n",
      "Epoch 565/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2186.8613 - val_loss: 3576.4093\n",
      "Epoch 566/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2144.5014 - val_loss: 3430.8154\n",
      "Epoch 567/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2069.1977 - val_loss: 3330.8707\n",
      "Epoch 568/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2056.6077 - val_loss: 3390.5334\n",
      "Epoch 569/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2005.2689 - val_loss: 3476.4745\n",
      "Epoch 570/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1997.4237 - val_loss: 3565.6488\n",
      "Epoch 571/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1886.9710 - val_loss: 3310.5870\n",
      "Epoch 572/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1889.2495 - val_loss: 3249.0374\n",
      "Epoch 573/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1860.1492 - val_loss: 3441.6457\n",
      "Epoch 574/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1869.0443 - val_loss: 3745.9800\n",
      "Epoch 575/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2139.0259 - val_loss: 3124.3763\n",
      "Epoch 576/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1927.7786 - val_loss: 3241.2600\n",
      "Epoch 577/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2156.5290 - val_loss: 3437.4592\n",
      "Epoch 578/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2092.0605 - val_loss: 3439.4556\n",
      "Epoch 579/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2019.5826 - val_loss: 3410.8476\n",
      "Epoch 580/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2031.3354 - val_loss: 3755.7959\n",
      "Epoch 581/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1909.5773 - val_loss: 3041.5058\n",
      "Epoch 582/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1903.7998 - val_loss: 3433.9833\n",
      "Epoch 583/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 3047.2957 - val_loss: 5015.4068\n",
      "Epoch 584/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 3332.0931 - val_loss: 4888.2496\n",
      "Epoch 585/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 3329.3060 - val_loss: 4669.8305\n",
      "Epoch 586/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 3404.2231 - val_loss: 4377.6760\n",
      "Epoch 587/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 3234.2606 - val_loss: 4300.9759\n",
      "Epoch 588/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2808.4684 - val_loss: 3209.2120\n",
      "Epoch 589/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2904.5488 - val_loss: 3556.1603\n",
      "Epoch 590/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - 0s 1ms/step - loss: 2659.2745 - val_loss: 3532.1061\n",
      "Epoch 591/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2732.4002 - val_loss: 3645.7976\n",
      "Epoch 592/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2729.4895 - val_loss: 3765.9086\n",
      "Epoch 593/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2724.1199 - val_loss: 3802.4064\n",
      "Epoch 594/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2718.2097 - val_loss: 3725.3601\n",
      "Epoch 595/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2738.8000 - val_loss: 3632.7037\n",
      "Epoch 596/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2747.3716 - val_loss: 3670.8601\n",
      "Epoch 597/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2730.8955 - val_loss: 3734.4000\n",
      "Epoch 598/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2712.4660 - val_loss: 3707.9567\n",
      "Epoch 599/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2724.7174 - val_loss: 3690.4642\n",
      "Epoch 600/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2713.7114 - val_loss: 3678.8371\n",
      "Epoch 601/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2699.8362 - val_loss: 3698.1519\n",
      "Epoch 602/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2711.1075 - val_loss: 3655.6984\n",
      "Epoch 603/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2711.3854 - val_loss: 3699.8010\n",
      "Epoch 604/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2716.1057 - val_loss: 3718.8161\n",
      "Epoch 605/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2716.0009 - val_loss: 3689.6504\n",
      "Epoch 606/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2710.9701 - val_loss: 3697.4182\n",
      "Epoch 607/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2693.8341 - val_loss: 3689.9878\n",
      "Epoch 608/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2707.7275 - val_loss: 3652.3168\n",
      "Epoch 609/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2714.9451 - val_loss: 3691.4923\n",
      "Epoch 610/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2726.5111 - val_loss: 3747.8250\n",
      "Epoch 611/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2714.4572 - val_loss: 3706.5768\n",
      "Epoch 612/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2684.8322 - val_loss: 3646.3784\n",
      "Epoch 613/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2719.6703 - val_loss: 3659.1447\n",
      "Epoch 614/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2731.6691 - val_loss: 3673.1336\n",
      "Epoch 615/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2714.7223 - val_loss: 3733.4692\n",
      "Epoch 616/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2695.0796 - val_loss: 3722.0261\n",
      "Epoch 617/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2738.4950 - val_loss: 3669.2115\n",
      "Epoch 618/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2688.3702 - val_loss: 3696.5990\n",
      "Epoch 619/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2721.6111 - val_loss: 3708.7811\n",
      "Epoch 620/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2680.8479 - val_loss: 3680.2137\n",
      "Epoch 621/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2685.1849 - val_loss: 3648.3198\n",
      "Epoch 622/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2725.3132 - val_loss: 3688.3403\n",
      "Epoch 623/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2677.9997 - val_loss: 3680.1024\n",
      "Epoch 624/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2738.3304 - val_loss: 3633.6343\n",
      "Epoch 625/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2699.1623 - val_loss: 3747.9167\n",
      "Epoch 626/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2711.2650 - val_loss: 3716.5477\n",
      "Epoch 627/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2685.7736 - val_loss: 3738.1892\n",
      "Epoch 628/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2714.4164 - val_loss: 3677.7056\n",
      "Epoch 629/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2727.4254 - val_loss: 3629.5299\n",
      "Epoch 630/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2662.7265 - val_loss: 3679.0367\n",
      "Epoch 631/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2643.1011 - val_loss: 3737.8950\n",
      "Epoch 632/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2684.2448 - val_loss: 3753.4998\n",
      "Epoch 633/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2724.3893 - val_loss: 3713.5501\n",
      "Epoch 634/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2682.7125 - val_loss: 3648.7460\n",
      "Epoch 635/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2685.0546 - val_loss: 3643.8985\n",
      "Epoch 636/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2664.7652 - val_loss: 3719.6795\n",
      "Epoch 637/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2675.1677 - val_loss: 3687.2556\n",
      "Epoch 638/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2691.2055 - val_loss: 3677.5863\n",
      "Epoch 639/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2666.2276 - val_loss: 3700.3100\n",
      "Epoch 640/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2675.6934 - val_loss: 3671.3976\n",
      "Epoch 641/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2659.7343 - val_loss: 3685.8046\n",
      "Epoch 642/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2698.1388 - val_loss: 3720.6340\n",
      "Epoch 643/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2689.8848 - val_loss: 3663.8875\n",
      "Epoch 644/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2655.3094 - val_loss: 3675.9721\n",
      "Epoch 645/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2635.1348 - val_loss: 3702.8275\n",
      "Epoch 646/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2689.3952 - val_loss: 3659.4234\n",
      "Epoch 647/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2679.2127 - val_loss: 3678.7876\n",
      "Epoch 648/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2675.6866 - val_loss: 3669.7841\n",
      "Epoch 649/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2649.4636 - val_loss: 3715.4045\n",
      "Epoch 650/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2645.9531 - val_loss: 3726.3662\n",
      "Epoch 651/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2651.7720 - val_loss: 3676.1806\n",
      "Epoch 652/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2635.7111 - val_loss: 3651.1874\n",
      "Epoch 653/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2657.6187 - val_loss: 3625.5647\n",
      "Epoch 654/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2655.8042 - val_loss: 3675.1425\n",
      "Epoch 655/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2690.1054 - val_loss: 3782.7589\n",
      "Epoch 656/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2703.8537 - val_loss: 3727.7026\n",
      "Epoch 657/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2645.1328 - val_loss: 3661.2552\n",
      "Epoch 658/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2665.4953 - val_loss: 3641.1618\n",
      "Epoch 659/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2660.7988 - val_loss: 3628.2845\n",
      "Epoch 660/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2635.5495 - val_loss: 3692.9627\n",
      "Epoch 661/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2668.0798 - val_loss: 3772.3956\n",
      "Epoch 662/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2639.9498 - val_loss: 3704.2012\n",
      "Epoch 663/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2616.4900 - val_loss: 3661.6293\n",
      "Epoch 664/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2631.6174 - val_loss: 3612.8734\n",
      "Epoch 665/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2628.3636 - val_loss: 3632.3931\n",
      "Epoch 666/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2625.4736 - val_loss: 3743.4266\n",
      "Epoch 667/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2618.5352 - val_loss: 3738.2839\n",
      "Epoch 668/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2611.5595 - val_loss: 3667.3610\n",
      "Epoch 669/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2620.5592 - val_loss: 3654.5130\n",
      "Epoch 670/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2594.1606 - val_loss: 3686.1001\n",
      "Epoch 671/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2633.9826 - val_loss: 3679.3622\n",
      "Epoch 672/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2596.0533 - val_loss: 3673.4053\n",
      "Epoch 673/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2639.7822 - val_loss: 3702.8379\n",
      "Epoch 674/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2618.6644 - val_loss: 3638.4006\n",
      "Epoch 675/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2607.2516 - val_loss: 3668.6801\n",
      "Epoch 676/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2561.0663 - val_loss: 3677.2419\n",
      "Epoch 677/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2659.2949 - val_loss: 3751.9791\n",
      "Epoch 678/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2590.6350 - val_loss: 3671.1848\n",
      "Epoch 679/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2585.7982 - val_loss: 3641.9352\n",
      "Epoch 680/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2606.4109 - val_loss: 3651.2390\n",
      "Epoch 681/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2611.1757 - val_loss: 3708.9425\n",
      "Epoch 682/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2659.0681 - val_loss: 3837.2186\n",
      "Epoch 683/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2592.3553 - val_loss: 3700.9727\n",
      "Epoch 684/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2573.3460 - val_loss: 3633.4826\n",
      "Epoch 685/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2642.4901 - val_loss: 3611.6912\n",
      "Epoch 686/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2578.5023 - val_loss: 3724.0045\n",
      "Epoch 687/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2578.8677 - val_loss: 3830.4941\n",
      "Epoch 688/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2598.6623 - val_loss: 3773.6661\n",
      "Epoch 689/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2564.1903 - val_loss: 3645.8921\n",
      "Epoch 690/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2619.2103 - val_loss: 3639.6163\n",
      "Epoch 691/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2577.3505 - val_loss: 3716.9073\n",
      "Epoch 692/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2564.3505 - val_loss: 3708.6657\n",
      "Epoch 693/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2588.5354 - val_loss: 3736.9322\n",
      "Epoch 694/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2562.7443 - val_loss: 3718.6534\n",
      "Epoch 695/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2523.0663 - val_loss: 3709.0831\n",
      "Epoch 696/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2589.4873 - val_loss: 3706.0378\n",
      "Epoch 697/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2554.9147 - val_loss: 3664.3581\n",
      "Epoch 698/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2599.0660 - val_loss: 3669.7271\n",
      "Epoch 699/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2550.4409 - val_loss: 3734.5268\n",
      "Epoch 700/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2529.2754 - val_loss: 3775.0621\n",
      "Epoch 701/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2600.3253 - val_loss: 3806.6942\n",
      "Epoch 702/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2556.4536 - val_loss: 3666.7825\n",
      "Epoch 703/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2600.7512 - val_loss: 3628.7454\n",
      "Epoch 704/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2551.2704 - val_loss: 3746.9166\n",
      "Epoch 705/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2564.1083 - val_loss: 3791.1212\n",
      "Epoch 706/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2538.6233 - val_loss: 3764.3727\n",
      "Epoch 707/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2539.2189 - val_loss: 3706.4003\n",
      "Epoch 708/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2487.1815 - val_loss: 3661.4412\n",
      "Epoch 709/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2529.3418 - val_loss: 3713.8964\n",
      "Epoch 710/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2533.5414 - val_loss: 3739.8504\n",
      "Epoch 711/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2508.7169 - val_loss: 3769.6272\n",
      "Epoch 712/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2561.9281 - val_loss: 3750.6758\n",
      "Epoch 713/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2530.4595 - val_loss: 3731.3972\n",
      "Epoch 714/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2525.8837 - val_loss: 3696.5471\n",
      "Epoch 715/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2501.2662 - val_loss: 3724.9836\n",
      "Epoch 716/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2524.8418 - val_loss: 3712.6171\n",
      "Epoch 717/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2559.6596 - val_loss: 3748.3158\n",
      "Epoch 718/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2506.6777 - val_loss: 3755.3095\n",
      "Epoch 719/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2544.5855 - val_loss: 3827.8806\n",
      "Epoch 720/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2489.0391 - val_loss: 3694.4026\n",
      "Epoch 721/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2516.5774 - val_loss: 3662.5399\n",
      "Epoch 722/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2524.2970 - val_loss: 3734.8160\n",
      "Epoch 723/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2493.8802 - val_loss: 3850.8643\n",
      "Epoch 724/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2503.2420 - val_loss: 3805.3473\n",
      "Epoch 725/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2453.6904 - val_loss: 3760.1071\n",
      "Epoch 726/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2505.4254 - val_loss: 3696.2614\n",
      "Epoch 727/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2505.6201 - val_loss: 3762.3915\n",
      "Epoch 728/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2490.7099 - val_loss: 3796.2850\n",
      "Epoch 729/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2440.7999 - val_loss: 3800.7594\n",
      "Epoch 730/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2513.6326 - val_loss: 3775.6012\n",
      "Epoch 731/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2471.5837 - val_loss: 3812.1816\n",
      "Epoch 732/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2502.3021 - val_loss: 3729.0430\n",
      "Epoch 733/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2460.7232 - val_loss: 3741.6030\n",
      "Epoch 734/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2471.1796 - val_loss: 3856.8728\n",
      "Epoch 735/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2446.6348 - val_loss: 3827.7019\n",
      "Epoch 736/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2410.0094 - val_loss: 3775.8896\n",
      "Epoch 737/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2391.7804 - val_loss: 3750.0539\n",
      "Epoch 738/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - 0s 1ms/step - loss: 2403.7087 - val_loss: 3814.2324\n",
      "Epoch 739/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2442.0206 - val_loss: 3925.1009\n",
      "Epoch 740/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2369.5739 - val_loss: 3798.1577\n",
      "Epoch 741/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2360.2294 - val_loss: 3752.8758\n",
      "Epoch 742/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2413.2677 - val_loss: 3766.0450\n",
      "Epoch 743/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2404.8101 - val_loss: 3950.0495\n",
      "Epoch 744/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2399.3184 - val_loss: 3975.0186\n",
      "Epoch 745/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2385.9405 - val_loss: 3776.8339\n",
      "Epoch 746/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2443.7350 - val_loss: 3769.2820\n",
      "Epoch 747/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2421.4657 - val_loss: 4053.4282\n",
      "Epoch 748/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2409.0498 - val_loss: 3919.9598\n",
      "Epoch 749/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2351.4501 - val_loss: 3909.8267\n",
      "Epoch 750/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2395.7711 - val_loss: 3836.8012\n",
      "Epoch 751/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2329.0610 - val_loss: 3866.5577\n",
      "Epoch 752/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2344.8596 - val_loss: 3940.8702\n",
      "Epoch 753/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2358.1448 - val_loss: 3858.3279\n",
      "Epoch 754/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2329.5359 - val_loss: 3908.1426\n",
      "Epoch 755/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2312.6903 - val_loss: 3866.1255\n",
      "Epoch 756/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2325.6168 - val_loss: 3855.6037\n",
      "Epoch 757/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2341.9708 - val_loss: 3854.6899\n",
      "Epoch 758/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2336.4056 - val_loss: 3909.6300\n",
      "Epoch 759/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2331.5988 - val_loss: 3914.5486\n",
      "Epoch 760/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2298.3077 - val_loss: 3880.3151\n",
      "Epoch 761/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2303.7014 - val_loss: 3863.3786\n",
      "Epoch 762/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2316.3224 - val_loss: 3826.7114\n",
      "Epoch 763/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2313.7176 - val_loss: 3883.6750\n",
      "Epoch 764/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2282.6262 - val_loss: 3995.8056\n",
      "Epoch 765/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2334.1315 - val_loss: 3980.3352\n",
      "Epoch 766/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2320.2184 - val_loss: 3846.6240\n",
      "Epoch 767/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2307.4284 - val_loss: 3874.5676\n",
      "Epoch 768/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2297.0707 - val_loss: 3900.5570\n",
      "Epoch 769/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2296.3255 - val_loss: 3889.8249\n",
      "Epoch 770/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2291.4768 - val_loss: 3868.7166\n",
      "Epoch 771/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2312.9822 - val_loss: 3840.4781\n",
      "Epoch 772/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2358.0310 - val_loss: 3962.2472\n",
      "Epoch 773/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2299.9562 - val_loss: 3872.8674\n",
      "Epoch 774/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2307.0098 - val_loss: 3837.7152\n",
      "Epoch 775/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2325.1902 - val_loss: 3909.8866\n",
      "Epoch 776/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2268.4254 - val_loss: 4025.9923\n",
      "Epoch 777/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2313.3731 - val_loss: 3947.5214\n",
      "Epoch 778/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2338.8015 - val_loss: 3929.3499\n",
      "Epoch 779/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2286.1889 - val_loss: 3828.0907\n",
      "Epoch 780/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2267.0783 - val_loss: 3890.0481\n",
      "Epoch 781/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2315.3468 - val_loss: 4026.5474\n",
      "Epoch 782/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2310.2655 - val_loss: 3940.8969\n",
      "Epoch 783/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2266.3953 - val_loss: 3893.3878\n",
      "Epoch 784/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2291.3970 - val_loss: 3837.6957\n",
      "Epoch 785/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2341.5741 - val_loss: 3934.7019\n",
      "Epoch 786/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2287.8657 - val_loss: 3922.8049\n",
      "Epoch 787/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2308.1241 - val_loss: 3954.9794\n",
      "Epoch 788/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2299.0683 - val_loss: 3919.1398\n",
      "Epoch 789/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2273.5661 - val_loss: 3886.5232\n",
      "Epoch 790/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2275.1619 - val_loss: 3940.0436\n",
      "Epoch 791/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2289.7169 - val_loss: 3902.3259\n",
      "Epoch 792/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2288.5370 - val_loss: 3917.8961\n",
      "Epoch 793/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2289.5918 - val_loss: 3934.0373\n",
      "Epoch 794/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2264.3279 - val_loss: 3930.2717\n",
      "Epoch 795/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2313.9429 - val_loss: 3963.4789\n",
      "Epoch 796/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2278.2052 - val_loss: 3858.2603\n",
      "Epoch 797/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2268.6255 - val_loss: 3939.3311\n",
      "Epoch 798/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2300.4269 - val_loss: 3939.1250\n",
      "Epoch 799/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2266.0190 - val_loss: 3899.9043\n",
      "Epoch 800/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2255.4416 - val_loss: 3946.0161\n",
      "Epoch 801/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2325.8770 - val_loss: 3973.3568\n",
      "Epoch 802/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2262.5724 - val_loss: 3939.3957\n",
      "Epoch 803/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2271.8714 - val_loss: 3903.7577\n",
      "Epoch 804/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2259.5066 - val_loss: 3946.1173\n",
      "Epoch 805/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2287.3585 - val_loss: 3932.3297\n",
      "Epoch 806/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2249.7670 - val_loss: 3943.6516\n",
      "Epoch 807/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2258.3682 - val_loss: 3943.0017\n",
      "Epoch 808/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2306.8435 - val_loss: 4001.7766\n",
      "Epoch 809/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2270.1947 - val_loss: 3936.2310\n",
      "Epoch 810/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2314.8970 - val_loss: 3839.2338\n",
      "Epoch 811/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2327.6762 - val_loss: 4055.7946\n",
      "Epoch 812/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2301.8135 - val_loss: 3973.9289\n",
      "Epoch 813/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2277.4681 - val_loss: 3942.6894\n",
      "Epoch 814/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2285.3526 - val_loss: 3879.7263\n",
      "Epoch 815/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2225.9993 - val_loss: 4032.8928\n",
      "Epoch 816/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2220.6957 - val_loss: 4034.3879\n",
      "Epoch 817/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2224.4819 - val_loss: 3897.7371\n",
      "Epoch 818/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2197.9074 - val_loss: 3893.3855\n",
      "Epoch 819/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2218.6235 - val_loss: 4004.8188\n",
      "Epoch 820/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2212.8797 - val_loss: 3941.1055\n",
      "Epoch 821/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2185.7585 - val_loss: 4028.8401\n",
      "Epoch 822/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2130.1562 - val_loss: 4024.6151\n",
      "Epoch 823/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2145.2217 - val_loss: 4054.2327\n",
      "Epoch 824/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2130.3195 - val_loss: 4078.1671\n",
      "Epoch 825/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2133.3762 - val_loss: 4076.6242\n",
      "Epoch 826/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2111.3383 - val_loss: 4219.2727\n",
      "Epoch 827/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2067.2425 - val_loss: 4370.8704\n",
      "Epoch 828/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2095.2356 - val_loss: 4371.3004\n",
      "Epoch 829/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2056.4783 - val_loss: 4391.8554\n",
      "Epoch 830/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2096.1904 - val_loss: 4386.0815\n",
      "Epoch 831/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2065.9620 - val_loss: 4472.0678\n",
      "Epoch 832/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2065.7100 - val_loss: 4470.3501\n",
      "Epoch 833/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2040.8197 - val_loss: 4485.1882\n",
      "Epoch 834/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2049.1597 - val_loss: 4551.1253\n",
      "Epoch 835/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2035.4559 - val_loss: 4603.8197\n",
      "Epoch 836/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2054.5974 - val_loss: 4577.2814\n",
      "Epoch 837/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2022.4029 - val_loss: 4492.2998\n",
      "Epoch 838/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2087.9279 - val_loss: 4405.2684\n",
      "Epoch 839/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2035.2891 - val_loss: 4510.1617\n",
      "Epoch 840/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2019.1899 - val_loss: 4614.0743\n",
      "Epoch 841/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2060.2549 - val_loss: 4608.7585\n",
      "Epoch 842/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2078.6178 - val_loss: 4405.7968\n",
      "Epoch 843/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2094.5472 - val_loss: 4415.9380\n",
      "Epoch 844/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2034.6068 - val_loss: 4433.5178\n",
      "Epoch 845/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2022.2437 - val_loss: 4421.8364\n",
      "Epoch 846/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2013.5133 - val_loss: 4446.9927\n",
      "Epoch 847/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2062.6828 - val_loss: 4461.4696\n",
      "Epoch 848/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2020.0540 - val_loss: 4526.1286\n",
      "Epoch 849/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2047.6691 - val_loss: 4441.4258\n",
      "Epoch 850/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2027.1538 - val_loss: 4383.5861\n",
      "Epoch 851/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2036.8747 - val_loss: 4464.5997\n",
      "Epoch 852/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2026.9193 - val_loss: 4487.5285\n",
      "Epoch 853/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2023.0933 - val_loss: 4485.2924\n",
      "Epoch 854/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2021.9535 - val_loss: 4388.2000\n",
      "Epoch 855/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2032.4639 - val_loss: 4393.6627\n",
      "Epoch 856/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1999.1601 - val_loss: 4322.9187\n",
      "Epoch 857/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2037.9643 - val_loss: 4310.6387\n",
      "Epoch 858/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1972.3868 - val_loss: 4390.6721\n",
      "Epoch 859/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2011.5144 - val_loss: 4437.0910\n",
      "Epoch 860/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1995.6050 - val_loss: 4396.1478\n",
      "Epoch 861/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2010.1057 - val_loss: 4419.7406\n",
      "Epoch 862/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2001.2435 - val_loss: 4331.8143\n",
      "Epoch 863/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2057.8952 - val_loss: 4318.5941\n",
      "Epoch 864/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2040.9709 - val_loss: 4383.0405\n",
      "Epoch 865/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2009.5412 - val_loss: 4542.8277\n",
      "Epoch 866/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2012.4833 - val_loss: 4457.9061\n",
      "Epoch 867/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2006.0983 - val_loss: 4344.4869\n",
      "Epoch 868/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2064.3653 - val_loss: 4294.3000\n",
      "Epoch 869/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1974.4194 - val_loss: 4370.1181\n",
      "Epoch 870/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2049.6522 - val_loss: 4474.9139\n",
      "Epoch 871/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2010.6347 - val_loss: 4397.8657\n",
      "Epoch 872/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2042.3533 - val_loss: 4353.8675\n",
      "Epoch 873/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2005.4126 - val_loss: 4282.3952\n",
      "Epoch 874/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1982.5621 - val_loss: 4271.4117\n",
      "Epoch 875/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1981.5328 - val_loss: 4346.7547\n",
      "Epoch 876/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1964.7701 - val_loss: 4437.3106\n",
      "Epoch 877/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1998.9473 - val_loss: 4408.3784\n",
      "Epoch 878/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1990.7576 - val_loss: 4346.3836\n",
      "Epoch 879/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1985.6135 - val_loss: 4313.3285\n",
      "Epoch 880/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2001.9447 - val_loss: 4294.8107\n",
      "Epoch 881/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1953.0637 - val_loss: 4510.3262\n",
      "Epoch 882/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2036.7487 - val_loss: 4521.5509\n",
      "Epoch 883/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2006.2658 - val_loss: 4275.8808\n",
      "Epoch 884/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1996.3933 - val_loss: 4315.8532\n",
      "Epoch 885/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1971.6728 - val_loss: 4567.4677\n",
      "Epoch 886/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - 0s 1ms/step - loss: 2019.6389 - val_loss: 4364.1049\n",
      "Epoch 887/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2005.5457 - val_loss: 4303.0896\n",
      "Epoch 888/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1993.6437 - val_loss: 4361.2421\n",
      "Epoch 889/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1929.5433 - val_loss: 4402.6723\n",
      "Epoch 890/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2007.1347 - val_loss: 4413.8616\n",
      "Epoch 891/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2033.5512 - val_loss: 4476.8090\n",
      "Epoch 892/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2009.8452 - val_loss: 4318.0273\n",
      "Epoch 893/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2000.2727 - val_loss: 4407.8778\n",
      "Epoch 894/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2013.0270 - val_loss: 4543.3389\n",
      "Epoch 895/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2008.5683 - val_loss: 4366.2496\n",
      "Epoch 896/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1977.4664 - val_loss: 4490.9509\n",
      "Epoch 897/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1997.7454 - val_loss: 4471.0337\n",
      "Epoch 898/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1964.9903 - val_loss: 4222.7341\n",
      "Epoch 899/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1977.6203 - val_loss: 4388.5403\n",
      "Epoch 900/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1996.9101 - val_loss: 4688.7628\n",
      "Epoch 901/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1972.6911 - val_loss: 4401.1606\n",
      "Epoch 902/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1995.5741 - val_loss: 4476.5091\n",
      "Epoch 903/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1994.5591 - val_loss: 4934.4415\n",
      "Epoch 904/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2056.8393 - val_loss: 4286.9657\n",
      "Epoch 905/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1994.6986 - val_loss: 4264.8439\n",
      "Epoch 906/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1952.1327 - val_loss: 4421.7521\n",
      "Epoch 907/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1998.9612 - val_loss: 4465.8668\n",
      "Epoch 908/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1955.8242 - val_loss: 4237.4154\n",
      "Epoch 909/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1945.6501 - val_loss: 4182.4078\n",
      "Epoch 910/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1922.4917 - val_loss: 4336.9952\n",
      "Epoch 911/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1959.8123 - val_loss: 4331.3772\n",
      "Epoch 912/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1974.9924 - val_loss: 4197.5820\n",
      "Epoch 913/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1984.4395 - val_loss: 4336.6632\n",
      "Epoch 914/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1961.2834 - val_loss: 4431.3423\n",
      "Epoch 915/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1957.0742 - val_loss: 4433.9401\n",
      "Epoch 916/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1958.6693 - val_loss: 4254.4787\n",
      "Epoch 917/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1943.8115 - val_loss: 4283.2186\n",
      "Epoch 918/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1963.0027 - val_loss: 4431.0473\n",
      "Epoch 919/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1955.7542 - val_loss: 4402.4969\n",
      "Epoch 920/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1961.6095 - val_loss: 4144.8304\n",
      "Epoch 921/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1932.8574 - val_loss: 4420.7764\n",
      "Epoch 922/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2000.0359 - val_loss: 4430.3710\n",
      "Epoch 923/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2057.4136 - val_loss: 4004.1056\n",
      "Epoch 924/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1954.1610 - val_loss: 4460.3907\n",
      "Epoch 925/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1974.7766 - val_loss: 4650.6479\n",
      "Epoch 926/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1997.8290 - val_loss: 4196.1540\n",
      "Epoch 927/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1960.1149 - val_loss: 4079.0593\n",
      "Epoch 928/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1909.8769 - val_loss: 4237.2456\n",
      "Epoch 929/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1930.8526 - val_loss: 4290.9958\n",
      "Epoch 930/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1943.8224 - val_loss: 4185.0577\n",
      "Epoch 931/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2012.4163 - val_loss: 4501.2534\n",
      "Epoch 932/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1985.4877 - val_loss: 4176.0801\n",
      "Epoch 933/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1967.3917 - val_loss: 3951.2414\n",
      "Epoch 934/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1945.8939 - val_loss: 4061.7129\n",
      "Epoch 935/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1962.1505 - val_loss: 4550.4489\n",
      "Epoch 936/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1949.7581 - val_loss: 4119.0253\n",
      "Epoch 937/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1975.1024 - val_loss: 3811.8830\n",
      "Epoch 938/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1941.4556 - val_loss: 4205.5798\n",
      "Epoch 939/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1942.9271 - val_loss: 4320.2975\n",
      "Epoch 940/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1960.8140 - val_loss: 4111.3716\n",
      "Epoch 941/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1917.3751 - val_loss: 4125.0923\n",
      "Epoch 942/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1953.7564 - val_loss: 4294.4715\n",
      "Epoch 943/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1932.1821 - val_loss: 4002.6638\n",
      "Epoch 944/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1922.1556 - val_loss: 4109.8659\n",
      "Epoch 945/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1955.4471 - val_loss: 4199.2787\n",
      "Epoch 946/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1958.2104 - val_loss: 4106.7097\n",
      "Epoch 947/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1917.3735 - val_loss: 4022.6648\n",
      "Epoch 948/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1943.9403 - val_loss: 4072.7878\n",
      "Epoch 949/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1904.3588 - val_loss: 4167.1649\n",
      "Epoch 950/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1928.1317 - val_loss: 4174.4310\n",
      "Epoch 951/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1934.7380 - val_loss: 4028.9298\n",
      "Epoch 952/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1953.5775 - val_loss: 4138.4596\n",
      "Epoch 953/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1914.5960 - val_loss: 4072.3421\n",
      "Epoch 954/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1932.2465 - val_loss: 4036.5901\n",
      "Epoch 955/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1932.7030 - val_loss: 4248.7254\n",
      "Epoch 956/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1956.2054 - val_loss: 4088.7089\n",
      "Epoch 957/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1948.9817 - val_loss: 4121.8114\n",
      "Epoch 958/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1935.5602 - val_loss: 4065.5906\n",
      "Epoch 959/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1954.2862 - val_loss: 4088.7915\n",
      "Epoch 960/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1935.2875 - val_loss: 4144.7522\n",
      "Epoch 961/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1939.1194 - val_loss: 4074.9796\n",
      "Epoch 962/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1947.3891 - val_loss: 4093.1338\n",
      "Epoch 963/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1907.7860 - val_loss: 4093.3720\n",
      "Epoch 964/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1953.3859 - val_loss: 4232.6869\n",
      "Epoch 965/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1957.7094 - val_loss: 4069.2741\n",
      "Epoch 966/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1937.4671 - val_loss: 4053.9374\n",
      "Epoch 967/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1960.9947 - val_loss: 4156.8569\n",
      "Epoch 968/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1964.0461 - val_loss: 4032.7919\n",
      "Epoch 969/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1935.2669 - val_loss: 4006.9661\n",
      "Epoch 970/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1918.2139 - val_loss: 4020.7963\n",
      "Epoch 971/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1968.4375 - val_loss: 4320.3947\n",
      "Epoch 972/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1949.9745 - val_loss: 4063.2792\n",
      "Epoch 973/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1913.8799 - val_loss: 4088.8782\n",
      "Epoch 974/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1931.1570 - val_loss: 4216.7691\n",
      "Epoch 975/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1939.0635 - val_loss: 4029.8249\n",
      "Epoch 976/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1921.1140 - val_loss: 3982.7858\n",
      "Epoch 977/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1910.0375 - val_loss: 4130.5474\n",
      "Epoch 978/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1949.1937 - val_loss: 4000.1200\n",
      "Epoch 979/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1957.6225 - val_loss: 4064.3125\n",
      "Epoch 980/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1946.0335 - val_loss: 3955.9188\n",
      "Epoch 981/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1956.8804 - val_loss: 3994.1648\n",
      "Epoch 982/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1931.1378 - val_loss: 4015.3197\n",
      "Epoch 983/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1941.7190 - val_loss: 4247.7882\n",
      "Epoch 984/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1952.2284 - val_loss: 4211.2999\n",
      "Epoch 985/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1944.6076 - val_loss: 4145.7888\n",
      "Epoch 986/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1972.7622 - val_loss: 4061.8284\n",
      "Epoch 987/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1954.9389 - val_loss: 4219.5146\n",
      "Epoch 988/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1933.3685 - val_loss: 4185.6817\n",
      "Epoch 989/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1917.9701 - val_loss: 3991.7471\n",
      "Epoch 990/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1926.9312 - val_loss: 4167.1148\n",
      "Epoch 991/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1952.0626 - val_loss: 3872.6223\n",
      "Epoch 992/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1931.3808 - val_loss: 4114.7455\n",
      "Epoch 993/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1942.9357 - val_loss: 3906.0276\n",
      "Epoch 994/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1942.9510 - val_loss: 4067.7898\n",
      "Epoch 995/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1954.7155 - val_loss: 4110.5852\n",
      "Epoch 996/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1988.0927 - val_loss: 4203.6484\n",
      "Epoch 997/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1940.8543 - val_loss: 4056.6823\n",
      "Epoch 998/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1972.5412 - val_loss: 4160.1938\n",
      "Epoch 999/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1904.8623 - val_loss: 3902.4128\n",
      "Epoch 1000/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1924.3963 - val_loss: 4002.8569\n",
      "Epoch 1001/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1938.8621 - val_loss: 3915.1095\n",
      "Epoch 1002/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1930.1314 - val_loss: 3903.6264\n",
      "Epoch 1003/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1939.5488 - val_loss: 3858.2051\n",
      "Epoch 1004/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1909.7389 - val_loss: 3903.8580\n",
      "Epoch 1005/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1915.0524 - val_loss: 4043.6372\n",
      "Epoch 1006/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1899.3366 - val_loss: 4129.8889\n",
      "Epoch 1007/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1963.6913 - val_loss: 4158.4685\n",
      "Epoch 1008/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1914.0506 - val_loss: 4114.2901\n",
      "Epoch 1009/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1942.1767 - val_loss: 3886.7815\n",
      "Epoch 1010/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1921.0094 - val_loss: 4174.1558\n",
      "Epoch 1011/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1915.9126 - val_loss: 3921.5408\n",
      "Epoch 1012/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1900.6499 - val_loss: 3814.1817\n",
      "Epoch 1013/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1917.3107 - val_loss: 4006.1321\n",
      "Epoch 1014/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1912.9729 - val_loss: 3892.1889\n",
      "Epoch 1015/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1941.5936 - val_loss: 3845.4219\n",
      "Epoch 1016/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1927.8387 - val_loss: 4017.3712\n",
      "Epoch 1017/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1922.5196 - val_loss: 3777.8407\n",
      "Epoch 1018/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1913.2546 - val_loss: 3681.4405\n",
      "Epoch 1019/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1909.6930 - val_loss: 3936.6168\n",
      "Epoch 1020/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1907.0854 - val_loss: 3760.8014\n",
      "Epoch 1021/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1950.9483 - val_loss: 3652.4074\n",
      "Epoch 1022/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1910.1351 - val_loss: 3854.4246\n",
      "Epoch 1023/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1903.0609 - val_loss: 3939.3441\n",
      "Epoch 1024/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1921.8478 - val_loss: 3744.0736\n",
      "Epoch 1025/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1907.1266 - val_loss: 3770.7209\n",
      "Epoch 1026/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1883.1947 - val_loss: 3873.1279\n",
      "Epoch 1027/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1907.8366 - val_loss: 3836.8790\n",
      "Epoch 1028/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1872.0874 - val_loss: 3714.0776\n",
      "Epoch 1029/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1925.0387 - val_loss: 3714.4203\n",
      "Epoch 1030/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1917.3718 - val_loss: 3748.3228\n",
      "Epoch 1031/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1881.2072 - val_loss: 3843.0677\n",
      "Epoch 1032/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1918.3096 - val_loss: 3881.5458\n",
      "Epoch 1033/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1903.5996 - val_loss: 3635.2156\n",
      "Epoch 1034/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - 0s 1ms/step - loss: 1916.1519 - val_loss: 3848.3059\n",
      "Epoch 1035/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1914.4457 - val_loss: 3833.4914\n",
      "Epoch 1036/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1895.5773 - val_loss: 3627.9975\n",
      "Epoch 1037/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1899.4839 - val_loss: 3808.8498\n",
      "Epoch 1038/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1909.6351 - val_loss: 3815.2652\n",
      "Epoch 1039/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1916.1522 - val_loss: 3739.5847\n",
      "Epoch 1040/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1878.7998 - val_loss: 3722.7947\n",
      "Epoch 1041/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1937.4000 - val_loss: 3797.6348\n",
      "Epoch 1042/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1889.1837 - val_loss: 3854.3774\n",
      "Epoch 1043/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1955.1486 - val_loss: 3943.9129\n",
      "Epoch 1044/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1916.1994 - val_loss: 3685.4764\n",
      "Epoch 1045/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1939.4813 - val_loss: 4097.1164\n",
      "Epoch 1046/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1945.9189 - val_loss: 3761.2578\n",
      "Epoch 1047/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1862.5113 - val_loss: 3701.4806\n",
      "Epoch 1048/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1911.4045 - val_loss: 3714.6909\n",
      "Epoch 1049/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1898.2418 - val_loss: 3695.4085\n",
      "Epoch 1050/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1891.7118 - val_loss: 3721.2646\n",
      "Epoch 1051/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1904.5637 - val_loss: 3660.5712\n",
      "Epoch 1052/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1903.0634 - val_loss: 3789.6620\n",
      "Epoch 1053/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1898.7233 - val_loss: 3930.4140\n",
      "Epoch 1054/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1918.2550 - val_loss: 3665.0298\n",
      "Epoch 1055/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1893.8120 - val_loss: 3625.6568\n",
      "Epoch 1056/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1897.6736 - val_loss: 3897.0494\n",
      "Epoch 1057/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1930.5280 - val_loss: 3876.0240\n",
      "Epoch 1058/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1859.7419 - val_loss: 3579.9213\n",
      "Epoch 1059/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1886.5329 - val_loss: 3709.5683\n",
      "Epoch 1060/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1916.0437 - val_loss: 3924.7497\n",
      "Epoch 1061/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1890.1295 - val_loss: 3725.0371\n",
      "Epoch 1062/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1898.3851 - val_loss: 3674.7231\n",
      "Epoch 1063/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1912.3661 - val_loss: 3974.2474\n",
      "Epoch 1064/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1878.4172 - val_loss: 3740.6401\n",
      "Epoch 1065/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1900.3131 - val_loss: 3637.4680\n",
      "Epoch 1066/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1871.1776 - val_loss: 3892.2297\n",
      "Epoch 1067/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1924.4442 - val_loss: 3931.0493\n",
      "Epoch 1068/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1883.1006 - val_loss: 3676.1082\n",
      "Epoch 1069/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1887.4298 - val_loss: 3816.7831\n",
      "Epoch 1070/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1861.5969 - val_loss: 3727.4331\n",
      "Epoch 1071/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1911.9654 - val_loss: 3843.9754\n",
      "Epoch 1072/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1927.5031 - val_loss: 3948.8004\n",
      "Epoch 1073/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1885.4105 - val_loss: 3701.5024\n",
      "Epoch 1074/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1933.4928 - val_loss: 3999.1031\n",
      "Epoch 1075/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1886.7353 - val_loss: 4064.8871\n",
      "Epoch 1076/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1881.8704 - val_loss: 3987.8956\n",
      "Epoch 1077/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1875.4934 - val_loss: 3675.5537\n",
      "Epoch 1078/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1875.0303 - val_loss: 4036.3178\n",
      "Epoch 1079/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1895.1061 - val_loss: 3710.7363\n",
      "Epoch 1080/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1896.3439 - val_loss: 3963.9735\n",
      "Epoch 1081/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1948.9027 - val_loss: 3853.7065\n",
      "Epoch 1082/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1879.1535 - val_loss: 4040.4626\n",
      "Epoch 1083/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1849.1540 - val_loss: 4020.1827\n",
      "Epoch 1084/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1870.7868 - val_loss: 4076.4696\n",
      "Epoch 1085/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1859.0032 - val_loss: 3832.2268\n",
      "Epoch 1086/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1878.5816 - val_loss: 3735.5326\n",
      "Epoch 1087/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1879.8191 - val_loss: 4001.3001\n",
      "Epoch 1088/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1864.6536 - val_loss: 3975.3199\n",
      "Epoch 1089/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1884.4950 - val_loss: 3843.3262\n",
      "Epoch 1090/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1834.8748 - val_loss: 4112.5033\n",
      "Epoch 1091/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1852.7330 - val_loss: 3991.3371\n",
      "Epoch 1092/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1862.8520 - val_loss: 4075.7703\n",
      "Epoch 1093/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1850.4379 - val_loss: 4130.5426\n",
      "Epoch 1094/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1832.3594 - val_loss: 4129.8315\n",
      "Epoch 1095/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1814.6044 - val_loss: 4096.0404\n",
      "Epoch 1096/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1852.7316 - val_loss: 4019.9222\n",
      "Epoch 1097/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1808.2822 - val_loss: 4150.5595\n",
      "Epoch 1098/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1820.6454 - val_loss: 4039.2973\n",
      "Epoch 1099/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1857.8701 - val_loss: 4181.9779\n",
      "Epoch 1100/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1833.3309 - val_loss: 3966.1373\n",
      "Epoch 1101/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1911.9306 - val_loss: 5029.0312\n",
      "Epoch 1102/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2203.5123 - val_loss: 5537.2343\n",
      "Epoch 1103/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2360.7891 - val_loss: 4186.2035\n",
      "Epoch 1104/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1999.2612 - val_loss: 4118.6564\n",
      "Epoch 1105/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2193.8431 - val_loss: 3815.6028\n",
      "Epoch 1106/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1943.4429 - val_loss: 3293.4072\n",
      "Epoch 1107/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2082.5801 - val_loss: 3756.5729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1108/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2030.8772 - val_loss: 3781.9542\n",
      "Epoch 1109/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1890.0329 - val_loss: 3397.8643\n",
      "Epoch 1110/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1907.9150 - val_loss: 3544.2365\n",
      "Epoch 1111/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1972.5211 - val_loss: 3878.7958\n",
      "Epoch 1112/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1852.5214 - val_loss: 3593.9070\n",
      "Epoch 1113/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1804.9623 - val_loss: 3565.7738\n",
      "Epoch 1114/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1824.3345 - val_loss: 3567.3188\n",
      "Epoch 1115/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1875.8695 - val_loss: 3846.8068\n",
      "Epoch 1116/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1796.7624 - val_loss: 3561.2754\n",
      "Epoch 1117/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1831.7933 - val_loss: 3607.1842\n",
      "Epoch 1118/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1896.7830 - val_loss: 3780.1310\n",
      "Epoch 1119/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1855.6426 - val_loss: 3636.7556\n",
      "Epoch 1120/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1808.6834 - val_loss: 3491.9483\n",
      "Epoch 1121/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1810.8305 - val_loss: 3468.4714\n",
      "Epoch 1122/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1813.2189 - val_loss: 3652.6903\n",
      "Epoch 1123/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1822.6202 - val_loss: 3634.3929\n",
      "Epoch 1124/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1835.2821 - val_loss: 3577.9436\n",
      "Epoch 1125/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1776.0325 - val_loss: 3591.5766\n",
      "Epoch 1126/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1778.1241 - val_loss: 3562.1392\n",
      "Epoch 1127/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1727.1151 - val_loss: 3561.1095\n",
      "Epoch 1128/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1756.1900 - val_loss: 3548.3209\n",
      "Epoch 1129/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1729.9453 - val_loss: 3541.3815\n",
      "Epoch 1130/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1735.8794 - val_loss: 4022.6110\n",
      "Epoch 1131/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1770.9398 - val_loss: 3554.9830\n",
      "Epoch 1132/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1744.5998 - val_loss: 3587.3852\n",
      "Epoch 1133/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1752.2095 - val_loss: 3829.8287\n",
      "Epoch 1134/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1742.7411 - val_loss: 3602.9160\n",
      "Epoch 1135/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1708.3445 - val_loss: 3618.1593\n",
      "Epoch 1136/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1803.7442 - val_loss: 3907.2834\n",
      "Epoch 1137/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1748.5358 - val_loss: 3464.9580\n",
      "Epoch 1138/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1771.1686 - val_loss: 4037.2384\n",
      "Epoch 1139/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1789.6724 - val_loss: 3611.4574\n",
      "Epoch 1140/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1744.6323 - val_loss: 3534.8398\n",
      "Epoch 1141/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1731.4579 - val_loss: 3621.5985\n",
      "Epoch 1142/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1782.5834 - val_loss: 3562.0456\n",
      "Epoch 1143/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1711.8872 - val_loss: 3970.5161\n",
      "Epoch 1144/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1741.4599 - val_loss: 3658.8235\n",
      "Epoch 1145/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1730.4563 - val_loss: 3595.7435\n",
      "Epoch 1146/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1772.7488 - val_loss: 3958.9993\n",
      "Epoch 1147/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1758.8995 - val_loss: 3748.9914\n",
      "Epoch 1148/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1785.6939 - val_loss: 3593.6719\n",
      "Epoch 1149/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1696.8707 - val_loss: 4034.8726\n",
      "Epoch 1150/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1751.7034 - val_loss: 4121.2168\n",
      "Epoch 1151/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1728.5050 - val_loss: 3599.4921\n",
      "Epoch 1152/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1713.3190 - val_loss: 3511.0212\n",
      "Epoch 1153/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1780.7630 - val_loss: 4084.5890\n",
      "Epoch 1154/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1765.7135 - val_loss: 3635.3241\n",
      "Epoch 1155/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1695.9583 - val_loss: 3798.3825\n",
      "Epoch 1156/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1723.7292 - val_loss: 3929.6714\n",
      "Epoch 1157/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1652.7151 - val_loss: 3998.1211\n",
      "Epoch 1158/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1712.4841 - val_loss: 4097.1415\n",
      "Epoch 1159/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1716.3907 - val_loss: 4018.2415\n",
      "Epoch 1160/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1668.0681 - val_loss: 3657.3165\n",
      "Epoch 1161/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1777.4612 - val_loss: 4625.8810\n",
      "Epoch 1162/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1814.5131 - val_loss: 4370.0248\n",
      "Epoch 1163/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2182.1625 - val_loss: 4907.7059\n",
      "Epoch 1164/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2106.3837 - val_loss: 4275.6131\n",
      "Epoch 1165/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2056.3197 - val_loss: 4153.5648\n",
      "Epoch 1166/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1848.9001 - val_loss: 4286.8843\n",
      "Epoch 1167/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1810.4420 - val_loss: 3901.8438\n",
      "Epoch 1168/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1733.7366 - val_loss: 4002.6879\n",
      "Epoch 1169/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1740.0050 - val_loss: 4038.7067\n",
      "Epoch 1170/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1784.3946 - val_loss: 4166.5866\n",
      "Epoch 1171/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1767.9664 - val_loss: 3985.5145\n",
      "Epoch 1172/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1666.8216 - val_loss: 4121.6016\n",
      "Epoch 1173/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1738.6710 - val_loss: 4772.1894\n",
      "Epoch 1174/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1972.5301 - val_loss: 4996.7025\n",
      "Epoch 1175/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1943.6306 - val_loss: 5089.3233\n",
      "Epoch 1176/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1913.3268 - val_loss: 4594.7708\n",
      "Epoch 1177/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1959.2222 - val_loss: 5750.7586\n",
      "Epoch 1178/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2226.8591 - val_loss: 5931.8190\n",
      "Epoch 1179/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1970.2579 - val_loss: 4816.3084\n",
      "Epoch 1180/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1851.0636 - val_loss: 4111.9237\n",
      "Epoch 1181/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1811.0383 - val_loss: 3865.2419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1182/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1795.9151 - val_loss: 3641.8287\n",
      "Epoch 1183/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1785.8410 - val_loss: 3742.2628\n",
      "Epoch 1184/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1697.5124 - val_loss: 3883.1528\n",
      "Epoch 1185/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1625.8626 - val_loss: 3658.4562\n",
      "Epoch 1186/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1696.5569 - val_loss: 3822.6984\n",
      "Epoch 1187/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1621.1435 - val_loss: 3823.4465\n",
      "Epoch 1188/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1701.4646 - val_loss: 3871.4041\n",
      "Epoch 1189/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1551.1638 - val_loss: 3996.3750\n",
      "Epoch 1190/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1750.7961 - val_loss: 3986.9604\n",
      "Epoch 1191/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2030.8566 - val_loss: 4258.8109\n",
      "Epoch 1192/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1847.4398 - val_loss: 4056.1544\n",
      "Epoch 1193/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1828.1656 - val_loss: 3950.3659\n",
      "Epoch 1194/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1714.0207 - val_loss: 4077.5641\n",
      "Epoch 1195/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1659.9397 - val_loss: 3794.6744\n",
      "Epoch 1196/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1534.4774 - val_loss: 3818.1523\n",
      "Epoch 1197/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1534.6074 - val_loss: 4091.0425\n",
      "Epoch 1198/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1521.2793 - val_loss: 3845.5849\n",
      "Epoch 1199/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1539.7862 - val_loss: 4235.1630\n",
      "Epoch 1200/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1555.7875 - val_loss: 4115.3750\n",
      "Epoch 1201/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1465.1809 - val_loss: 3965.5179\n",
      "Epoch 1202/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1529.2776 - val_loss: 3900.0383\n",
      "Epoch 1203/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1493.3612 - val_loss: 4125.0996\n",
      "Epoch 1204/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1485.1225 - val_loss: 4390.3981\n",
      "Epoch 1205/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1475.3168 - val_loss: 4323.0293\n",
      "Epoch 1206/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1470.4066 - val_loss: 3992.3642\n",
      "Epoch 1207/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1400.8378 - val_loss: 3932.6440\n",
      "Epoch 1208/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1457.2999 - val_loss: 4140.5604\n",
      "Epoch 1209/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1419.2043 - val_loss: 4238.2741\n",
      "Epoch 1210/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1502.5712 - val_loss: 4930.4462\n",
      "Epoch 1211/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1531.6335 - val_loss: 4254.0168\n",
      "Epoch 1212/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1928.0327 - val_loss: 4564.1503\n",
      "Epoch 1213/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1912.0217 - val_loss: 3505.2112\n",
      "Epoch 1214/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2882.2898 - val_loss: 3709.8504\n",
      "Epoch 1215/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2275.0171 - val_loss: 4393.3034\n",
      "Epoch 1216/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2411.6765 - val_loss: 4196.5047\n",
      "Epoch 1217/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2284.1758 - val_loss: 4112.1169\n",
      "Epoch 1218/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2339.4613 - val_loss: 3967.0311\n",
      "Epoch 1219/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1973.0735 - val_loss: 3945.6310\n",
      "Epoch 1220/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1922.5583 - val_loss: 3930.7057\n",
      "Epoch 1221/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1981.9693 - val_loss: 3994.0054\n",
      "Epoch 1222/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1954.6943 - val_loss: 4123.0297\n",
      "Epoch 1223/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1874.7210 - val_loss: 4033.2329\n",
      "Epoch 1224/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1835.6743 - val_loss: 4104.7895\n",
      "Epoch 1225/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1827.9560 - val_loss: 4071.2977\n",
      "Epoch 1226/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1782.2673 - val_loss: 4155.5555\n",
      "Epoch 1227/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1763.9598 - val_loss: 4148.1247\n",
      "Epoch 1228/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1957.0785 - val_loss: 4409.9596\n",
      "Epoch 1229/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1828.4435 - val_loss: 4627.3392\n",
      "Epoch 1230/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1935.9666 - val_loss: 4121.3192\n",
      "Epoch 1231/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1924.6911 - val_loss: 4362.3824\n",
      "Epoch 1232/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1755.9647 - val_loss: 4326.7423\n",
      "Epoch 1233/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1746.6435 - val_loss: 4274.2434\n",
      "Epoch 1234/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1717.0234 - val_loss: 4449.9492\n",
      "Epoch 1235/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1730.5036 - val_loss: 4523.1257\n",
      "Epoch 1236/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1697.2285 - val_loss: 4612.3726\n",
      "Epoch 1237/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1738.0592 - val_loss: 4506.6652\n",
      "Epoch 1238/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1674.3254 - val_loss: 4619.1996\n",
      "Epoch 1239/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1643.7930 - val_loss: 4711.6460\n",
      "Epoch 1240/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1641.2378 - val_loss: 4797.8591\n",
      "Epoch 1241/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1629.3820 - val_loss: 4759.0789\n",
      "Epoch 1242/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1623.5592 - val_loss: 4825.3210\n",
      "Epoch 1243/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1547.3485 - val_loss: 4955.1959\n",
      "Epoch 1244/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1589.3840 - val_loss: 4939.8266\n",
      "Epoch 1245/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1649.1748 - val_loss: 4914.6745\n",
      "Epoch 1246/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1659.3398 - val_loss: 5154.5675\n",
      "Epoch 1247/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1693.9038 - val_loss: 5016.8064\n",
      "Epoch 1248/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1621.0282 - val_loss: 4983.2077\n",
      "Epoch 1249/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1623.1511 - val_loss: 4717.0179\n",
      "Epoch 1250/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1585.3993 - val_loss: 4572.4107\n",
      "Epoch 1251/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1564.5702 - val_loss: 4596.1592\n",
      "Epoch 1252/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1538.7893 - val_loss: 4662.2464\n",
      "Epoch 1253/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1528.6055 - val_loss: 4855.5545\n",
      "Epoch 1254/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1490.6883 - val_loss: 5132.7645\n",
      "Epoch 1255/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1522.5346 - val_loss: 4958.9255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1256/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1503.3800 - val_loss: 5255.1132\n",
      "Epoch 1257/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1470.6447 - val_loss: 5096.9357\n",
      "Epoch 1258/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1552.6968 - val_loss: 5219.2982\n",
      "Epoch 1259/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1422.2627 - val_loss: 5218.1229\n",
      "Epoch 1260/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1417.3776 - val_loss: 5249.5961\n",
      "Epoch 1261/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1361.3484 - val_loss: 5186.1784\n",
      "Epoch 1262/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1371.9416 - val_loss: 5211.9259\n",
      "Epoch 1263/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1329.5247 - val_loss: 5316.5928\n",
      "Epoch 1264/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1325.1672 - val_loss: 5385.7954\n",
      "Epoch 1265/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1353.1590 - val_loss: 5423.2621\n",
      "Epoch 1266/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1348.6003 - val_loss: 5342.3604\n",
      "Epoch 1267/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1316.0623 - val_loss: 5365.7137\n",
      "Epoch 1268/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1419.9190 - val_loss: 4452.4971\n",
      "Epoch 1269/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1500.0868 - val_loss: 5101.0968\n",
      "Epoch 1270/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1465.2008 - val_loss: 4988.8388\n",
      "Epoch 1271/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1471.4072 - val_loss: 5039.0419\n",
      "Epoch 1272/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1524.2093 - val_loss: 4829.2713\n",
      "Epoch 1273/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1426.9665 - val_loss: 5056.4078\n",
      "Epoch 1274/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1393.2804 - val_loss: 5111.6090\n",
      "Epoch 1275/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1365.4736 - val_loss: 5167.6349\n",
      "Epoch 1276/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1409.3690 - val_loss: 5127.3999\n",
      "Epoch 1277/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1291.7960 - val_loss: 5300.6795\n",
      "Epoch 1278/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1724.4801 - val_loss: 5564.3086\n",
      "Epoch 1279/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1525.1064 - val_loss: 5003.6734\n",
      "Epoch 1280/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1996.5034 - val_loss: 4310.1245\n",
      "Epoch 1281/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1692.6233 - val_loss: 4080.3350\n",
      "Epoch 1282/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1492.7355 - val_loss: 4159.0099\n",
      "Epoch 1283/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1547.6236 - val_loss: 4098.7860\n",
      "Epoch 1284/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1530.1335 - val_loss: 4298.9036\n",
      "Epoch 1285/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1439.0463 - val_loss: 4419.7883\n",
      "Epoch 1286/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1414.4452 - val_loss: 4859.5252\n",
      "Epoch 1287/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1389.6537 - val_loss: 5009.7775\n",
      "Epoch 1288/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1494.0033 - val_loss: 5194.4724\n",
      "Epoch 1289/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1451.2538 - val_loss: 5549.3746\n",
      "Epoch 1290/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1698.3949 - val_loss: 4542.0011\n",
      "Epoch 1291/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1479.7724 - val_loss: 4455.8683\n",
      "Epoch 1292/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1525.5946 - val_loss: 4534.1719\n",
      "Epoch 1293/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1431.2548 - val_loss: 4200.7668\n",
      "Epoch 1294/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1458.0059 - val_loss: 4321.6537\n",
      "Epoch 1295/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1379.7565 - val_loss: 4474.0424\n",
      "Epoch 1296/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1362.7593 - val_loss: 4461.1641\n",
      "Epoch 1297/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1344.0143 - val_loss: 4547.9484\n",
      "Epoch 1298/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1309.1016 - val_loss: 4595.3259\n",
      "Epoch 1299/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1308.1974 - val_loss: 4788.0770\n",
      "Epoch 1300/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1310.5053 - val_loss: 4496.2788\n",
      "Epoch 1301/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1315.0052 - val_loss: 4740.8291\n",
      "Epoch 1302/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1293.0275 - val_loss: 4616.2636\n",
      "Epoch 1303/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1243.1657 - val_loss: 4770.9547\n",
      "Epoch 1304/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1293.8568 - val_loss: 4637.9720\n",
      "Epoch 1305/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1247.0615 - val_loss: 4540.7557\n",
      "Epoch 1306/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1397.7629 - val_loss: 4714.7094\n",
      "Epoch 1307/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1278.4661 - val_loss: 4607.7517\n",
      "Epoch 1308/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1261.7037 - val_loss: 4598.9577\n",
      "Epoch 1309/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1315.0279 - val_loss: 4435.4006\n",
      "Epoch 1310/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1325.3304 - val_loss: 4575.6912\n",
      "Epoch 1311/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1283.0454 - val_loss: 4341.4005\n",
      "Epoch 1312/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1224.6128 - val_loss: 4680.2895\n",
      "Epoch 1313/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1158.4883 - val_loss: 4430.1967\n",
      "Epoch 1314/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1191.1840 - val_loss: 4515.0713\n",
      "Epoch 1315/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1167.8796 - val_loss: 4566.9711\n",
      "Epoch 1316/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1192.6875 - val_loss: 4205.7316\n",
      "Epoch 1317/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1194.5038 - val_loss: 4459.4082\n",
      "Epoch 1318/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1198.0324 - val_loss: 4067.5194\n",
      "Epoch 1319/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1315.8509 - val_loss: 5150.7323\n",
      "Epoch 1320/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1286.9378 - val_loss: 3972.9301\n",
      "Epoch 1321/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1272.2245 - val_loss: 4813.4203\n",
      "Epoch 1322/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1372.2706 - val_loss: 3770.6141\n",
      "Epoch 1323/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1495.8407 - val_loss: 4818.9089\n",
      "Epoch 1324/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1299.6213 - val_loss: 4306.8209\n",
      "Epoch 1325/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1572.4363 - val_loss: 5171.0198\n",
      "Epoch 1326/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1654.1200 - val_loss: 4794.8592\n",
      "Epoch 1327/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1741.9207 - val_loss: 3776.3614\n",
      "Epoch 1328/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1988.8767 - val_loss: 4023.4673\n",
      "Epoch 1329/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1715.1801 - val_loss: 3670.5386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1330/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1707.5989 - val_loss: 3437.9474\n",
      "Epoch 1331/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1675.0386 - val_loss: 3302.1970\n",
      "Epoch 1332/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1593.7070 - val_loss: 3599.0333\n",
      "Epoch 1333/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1517.8236 - val_loss: 3602.4145\n",
      "Epoch 1334/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1394.9542 - val_loss: 3575.1385\n",
      "Epoch 1335/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1387.4012 - val_loss: 3568.3169\n",
      "Epoch 1336/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1369.5085 - val_loss: 3835.5746\n",
      "Epoch 1337/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1346.6951 - val_loss: 4204.2043\n",
      "Epoch 1338/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1333.8514 - val_loss: 4139.9675\n",
      "Epoch 1339/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1285.2734 - val_loss: 4510.6416\n",
      "Epoch 1340/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1230.4033 - val_loss: 4146.1285\n",
      "Epoch 1341/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1243.4716 - val_loss: 5193.5337\n",
      "Epoch 1342/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1338.4967 - val_loss: 4940.4754\n",
      "Epoch 1343/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1199.0364 - val_loss: 4601.2232\n",
      "Epoch 1344/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1283.0254 - val_loss: 4761.4373\n",
      "Epoch 1345/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1306.4092 - val_loss: 4558.4058\n",
      "Epoch 1346/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1231.4963 - val_loss: 4489.9780\n",
      "Epoch 1347/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1221.8588 - val_loss: 4156.2980\n",
      "Epoch 1348/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1106.0901 - val_loss: 5132.0789\n",
      "Epoch 1349/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1185.2477 - val_loss: 4057.5862\n",
      "Epoch 1350/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1077.3180 - val_loss: 4963.5631\n",
      "Epoch 1351/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1159.5023 - val_loss: 4936.2613\n",
      "Epoch 1352/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1216.9208 - val_loss: 4876.4601\n",
      "Epoch 1353/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2413.9036 - val_loss: 5606.2969\n",
      "Epoch 1354/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2507.3352 - val_loss: 5137.4221\n",
      "Epoch 1355/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2242.2168 - val_loss: 4665.9935\n",
      "Epoch 1356/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2412.3991 - val_loss: 4889.3698\n",
      "Epoch 1357/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1635.9690 - val_loss: 3861.0916\n",
      "Epoch 1358/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2019.2715 - val_loss: 3873.7010\n",
      "Epoch 1359/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1346.4466 - val_loss: 3584.8379\n",
      "Epoch 1360/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1537.3808 - val_loss: 3953.2494\n",
      "Epoch 1361/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1429.2678 - val_loss: 4018.1561\n",
      "Epoch 1362/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1253.3166 - val_loss: 3691.3058\n",
      "Epoch 1363/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1314.6843 - val_loss: 4543.8826\n",
      "Epoch 1364/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1319.3717 - val_loss: 3484.2112\n",
      "Epoch 1365/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1408.7720 - val_loss: 4354.9842\n",
      "Epoch 1366/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1632.5018 - val_loss: 4534.3090\n",
      "Epoch 1367/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1346.4565 - val_loss: 4095.9148\n",
      "Epoch 1368/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1214.3578 - val_loss: 3946.5599\n",
      "Epoch 1369/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1209.7962 - val_loss: 4141.8684\n",
      "Epoch 1370/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1393.6978 - val_loss: 3944.4427\n",
      "Epoch 1371/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1264.1390 - val_loss: 3985.4185\n",
      "Epoch 1372/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1279.0114 - val_loss: 4333.6557\n",
      "Epoch 1373/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1209.0112 - val_loss: 4093.1400\n",
      "Epoch 1374/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1181.8432 - val_loss: 4741.5794\n",
      "Epoch 1375/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1797.9518 - val_loss: 4665.8848\n",
      "Epoch 1376/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1451.9349 - val_loss: 4053.4799\n",
      "Epoch 1377/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1424.8753 - val_loss: 3793.7250\n",
      "Epoch 1378/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1375.3895 - val_loss: 3915.2043\n",
      "Epoch 1379/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1209.4224 - val_loss: 3887.0291\n",
      "Epoch 1380/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1168.4671 - val_loss: 3794.1424\n",
      "Epoch 1381/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1132.2098 - val_loss: 3691.8838\n",
      "Epoch 1382/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1089.2434 - val_loss: 3742.6725\n",
      "Epoch 1383/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1167.6003 - val_loss: 4294.5587\n",
      "Epoch 1384/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1561.7420 - val_loss: 4129.3172\n",
      "Epoch 1385/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1521.4580 - val_loss: 3849.6389\n",
      "Epoch 1386/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1363.5200 - val_loss: 3788.9602\n",
      "Epoch 1387/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1337.2975 - val_loss: 4102.8873\n",
      "Epoch 1388/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1392.9870 - val_loss: 4298.6777\n",
      "Epoch 1389/2000\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 1391.2066 - val_loss: 4051.3601\n",
      "Epoch 1390/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1178.4144 - val_loss: 4116.2608\n",
      "Epoch 1391/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1225.3280 - val_loss: 3844.1111\n",
      "Epoch 1392/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1136.7901 - val_loss: 4558.3407\n",
      "Epoch 1393/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1129.8154 - val_loss: 3856.1403\n",
      "Epoch 1394/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1153.7181 - val_loss: 4452.0149\n",
      "Epoch 1395/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1295.5099 - val_loss: 4347.2245\n",
      "Epoch 1396/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1256.9482 - val_loss: 4516.9581\n",
      "Epoch 1397/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1451.3566 - val_loss: 4531.8456\n",
      "Epoch 1398/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1256.9685 - val_loss: 3829.5628\n",
      "Epoch 1399/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1218.2927 - val_loss: 5090.8260\n",
      "Epoch 1400/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1823.4685 - val_loss: 4724.4115\n",
      "Epoch 1401/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2167.2813 - val_loss: 6123.7846\n",
      "Epoch 1402/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 3335.9380 - val_loss: 3760.8690\n",
      "Epoch 1403/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2659.4555 - val_loss: 3441.1728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1404/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2789.9584 - val_loss: 4016.1073\n",
      "Epoch 1405/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2579.2371 - val_loss: 4400.4094\n",
      "Epoch 1406/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2561.6092 - val_loss: 3566.8973\n",
      "Epoch 1407/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2509.2311 - val_loss: 3430.0725\n",
      "Epoch 1408/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2588.2992 - val_loss: 3846.4027\n",
      "Epoch 1409/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2494.3337 - val_loss: 3755.0258\n",
      "Epoch 1410/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2509.1478 - val_loss: 3527.1786\n",
      "Epoch 1411/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2441.0499 - val_loss: 3689.5179\n",
      "Epoch 1412/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2440.4420 - val_loss: 3701.4760\n",
      "Epoch 1413/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2480.3755 - val_loss: 3663.6050\n",
      "Epoch 1414/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2438.7436 - val_loss: 3644.1312\n",
      "Epoch 1415/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2460.9996 - val_loss: 3611.6904\n",
      "Epoch 1416/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2468.5538 - val_loss: 3637.8444\n",
      "Epoch 1417/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2444.0687 - val_loss: 3713.7861\n",
      "Epoch 1418/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2406.0270 - val_loss: 3683.4223\n",
      "Epoch 1419/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2443.4242 - val_loss: 3559.6617\n",
      "Epoch 1420/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2417.5854 - val_loss: 3650.0015\n",
      "Epoch 1421/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2470.3415 - val_loss: 3702.2468\n",
      "Epoch 1422/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2400.4873 - val_loss: 3611.9319\n",
      "Epoch 1423/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2466.8298 - val_loss: 3583.6806\n",
      "Epoch 1424/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2425.9444 - val_loss: 3799.8579\n",
      "Epoch 1425/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2407.5970 - val_loss: 3682.5305\n",
      "Epoch 1426/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2408.3617 - val_loss: 3512.5438\n",
      "Epoch 1427/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2426.5000 - val_loss: 3647.9070\n",
      "Epoch 1428/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2454.8327 - val_loss: 3927.7314\n",
      "Epoch 1429/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2411.7408 - val_loss: 3629.7848\n",
      "Epoch 1430/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2357.2100 - val_loss: 3609.9311\n",
      "Epoch 1431/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2366.0445 - val_loss: 3597.0733\n",
      "Epoch 1432/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2352.4806 - val_loss: 3680.4513\n",
      "Epoch 1433/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2427.5856 - val_loss: 3715.4996\n",
      "Epoch 1434/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2400.2314 - val_loss: 3770.8481\n",
      "Epoch 1435/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2379.9294 - val_loss: 3717.0426\n",
      "Epoch 1436/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2433.1879 - val_loss: 3591.2728\n",
      "Epoch 1437/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2418.6220 - val_loss: 3741.7874\n",
      "Epoch 1438/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2376.3577 - val_loss: 3750.4183\n",
      "Epoch 1439/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2375.3093 - val_loss: 3781.2349\n",
      "Epoch 1440/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2391.4785 - val_loss: 3702.9607\n",
      "Epoch 1441/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2419.5837 - val_loss: 3587.9774\n",
      "Epoch 1442/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2365.6844 - val_loss: 3795.1802\n",
      "Epoch 1443/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2378.0349 - val_loss: 3825.9717\n",
      "Epoch 1444/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2328.0947 - val_loss: 3752.2229\n",
      "Epoch 1445/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2286.1152 - val_loss: 3676.6801\n",
      "Epoch 1446/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2325.7640 - val_loss: 3657.8007\n",
      "Epoch 1447/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2293.3824 - val_loss: 3857.3054\n",
      "Epoch 1448/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2244.8607 - val_loss: 3750.2674\n",
      "Epoch 1449/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2397.6474 - val_loss: 3821.0862\n",
      "Epoch 1450/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2270.1791 - val_loss: 4282.4215\n",
      "Epoch 1451/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2213.7169 - val_loss: 4006.9043\n",
      "Epoch 1452/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2270.7412 - val_loss: 4032.6969\n",
      "Epoch 1453/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2246.2087 - val_loss: 4340.2119\n",
      "Epoch 1454/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2029.4616 - val_loss: 4032.2321\n",
      "Epoch 1455/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2044.4538 - val_loss: 3993.3222\n",
      "Epoch 1456/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2013.0233 - val_loss: 4248.2595\n",
      "Epoch 1457/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2074.6663 - val_loss: 4359.4685\n",
      "Epoch 1458/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1993.1308 - val_loss: 4044.0642\n",
      "Epoch 1459/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2026.7750 - val_loss: 4043.3586\n",
      "Epoch 1460/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1948.7613 - val_loss: 4472.1475\n",
      "Epoch 1461/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1952.1493 - val_loss: 4333.2332\n",
      "Epoch 1462/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1771.0817 - val_loss: 4112.1106\n",
      "Epoch 1463/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1821.3733 - val_loss: 4169.0608\n",
      "Epoch 1464/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1839.4317 - val_loss: 4149.0213\n",
      "Epoch 1465/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1899.9743 - val_loss: 4181.2611\n",
      "Epoch 1466/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1821.2811 - val_loss: 4080.2128\n",
      "Epoch 1467/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1804.9782 - val_loss: 4299.1308\n",
      "Epoch 1468/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1788.1909 - val_loss: 4191.5983\n",
      "Epoch 1469/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1768.8198 - val_loss: 4142.4748\n",
      "Epoch 1470/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1726.0134 - val_loss: 4215.7160\n",
      "Epoch 1471/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1750.7737 - val_loss: 4091.2841\n",
      "Epoch 1472/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1699.7082 - val_loss: 4017.0216\n",
      "Epoch 1473/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1724.9553 - val_loss: 4232.4644\n",
      "Epoch 1474/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1687.3374 - val_loss: 3916.6970\n",
      "Epoch 1475/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1770.9597 - val_loss: 3850.5649\n",
      "Epoch 1476/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1681.1494 - val_loss: 4269.6618\n",
      "Epoch 1477/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1756.3897 - val_loss: 3818.7311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1478/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1663.5877 - val_loss: 3859.9217\n",
      "Epoch 1479/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1689.3102 - val_loss: 3957.5181\n",
      "Epoch 1480/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1665.1999 - val_loss: 3695.3674\n",
      "Epoch 1481/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1678.4123 - val_loss: 3944.5669\n",
      "Epoch 1482/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1710.2449 - val_loss: 3693.9940\n",
      "Epoch 1483/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1585.3779 - val_loss: 3574.1509\n",
      "Epoch 1484/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1734.1677 - val_loss: 3638.8912\n",
      "Epoch 1485/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1553.9344 - val_loss: 3478.9236\n",
      "Epoch 1486/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1618.1400 - val_loss: 3798.6796\n",
      "Epoch 1487/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1681.6240 - val_loss: 3625.8206\n",
      "Epoch 1488/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1539.9568 - val_loss: 3481.5577\n",
      "Epoch 1489/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1644.4800 - val_loss: 3781.2134\n",
      "Epoch 1490/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1624.2438 - val_loss: 3403.9996\n",
      "Epoch 1491/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1692.2751 - val_loss: 3692.0122\n",
      "Epoch 1492/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1589.5781 - val_loss: 3393.0264\n",
      "Epoch 1493/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1545.0601 - val_loss: 3699.3676\n",
      "Epoch 1494/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1681.4539 - val_loss: 3523.9702\n",
      "Epoch 1495/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1653.5570 - val_loss: 3368.7537\n",
      "Epoch 1496/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1547.3154 - val_loss: 3798.1126\n",
      "Epoch 1497/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1540.9736 - val_loss: 3324.7086\n",
      "Epoch 1498/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1659.2696 - val_loss: 3577.7523\n",
      "Epoch 1499/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1573.7796 - val_loss: 3657.8973\n",
      "Epoch 1500/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1587.5305 - val_loss: 3265.2505\n",
      "Epoch 1501/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1622.2057 - val_loss: 3661.2791\n",
      "Epoch 1502/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1519.9494 - val_loss: 3247.4148\n",
      "Epoch 1503/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1538.9417 - val_loss: 3647.2664\n",
      "Epoch 1504/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1576.5206 - val_loss: 3462.2824\n",
      "Epoch 1505/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1540.9009 - val_loss: 3441.6280\n",
      "Epoch 1506/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1462.1286 - val_loss: 3442.8209\n",
      "Epoch 1507/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1559.4513 - val_loss: 3614.6663\n",
      "Epoch 1508/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1563.3876 - val_loss: 3362.6618\n",
      "Epoch 1509/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1465.8084 - val_loss: 3794.8667\n",
      "Epoch 1510/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1479.7983 - val_loss: 3593.3789\n",
      "Epoch 1511/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1463.4242 - val_loss: 3566.8151\n",
      "Epoch 1512/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1434.4507 - val_loss: 3911.3099\n",
      "Epoch 1513/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1424.0938 - val_loss: 3821.5022\n",
      "Epoch 1514/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1425.2618 - val_loss: 3665.8699\n",
      "Epoch 1515/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1510.9884 - val_loss: 3814.4881\n",
      "Epoch 1516/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1503.8818 - val_loss: 4049.0619\n",
      "Epoch 1517/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1381.6115 - val_loss: 3489.8102\n",
      "Epoch 1518/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1452.2887 - val_loss: 3900.5273\n",
      "Epoch 1519/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1412.8739 - val_loss: 3766.4250\n",
      "Epoch 1520/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1382.7423 - val_loss: 3719.3442\n",
      "Epoch 1521/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1347.3038 - val_loss: 3816.9598\n",
      "Epoch 1522/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1499.6479 - val_loss: 3449.3680\n",
      "Epoch 1523/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1380.2105 - val_loss: 3822.6327\n",
      "Epoch 1524/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1428.0722 - val_loss: 3489.7122\n",
      "Epoch 1525/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1370.2454 - val_loss: 4103.9886\n",
      "Epoch 1526/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1372.8157 - val_loss: 3316.1541\n",
      "Epoch 1527/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1341.5694 - val_loss: 3148.0043\n",
      "Epoch 1528/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1312.8851 - val_loss: 3189.9651\n",
      "Epoch 1529/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1348.4137 - val_loss: 3352.2924\n",
      "Epoch 1530/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1333.6135 - val_loss: 3138.2317\n",
      "Epoch 1531/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1328.0251 - val_loss: 3162.9479\n",
      "Epoch 1532/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1236.7714 - val_loss: 3788.2223\n",
      "Epoch 1533/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1310.7208 - val_loss: 3563.9206\n",
      "Epoch 1534/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1287.0008 - val_loss: 3502.3042\n",
      "Epoch 1535/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1299.8503 - val_loss: 3367.9994\n",
      "Epoch 1536/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1315.6109 - val_loss: 3641.8132\n",
      "Epoch 1537/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1254.4911 - val_loss: 3841.3152\n",
      "Epoch 1538/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1276.0693 - val_loss: 3599.4252\n",
      "Epoch 1539/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1238.9833 - val_loss: 3061.5590\n",
      "Epoch 1540/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1293.9465 - val_loss: 4021.7518\n",
      "Epoch 1541/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1214.4614 - val_loss: 2695.9359\n",
      "Epoch 1542/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1339.0630 - val_loss: 2791.1323\n",
      "Epoch 1543/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1319.6417 - val_loss: 2779.8289\n",
      "Epoch 1544/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1250.7706 - val_loss: 2752.9886\n",
      "Epoch 1545/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1249.7069 - val_loss: 2969.4898\n",
      "Epoch 1546/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1183.7198 - val_loss: 2963.0652\n",
      "Epoch 1547/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1213.9191 - val_loss: 3062.7441\n",
      "Epoch 1548/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1210.5251 - val_loss: 2961.0907\n",
      "Epoch 1549/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1205.3749 - val_loss: 3079.8452\n",
      "Epoch 1550/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1171.4495 - val_loss: 3044.9581\n",
      "Epoch 1551/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1161.8076 - val_loss: 3125.0606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1552/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1116.4609 - val_loss: 3323.6478\n",
      "Epoch 1553/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1191.7776 - val_loss: 3135.1319\n",
      "Epoch 1554/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1168.9389 - val_loss: 3408.3752\n",
      "Epoch 1555/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1154.1191 - val_loss: 3017.7480\n",
      "Epoch 1556/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1177.3767 - val_loss: 2971.1889\n",
      "Epoch 1557/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1166.4668 - val_loss: 3230.8846\n",
      "Epoch 1558/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1205.5901 - val_loss: 2997.8378\n",
      "Epoch 1559/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1174.3908 - val_loss: 2978.9223\n",
      "Epoch 1560/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1196.9962 - val_loss: 3236.2047\n",
      "Epoch 1561/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1096.7763 - val_loss: 2990.6520\n",
      "Epoch 1562/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1087.7312 - val_loss: 3407.5306\n",
      "Epoch 1563/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1172.4974 - val_loss: 3140.4240\n",
      "Epoch 1564/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1102.5645 - val_loss: 3176.1969\n",
      "Epoch 1565/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1104.0189 - val_loss: 3278.9958\n",
      "Epoch 1566/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1073.9662 - val_loss: 3061.5858\n",
      "Epoch 1567/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1072.8835 - val_loss: 3343.8288\n",
      "Epoch 1568/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1029.7060 - val_loss: 3090.7197\n",
      "Epoch 1569/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1175.8187 - val_loss: 3146.9047\n",
      "Epoch 1570/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1089.7513 - val_loss: 3544.6071\n",
      "Epoch 1571/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1099.2497 - val_loss: 3105.9433\n",
      "Epoch 1572/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1135.7649 - val_loss: 3254.8551\n",
      "Epoch 1573/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1096.5379 - val_loss: 3313.9326\n",
      "Epoch 1574/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1123.0287 - val_loss: 3262.3515\n",
      "Epoch 1575/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 996.7880 - val_loss: 3437.5174\n",
      "Epoch 1576/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1058.7686 - val_loss: 3298.6825\n",
      "Epoch 1577/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1029.6444 - val_loss: 3415.3848\n",
      "Epoch 1578/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 992.1948 - val_loss: 3245.0369\n",
      "Epoch 1579/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1060.1934 - val_loss: 3561.1515\n",
      "Epoch 1580/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1579.4201 - val_loss: 3862.6632\n",
      "Epoch 1581/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1197.3736 - val_loss: 3100.8665\n",
      "Epoch 1582/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1380.0859 - val_loss: 3291.9983\n",
      "Epoch 1583/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1572.8293 - val_loss: 4196.6138\n",
      "Epoch 1584/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1233.8514 - val_loss: 3065.4404\n",
      "Epoch 1585/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1243.6578 - val_loss: 2918.1486\n",
      "Epoch 1586/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1072.0072 - val_loss: 3305.1638\n",
      "Epoch 1587/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1080.7479 - val_loss: 2898.5413\n",
      "Epoch 1588/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1023.4650 - val_loss: 3353.7270\n",
      "Epoch 1589/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1071.8666 - val_loss: 3375.0322\n",
      "Epoch 1590/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1033.5787 - val_loss: 3079.7854\n",
      "Epoch 1591/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1040.9338 - val_loss: 3518.8786\n",
      "Epoch 1592/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1038.2242 - val_loss: 3140.1951\n",
      "Epoch 1593/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 998.0274 - val_loss: 3183.0373\n",
      "Epoch 1594/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1070.3468 - val_loss: 3293.6060\n",
      "Epoch 1595/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1019.9546 - val_loss: 3142.8903\n",
      "Epoch 1596/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1045.6555 - val_loss: 3414.3702\n",
      "Epoch 1597/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 937.6356 - val_loss: 3404.8026\n",
      "Epoch 1598/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 981.0330 - val_loss: 3413.9904\n",
      "Epoch 1599/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 924.4700 - val_loss: 3344.7005\n",
      "Epoch 1600/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 932.3544 - val_loss: 3322.0264\n",
      "Epoch 1601/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 948.8608 - val_loss: 3257.7859\n",
      "Epoch 1602/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 937.7667 - val_loss: 3352.0095\n",
      "Epoch 1603/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 944.9101 - val_loss: 3373.1367\n",
      "Epoch 1604/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 901.9849 - val_loss: 3425.4297\n",
      "Epoch 1605/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 909.0127 - val_loss: 3514.1871\n",
      "Epoch 1606/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 916.9545 - val_loss: 3453.4309\n",
      "Epoch 1607/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 863.2338 - val_loss: 3086.1275\n",
      "Epoch 1608/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 893.1904 - val_loss: 3206.8931\n",
      "Epoch 1609/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 837.0735 - val_loss: 3199.0388\n",
      "Epoch 1610/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1149.9311 - val_loss: 3188.0926\n",
      "Epoch 1611/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1253.9372 - val_loss: 2968.2650\n",
      "Epoch 1612/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1113.8899 - val_loss: 3470.8737\n",
      "Epoch 1613/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1149.9647 - val_loss: 3276.9535\n",
      "Epoch 1614/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 891.1125 - val_loss: 3155.3016\n",
      "Epoch 1615/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 946.9722 - val_loss: 3335.8769\n",
      "Epoch 1616/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 959.7465 - val_loss: 3008.9323\n",
      "Epoch 1617/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 914.6495 - val_loss: 3140.3303\n",
      "Epoch 1618/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 864.6025 - val_loss: 3268.6112\n",
      "Epoch 1619/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 829.8702 - val_loss: 3322.3534\n",
      "Epoch 1620/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 784.1653 - val_loss: 3129.0556\n",
      "Epoch 1621/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 803.2094 - val_loss: 3241.2909\n",
      "Epoch 1622/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 779.2013 - val_loss: 3502.3023\n",
      "Epoch 1623/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 921.5634 - val_loss: 3668.9976\n",
      "Epoch 1624/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 949.2776 - val_loss: 3413.3695\n",
      "Epoch 1625/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 964.7743 - val_loss: 2880.3510\n",
      "Epoch 1626/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - 0s 1ms/step - loss: 1216.8745 - val_loss: 2873.6984\n",
      "Epoch 1627/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1609.9040 - val_loss: 3520.8514\n",
      "Epoch 1628/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1267.3507 - val_loss: 3729.8013\n",
      "Epoch 1629/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1113.4287 - val_loss: 3404.3917\n",
      "Epoch 1630/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1103.5611 - val_loss: 3304.1389\n",
      "Epoch 1631/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1124.4450 - val_loss: 3250.0913\n",
      "Epoch 1632/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1054.3960 - val_loss: 3051.9633\n",
      "Epoch 1633/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 914.7223 - val_loss: 3452.9898\n",
      "Epoch 1634/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1089.0680 - val_loss: 3307.5167\n",
      "Epoch 1635/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1132.4177 - val_loss: 3342.7824\n",
      "Epoch 1636/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1101.6454 - val_loss: 3023.4711\n",
      "Epoch 1637/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 938.3975 - val_loss: 3133.0353\n",
      "Epoch 1638/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 936.5427 - val_loss: 3129.4108\n",
      "Epoch 1639/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 876.3706 - val_loss: 3224.7165\n",
      "Epoch 1640/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 944.1737 - val_loss: 3340.5461\n",
      "Epoch 1641/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 836.6335 - val_loss: 3205.9132\n",
      "Epoch 1642/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 879.8516 - val_loss: 3328.5547\n",
      "Epoch 1643/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 800.5046 - val_loss: 3360.2543\n",
      "Epoch 1644/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 723.0250 - val_loss: 3254.1121\n",
      "Epoch 1645/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 746.2808 - val_loss: 3067.1609\n",
      "Epoch 1646/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 794.5348 - val_loss: 3264.9989\n",
      "Epoch 1647/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 825.9583 - val_loss: 3348.6838\n",
      "Epoch 1648/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 741.5367 - val_loss: 3455.7893\n",
      "Epoch 1649/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 834.0628 - val_loss: 3275.1346\n",
      "Epoch 1650/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 809.0313 - val_loss: 3122.6661\n",
      "Epoch 1651/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 730.6494 - val_loss: 2966.0864\n",
      "Epoch 1652/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 731.3860 - val_loss: 3082.7632\n",
      "Epoch 1653/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 721.0406 - val_loss: 3359.1036\n",
      "Epoch 1654/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 749.1780 - val_loss: 3051.0843\n",
      "Epoch 1655/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 712.8215 - val_loss: 3165.3732\n",
      "Epoch 1656/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 749.0912 - val_loss: 3321.5129\n",
      "Epoch 1657/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 713.8974 - val_loss: 3326.0785\n",
      "Epoch 1658/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 750.8228 - val_loss: 3137.5026\n",
      "Epoch 1659/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 712.7956 - val_loss: 3243.2525\n",
      "Epoch 1660/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 953.8024 - val_loss: 4562.0828\n",
      "Epoch 1661/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1710.8599 - val_loss: 2922.9699\n",
      "Epoch 1662/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1215.8050 - val_loss: 2685.5575\n",
      "Epoch 1663/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1095.8468 - val_loss: 2803.9014\n",
      "Epoch 1664/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 961.7238 - val_loss: 2886.2612\n",
      "Epoch 1665/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1055.8129 - val_loss: 3060.0002\n",
      "Epoch 1666/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1008.6975 - val_loss: 3065.0922\n",
      "Epoch 1667/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 955.8142 - val_loss: 3190.9464\n",
      "Epoch 1668/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 897.8269 - val_loss: 3390.6183\n",
      "Epoch 1669/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 820.4725 - val_loss: 3412.6148\n",
      "Epoch 1670/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 862.1337 - val_loss: 2950.9524\n",
      "Epoch 1671/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 897.8286 - val_loss: 2906.8143\n",
      "Epoch 1672/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 820.9169 - val_loss: 2891.5071\n",
      "Epoch 1673/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 793.3229 - val_loss: 3242.7608\n",
      "Epoch 1674/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 765.0769 - val_loss: 3204.9542\n",
      "Epoch 1675/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 782.9356 - val_loss: 3103.7445\n",
      "Epoch 1676/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 728.0111 - val_loss: 2969.9841\n",
      "Epoch 1677/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 743.3223 - val_loss: 3324.4714\n",
      "Epoch 1678/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 711.9753 - val_loss: 3338.5251\n",
      "Epoch 1679/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 756.0979 - val_loss: 3439.4595\n",
      "Epoch 1680/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 717.4004 - val_loss: 3644.1404\n",
      "Epoch 1681/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 646.6235 - val_loss: 3685.1975\n",
      "Epoch 1682/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 707.8590 - val_loss: 3317.9912\n",
      "Epoch 1683/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 786.5390 - val_loss: 3394.0055\n",
      "Epoch 1684/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 755.7597 - val_loss: 3203.3957\n",
      "Epoch 1685/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 753.8987 - val_loss: 3584.3194\n",
      "Epoch 1686/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1036.5607 - val_loss: 3832.7885\n",
      "Epoch 1687/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 910.1792 - val_loss: 2998.0945\n",
      "Epoch 1688/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 872.4495 - val_loss: 3130.1566\n",
      "Epoch 1689/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 980.2136 - val_loss: 3061.1205\n",
      "Epoch 1690/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1033.2464 - val_loss: 3318.8499\n",
      "Epoch 1691/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 972.4982 - val_loss: 3089.1633\n",
      "Epoch 1692/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 811.3814 - val_loss: 2961.0687\n",
      "Epoch 1693/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 746.9745 - val_loss: 3193.8407\n",
      "Epoch 1694/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 706.9175 - val_loss: 3573.2976\n",
      "Epoch 1695/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 678.1836 - val_loss: 3320.9320\n",
      "Epoch 1696/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 653.2279 - val_loss: 3563.8662\n",
      "Epoch 1697/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 650.1215 - val_loss: 3371.4238\n",
      "Epoch 1698/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 658.2179 - val_loss: 3178.0916\n",
      "Epoch 1699/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 630.9399 - val_loss: 3568.6366\n",
      "Epoch 1700/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1468.0940 - val_loss: 6209.5474\n",
      "Epoch 1701/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2161.7769 - val_loss: 4175.4986\n",
      "Epoch 1702/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 3522.9668 - val_loss: 4026.7873\n",
      "Epoch 1703/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2444.8901 - val_loss: 3863.7052\n",
      "Epoch 1704/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2205.6089 - val_loss: 3487.4379\n",
      "Epoch 1705/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2692.6506 - val_loss: 3748.4516\n",
      "Epoch 1706/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2514.7552 - val_loss: 4608.1664\n",
      "Epoch 1707/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2512.0632 - val_loss: 4057.9135\n",
      "Epoch 1708/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2345.3367 - val_loss: 3554.6596\n",
      "Epoch 1709/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2276.0891 - val_loss: 3606.6439\n",
      "Epoch 1710/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2230.0491 - val_loss: 3850.0915\n",
      "Epoch 1711/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2296.1890 - val_loss: 3770.8616\n",
      "Epoch 1712/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2292.2945 - val_loss: 3702.3233\n",
      "Epoch 1713/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2196.1425 - val_loss: 3691.5510\n",
      "Epoch 1714/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2187.8343 - val_loss: 3632.1773\n",
      "Epoch 1715/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2226.7502 - val_loss: 3665.4281\n",
      "Epoch 1716/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2199.9644 - val_loss: 3638.5957\n",
      "Epoch 1717/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2107.2918 - val_loss: 3524.4181\n",
      "Epoch 1718/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2053.9666 - val_loss: 3565.9335\n",
      "Epoch 1719/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2185.2701 - val_loss: 3749.5570\n",
      "Epoch 1720/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2024.0995 - val_loss: 3568.8964\n",
      "Epoch 1721/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1917.0373 - val_loss: 3477.0809\n",
      "Epoch 1722/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1919.5870 - val_loss: 3569.2080\n",
      "Epoch 1723/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1892.6833 - val_loss: 3757.8153\n",
      "Epoch 1724/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1893.0525 - val_loss: 3615.0636\n",
      "Epoch 1725/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1769.2629 - val_loss: 3611.2431\n",
      "Epoch 1726/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1829.1949 - val_loss: 3725.7415\n",
      "Epoch 1727/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1756.9172 - val_loss: 3654.1442\n",
      "Epoch 1728/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1690.5527 - val_loss: 3638.1720\n",
      "Epoch 1729/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1646.7085 - val_loss: 3831.6182\n",
      "Epoch 1730/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1664.1756 - val_loss: 4025.4131\n",
      "Epoch 1731/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1613.1148 - val_loss: 3954.7706\n",
      "Epoch 1732/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1531.1772 - val_loss: 3945.1270\n",
      "Epoch 1733/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1548.0151 - val_loss: 4023.0034\n",
      "Epoch 1734/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1505.1442 - val_loss: 4084.7708\n",
      "Epoch 1735/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1556.9347 - val_loss: 4053.3909\n",
      "Epoch 1736/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1419.8433 - val_loss: 3949.3931\n",
      "Epoch 1737/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1433.0141 - val_loss: 4011.9897\n",
      "Epoch 1738/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1408.5111 - val_loss: 4155.6982\n",
      "Epoch 1739/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1400.5732 - val_loss: 3746.6084\n",
      "Epoch 1740/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1455.8563 - val_loss: 3350.8416\n",
      "Epoch 1741/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1431.8448 - val_loss: 3275.3155\n",
      "Epoch 1742/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1608.1297 - val_loss: 3740.6578\n",
      "Epoch 1743/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1703.0487 - val_loss: 3689.6856\n",
      "Epoch 1744/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2099.8385 - val_loss: 3388.7531\n",
      "Epoch 1745/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1930.0711 - val_loss: 3840.7705\n",
      "Epoch 1746/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2524.4399 - val_loss: 3631.2433\n",
      "Epoch 1747/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2785.6109 - val_loss: 3884.2115\n",
      "Epoch 1748/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 3004.2475 - val_loss: 3897.9787\n",
      "Epoch 1749/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2803.9405 - val_loss: 3690.6605\n",
      "Epoch 1750/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2513.3950 - val_loss: 3824.3410\n",
      "Epoch 1751/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2501.7477 - val_loss: 3757.3962\n",
      "Epoch 1752/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2459.8052 - val_loss: 3361.7086\n",
      "Epoch 1753/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2379.4267 - val_loss: 3454.9164\n",
      "Epoch 1754/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2259.3875 - val_loss: 3644.2792\n",
      "Epoch 1755/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2275.0425 - val_loss: 3581.2681\n",
      "Epoch 1756/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2249.1314 - val_loss: 3548.9808\n",
      "Epoch 1757/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2183.0506 - val_loss: 3518.8963\n",
      "Epoch 1758/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2171.2345 - val_loss: 3397.8145\n",
      "Epoch 1759/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2147.4841 - val_loss: 3359.4092\n",
      "Epoch 1760/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2109.3421 - val_loss: 3424.7593\n",
      "Epoch 1761/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2091.4057 - val_loss: 3301.0411\n",
      "Epoch 1762/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2011.8902 - val_loss: 3252.0483\n",
      "Epoch 1763/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2048.3342 - val_loss: 3115.2142\n",
      "Epoch 1764/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1945.2714 - val_loss: 3099.3422\n",
      "Epoch 1765/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1912.2865 - val_loss: 3124.3702\n",
      "Epoch 1766/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1858.2629 - val_loss: 3083.8279\n",
      "Epoch 1767/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1836.5127 - val_loss: 3047.2129\n",
      "Epoch 1768/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1818.3742 - val_loss: 2842.3225\n",
      "Epoch 1769/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1832.9072 - val_loss: 2901.2953\n",
      "Epoch 1770/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1705.0790 - val_loss: 3094.2261\n",
      "Epoch 1771/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1754.2955 - val_loss: 2924.8088\n",
      "Epoch 1772/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1931.0829 - val_loss: 3168.4033\n",
      "Epoch 1773/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1972.3877 - val_loss: 2782.4578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1774/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1869.7474 - val_loss: 2880.5767\n",
      "Epoch 1775/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1857.6402 - val_loss: 3256.4241\n",
      "Epoch 1776/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1658.4097 - val_loss: 2857.1004\n",
      "Epoch 1777/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1762.4571 - val_loss: 2773.4951\n",
      "Epoch 1778/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1929.0608 - val_loss: 2837.7523\n",
      "Epoch 1779/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1798.3660 - val_loss: 2996.3309\n",
      "Epoch 1780/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1591.1858 - val_loss: 3016.1707\n",
      "Epoch 1781/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1579.6331 - val_loss: 2595.7475\n",
      "Epoch 1782/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1791.5439 - val_loss: 2655.3388\n",
      "Epoch 1783/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1605.3708 - val_loss: 3112.6380\n",
      "Epoch 1784/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1565.6361 - val_loss: 3109.8879\n",
      "Epoch 1785/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1691.3777 - val_loss: 2982.6394\n",
      "Epoch 1786/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1607.4152 - val_loss: 2634.8276\n",
      "Epoch 1787/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1618.2459 - val_loss: 2621.2650\n",
      "Epoch 1788/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1570.3171 - val_loss: 2911.6854\n",
      "Epoch 1789/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1561.6694 - val_loss: 2976.5971\n",
      "Epoch 1790/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1534.0081 - val_loss: 2802.7318\n",
      "Epoch 1791/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1606.4106 - val_loss: 2721.2811\n",
      "Epoch 1792/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1389.2572 - val_loss: 2778.7814\n",
      "Epoch 1793/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1467.6325 - val_loss: 2897.3122\n",
      "Epoch 1794/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1348.4475 - val_loss: 2541.9753\n",
      "Epoch 1795/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1726.5754 - val_loss: 2615.5486\n",
      "Epoch 1796/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1490.0216 - val_loss: 2750.8568\n",
      "Epoch 1797/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1292.7991 - val_loss: 2734.9192\n",
      "Epoch 1798/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1424.8799 - val_loss: 2594.7578\n",
      "Epoch 1799/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1433.9310 - val_loss: 2903.3664\n",
      "Epoch 1800/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1556.9236 - val_loss: 2787.3188\n",
      "Epoch 1801/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1383.3709 - val_loss: 2581.2872\n",
      "Epoch 1802/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1230.1680 - val_loss: 2528.0310\n",
      "Epoch 1803/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1226.9099 - val_loss: 2754.6034\n",
      "Epoch 1804/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1262.0554 - val_loss: 2865.2440\n",
      "Epoch 1805/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1473.4573 - val_loss: 2749.4757\n",
      "Epoch 1806/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1549.3778 - val_loss: 2770.4878\n",
      "Epoch 1807/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1284.9047 - val_loss: 2712.5941\n",
      "Epoch 1808/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1188.0477 - val_loss: 2656.6626\n",
      "Epoch 1809/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1082.8564 - val_loss: 2490.5122\n",
      "Epoch 1810/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1148.3046 - val_loss: 2716.1981\n",
      "Epoch 1811/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1076.8844 - val_loss: 2898.8874\n",
      "Epoch 1812/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1210.1217 - val_loss: 2367.6648\n",
      "Epoch 1813/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1343.2840 - val_loss: 2562.4862\n",
      "Epoch 1814/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1202.3934 - val_loss: 2772.9862\n",
      "Epoch 1815/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1225.7414 - val_loss: 2694.7663\n",
      "Epoch 1816/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1535.0074 - val_loss: 2509.4506\n",
      "Epoch 1817/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1640.0384 - val_loss: 3127.6841\n",
      "Epoch 1818/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1868.7645 - val_loss: 3396.9902\n",
      "Epoch 1819/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1762.7342 - val_loss: 3052.6169\n",
      "Epoch 1820/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1459.8713 - val_loss: 2540.8085\n",
      "Epoch 1821/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1684.4934 - val_loss: 2648.9426\n",
      "Epoch 1822/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1404.7814 - val_loss: 3333.2554\n",
      "Epoch 1823/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1363.2777 - val_loss: 3098.0123\n",
      "Epoch 1824/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1250.6141 - val_loss: 3070.2497\n",
      "Epoch 1825/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1192.7449 - val_loss: 2849.9483\n",
      "Epoch 1826/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1217.9627 - val_loss: 2871.3753\n",
      "Epoch 1827/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1178.2359 - val_loss: 2730.1568\n",
      "Epoch 1828/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1608.6701 - val_loss: 2681.0621\n",
      "Epoch 1829/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1237.5903 - val_loss: 2301.9419\n",
      "Epoch 1830/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1236.0114 - val_loss: 2508.3696\n",
      "Epoch 1831/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1340.7560 - val_loss: 2425.0751\n",
      "Epoch 1832/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1246.9154 - val_loss: 2353.3646\n",
      "Epoch 1833/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1087.4906 - val_loss: 2458.3332\n",
      "Epoch 1834/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1062.3834 - val_loss: 2566.5081\n",
      "Epoch 1835/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 957.5502 - val_loss: 2540.8849\n",
      "Epoch 1836/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 944.6120 - val_loss: 2415.4735\n",
      "Epoch 1837/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 886.9450 - val_loss: 2345.7764\n",
      "Epoch 1838/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 888.1446 - val_loss: 2235.9937\n",
      "Epoch 1839/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 817.3076 - val_loss: 2190.8760\n",
      "Epoch 1840/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 845.8326 - val_loss: 2087.6424\n",
      "Epoch 1841/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 853.6748 - val_loss: 2458.5814\n",
      "Epoch 1842/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 924.8702 - val_loss: 2120.9084\n",
      "Epoch 1843/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1035.0887 - val_loss: 2277.5104\n",
      "Epoch 1844/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1146.5263 - val_loss: 2174.0189\n",
      "Epoch 1845/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 938.6699 - val_loss: 2262.2667\n",
      "Epoch 1846/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 988.0389 - val_loss: 2047.4703\n",
      "Epoch 1847/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1124.2749 - val_loss: 2853.3237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1848/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1199.5128 - val_loss: 2628.3473\n",
      "Epoch 1849/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1089.0349 - val_loss: 2331.6551\n",
      "Epoch 1850/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 999.8988 - val_loss: 2393.7883\n",
      "Epoch 1851/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 986.8168 - val_loss: 2551.1653\n",
      "Epoch 1852/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 996.3885 - val_loss: 2997.0667\n",
      "Epoch 1853/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2556.6989 - val_loss: 3555.6443\n",
      "Epoch 1854/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 2431.9577 - val_loss: 3275.1653\n",
      "Epoch 1855/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1990.2107 - val_loss: 2506.2094\n",
      "Epoch 1856/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1575.2557 - val_loss: 2775.6660\n",
      "Epoch 1857/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1630.2360 - val_loss: 3138.5762\n",
      "Epoch 1858/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1555.6068 - val_loss: 3098.0000\n",
      "Epoch 1859/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1546.6863 - val_loss: 2873.8904\n",
      "Epoch 1860/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1436.9633 - val_loss: 2616.8121\n",
      "Epoch 1861/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1324.7789 - val_loss: 2305.2784\n",
      "Epoch 1862/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1301.9961 - val_loss: 2147.6717\n",
      "Epoch 1863/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1320.5955 - val_loss: 2115.7913\n",
      "Epoch 1864/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1333.8826 - val_loss: 2143.5839\n",
      "Epoch 1865/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1297.5818 - val_loss: 2374.9955\n",
      "Epoch 1866/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1296.8882 - val_loss: 2388.3903\n",
      "Epoch 1867/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1169.4574 - val_loss: 2465.6628\n",
      "Epoch 1868/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1110.6086 - val_loss: 2467.0254\n",
      "Epoch 1869/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1115.8702 - val_loss: 2437.9504\n",
      "Epoch 1870/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1227.9042 - val_loss: 2259.7448\n",
      "Epoch 1871/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1056.6370 - val_loss: 2574.3683\n",
      "Epoch 1872/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1086.9690 - val_loss: 2575.3788\n",
      "Epoch 1873/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1056.0579 - val_loss: 2451.0069\n",
      "Epoch 1874/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1074.8193 - val_loss: 2671.0823\n",
      "Epoch 1875/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1021.4640 - val_loss: 2377.6551\n",
      "Epoch 1876/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 996.7164 - val_loss: 2352.8122\n",
      "Epoch 1877/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 910.2952 - val_loss: 2747.9282\n",
      "Epoch 1878/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 987.6772 - val_loss: 2502.4242\n",
      "Epoch 1879/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 916.4035 - val_loss: 2383.1655\n",
      "Epoch 1880/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 959.3613 - val_loss: 2451.3630\n",
      "Epoch 1881/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 854.1608 - val_loss: 2138.7921\n",
      "Epoch 1882/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1014.9667 - val_loss: 2303.4404\n",
      "Epoch 1883/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 883.7743 - val_loss: 2459.3751\n",
      "Epoch 1884/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 933.6031 - val_loss: 2810.1940\n",
      "Epoch 1885/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1071.8015 - val_loss: 2557.8735\n",
      "Epoch 1886/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 945.0923 - val_loss: 2326.1217\n",
      "Epoch 1887/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 837.5291 - val_loss: 2990.4771\n",
      "Epoch 1888/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 775.5666 - val_loss: 3013.4377\n",
      "Epoch 1889/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 813.8489 - val_loss: 2953.3205\n",
      "Epoch 1890/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 697.7772 - val_loss: 3064.5846\n",
      "Epoch 1891/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 720.7315 - val_loss: 2463.4683\n",
      "Epoch 1892/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 665.6412 - val_loss: 3105.5776\n",
      "Epoch 1893/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 692.9287 - val_loss: 2821.9186\n",
      "Epoch 1894/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 726.1913 - val_loss: 2093.9938\n",
      "Epoch 1895/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1025.4021 - val_loss: 2340.2956\n",
      "Epoch 1896/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 989.0764 - val_loss: 2545.6931\n",
      "Epoch 1897/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 867.6015 - val_loss: 4234.4294\n",
      "Epoch 1898/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1254.6496 - val_loss: 4643.2946\n",
      "Epoch 1899/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1279.4242 - val_loss: 4273.4785\n",
      "Epoch 1900/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 1003.8092 - val_loss: 3646.4320\n",
      "Epoch 1901/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 965.8767 - val_loss: 1856.2693\n",
      "Epoch 1902/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 924.2494 - val_loss: 2037.2627\n",
      "Epoch 1903/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 828.4567 - val_loss: 1987.4633\n",
      "Epoch 1904/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 810.0265 - val_loss: 2361.3802\n",
      "Epoch 1905/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 777.7223 - val_loss: 2966.2842\n",
      "Epoch 1906/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 739.5403 - val_loss: 2629.4472\n",
      "Epoch 1907/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 701.4186 - val_loss: 2708.7767\n",
      "Epoch 1908/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 769.4316 - val_loss: 3001.7581\n",
      "Epoch 1909/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 714.7508 - val_loss: 3105.7697\n",
      "Epoch 1910/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 680.1525 - val_loss: 2455.1351\n",
      "Epoch 1911/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 776.4572 - val_loss: 2653.6782\n",
      "Epoch 1912/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 852.6598 - val_loss: 3090.0857\n",
      "Epoch 1913/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 828.0291 - val_loss: 3319.0050\n",
      "Epoch 1914/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 756.9288 - val_loss: 2342.6846\n",
      "Epoch 1915/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 613.5088 - val_loss: 2738.8124\n",
      "Epoch 1916/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 662.4078 - val_loss: 2594.1225\n",
      "Epoch 1917/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 658.9078 - val_loss: 2754.0976\n",
      "Epoch 1918/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 723.5527 - val_loss: 4005.6090\n",
      "Epoch 1919/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 877.3005 - val_loss: 4596.6411\n",
      "Epoch 1920/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 943.5019 - val_loss: 4661.9055\n",
      "Epoch 1921/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 839.8350 - val_loss: 3700.2431\n",
      "Epoch 1922/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 904.0833 - val_loss: 3353.1993\n",
      "Epoch 1923/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 715.6160 - val_loss: 3989.5091\n",
      "Epoch 1924/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 779.5127 - val_loss: 3829.9028\n",
      "Epoch 1925/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 776.8697 - val_loss: 3261.2662\n",
      "Epoch 1926/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 793.0326 - val_loss: 3340.3266\n",
      "Epoch 1927/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 795.1440 - val_loss: 3226.3134\n",
      "Epoch 1928/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 796.0550 - val_loss: 3221.0261\n",
      "Epoch 1929/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 728.8759 - val_loss: 2556.8135\n",
      "Epoch 1930/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 951.4116 - val_loss: 2129.7794\n",
      "Epoch 1931/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 820.6187 - val_loss: 3264.0205\n",
      "Epoch 1932/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 844.9381 - val_loss: 4401.9583\n",
      "Epoch 1933/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 736.7700 - val_loss: 3162.7166\n",
      "Epoch 1934/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 844.4454 - val_loss: 3419.0634\n",
      "Epoch 1935/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 844.0330 - val_loss: 4359.6869\n",
      "Epoch 1936/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 783.7139 - val_loss: 4006.0802\n",
      "Epoch 1937/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 852.1307 - val_loss: 4004.2256\n",
      "Epoch 1938/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 733.4971 - val_loss: 3689.4216\n",
      "Epoch 1939/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 799.4644 - val_loss: 3507.7402\n",
      "Epoch 1940/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 658.3513 - val_loss: 3851.9301\n",
      "Epoch 1941/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 724.8539 - val_loss: 3653.9131\n",
      "Epoch 1942/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 663.5999 - val_loss: 3391.8701\n",
      "Epoch 1943/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 660.9288 - val_loss: 3370.8237\n",
      "Epoch 1944/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 599.1621 - val_loss: 3307.5302\n",
      "Epoch 1945/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 603.9159 - val_loss: 3270.8629\n",
      "Epoch 1946/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 612.6689 - val_loss: 3357.8742\n",
      "Epoch 1947/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 578.1269 - val_loss: 3332.6057\n",
      "Epoch 1948/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 592.9259 - val_loss: 3500.9947\n",
      "Epoch 1949/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 676.1812 - val_loss: 3663.1110\n",
      "Epoch 1950/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 599.8026 - val_loss: 3401.8794\n",
      "Epoch 1951/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 553.2787 - val_loss: 3530.4915\n",
      "Epoch 1952/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 601.7566 - val_loss: 3554.0690\n",
      "Epoch 1953/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 601.8604 - val_loss: 3710.0362\n",
      "Epoch 1954/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 556.1011 - val_loss: 3571.5406\n",
      "Epoch 1955/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 576.3204 - val_loss: 3715.5721\n",
      "Epoch 1956/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 568.8953 - val_loss: 3618.1762\n",
      "Epoch 1957/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 622.6288 - val_loss: 3642.2453\n",
      "Epoch 1958/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 554.6658 - val_loss: 3685.9211\n",
      "Epoch 1959/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 557.4137 - val_loss: 3553.2265\n",
      "Epoch 1960/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 527.0931 - val_loss: 3609.9203\n",
      "Epoch 1961/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 548.2696 - val_loss: 3599.5705\n",
      "Epoch 1962/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 512.2972 - val_loss: 3540.2486\n",
      "Epoch 1963/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 454.9909 - val_loss: 3805.6845\n",
      "Epoch 1964/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 546.0747 - val_loss: 3699.8691\n",
      "Epoch 1965/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 527.2770 - val_loss: 3631.5444\n",
      "Epoch 1966/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 507.0782 - val_loss: 3670.9876\n",
      "Epoch 1967/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 542.8822 - val_loss: 3669.4606\n",
      "Epoch 1968/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 779.7612 - val_loss: 3305.5045\n",
      "Epoch 1969/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 771.9222 - val_loss: 3848.3778\n",
      "Epoch 1970/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 649.7081 - val_loss: 3340.1086\n",
      "Epoch 1971/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 939.3466 - val_loss: 3861.0452\n",
      "Epoch 1972/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 872.3640 - val_loss: 3563.9116\n",
      "Epoch 1973/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 865.5620 - val_loss: 4017.1510\n",
      "Epoch 1974/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 928.1069 - val_loss: 3827.8200\n",
      "Epoch 1975/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 843.8266 - val_loss: 3604.5202\n",
      "Epoch 1976/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 750.9869 - val_loss: 3575.6776\n",
      "Epoch 1977/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 654.8540 - val_loss: 3525.5096\n",
      "Epoch 1978/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 761.0507 - val_loss: 3975.5848\n",
      "Epoch 1979/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 803.1109 - val_loss: 3955.9809\n",
      "Epoch 1980/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 738.3412 - val_loss: 3569.3685\n",
      "Epoch 1981/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 624.7440 - val_loss: 3331.5927\n",
      "Epoch 1982/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 608.8946 - val_loss: 4225.2153\n",
      "Epoch 1983/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 779.0761 - val_loss: 4306.0108\n",
      "Epoch 1984/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 590.9627 - val_loss: 3627.1958\n",
      "Epoch 1985/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 694.0230 - val_loss: 3695.5309\n",
      "Epoch 1986/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 839.2204 - val_loss: 3883.1284\n",
      "Epoch 1987/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 697.0150 - val_loss: 4450.8545\n",
      "Epoch 1988/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 695.0542 - val_loss: 4086.0057\n",
      "Epoch 1989/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 706.9589 - val_loss: 3857.5834\n",
      "Epoch 1990/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 747.4046 - val_loss: 3451.8316\n",
      "Epoch 1991/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 671.7624 - val_loss: 3443.3721\n",
      "Epoch 1992/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 704.4066 - val_loss: 3337.9410\n",
      "Epoch 1993/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 853.5459 - val_loss: 3795.6266\n",
      "Epoch 1994/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 739.1498 - val_loss: 4702.4617\n",
      "Epoch 1995/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 834.3409 - val_loss: 3928.0183\n",
      "Epoch 1996/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - 0s 1ms/step - loss: 788.7973 - val_loss: 3469.6530\n",
      "Epoch 1997/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 806.1235 - val_loss: 3462.7354\n",
      "Epoch 1998/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 669.5143 - val_loss: 3332.6017\n",
      "Epoch 1999/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 666.9318 - val_loss: 3395.0332\n",
      "Epoch 2000/2000\n",
      "122/122 [==============================] - 0s 1ms/step - loss: 619.8315 - val_loss: 3090.7973\n",
      "Training Model took:  277.72938084602356\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "#import tensorflow as tf\n",
    "d = 0.01\n",
    "model = Sequential()\n",
    "input_shape=(101,29)\n",
    "model.add(Bidirectional(GRU(64, input_shape=(101,29), return_sequences=False)))\n",
    "model.add(Dropout(d))\n",
    "model.add(SelfAttention(64))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(SelfAttention(32))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(SelfAttention(32))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(SelfAttention(16))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(SelfAttention(16))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(SelfAttention(8))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(SelfAttention(8))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(SelfAttention(4))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(SelfAttention(4))\n",
    "model.add(Dense(2, activation='relu'))\n",
    "model.add(SelfAttention(2))\n",
    "model.add(Dense(2, activation='relu'))\n",
    "model.add(SelfAttention(2))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "#model = load_model('C:/Users/Danny Lee/Desktop/motion hw/final/LSTM model performance/try_best_nodropout/Regression.h5')\n",
    "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss='mean_squared_error', optimizer= opt)\n",
    "start_fitting = time.time()\n",
    "#model.load_weights('C:/Users/Danny Lee/Desktop/motion hw/final/LSTM model performance/try_best_nodropout/Regression_weights.h5'.encode('utf-8'))\n",
    "#model = tf.keras.models.load_model('C:/Users/Danny Lee/Desktop/motion hw/final/LSTM model performance/try_best_nodropout/Regression_weights.h5')\n",
    "model.fit(X_train, y_train, epochs=2000, batch_size=32,validation_data=(X_val, y_val))\n",
    "fitting_model_time = time.time()\n",
    "print('Training Model took: ', fitting_model_time - start_fitting)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66f013a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_1 (Bidirection (None, 128)               36096     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "self_attention_1 (SelfAttent (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "self_attention_2 (SelfAttent (None, 32)                1088      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "self_attention_3 (SelfAttent (None, 32)                1088      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "self_attention_4 (SelfAttent (None, 16)                288       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "self_attention_5 (SelfAttent (None, 16)                288       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "self_attention_6 (SelfAttent (None, 8)                 80        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "self_attention_7 (SelfAttent (None, 8)                 80        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "self_attention_8 (SelfAttent (None, 4)                 24        \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "self_attention_9 (SelfAttent (None, 4)                 24        \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "self_attention_10 (SelfAtten (None, 2)                 8         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "self_attention_11 (SelfAtten (None, 2)                 8         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 53,659\n",
      "Trainable params: 53,659\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "model.build(input_shape)\n",
    "print(model.summary())\n",
    "with open('./LSTM model performance/try_0612_dropout_adam/modelsummary.txt', 'w') as f:\n",
    "\n",
    "    model.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
    "\n",
    "#earlystopping\n",
    "#monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=50, verbose=2, mode='auto', restore_best_weights=True)\n",
    "#model.fit(X_train, y_train, nb_epoch = 1000, batch_size = 32,validation_data=(X_val, y_val),callbacks=[monitor]) #训练模型1000次\n",
    "#epochxxx =  monitor.stopped_epoch+1   #len(model.history.history['loss'])\n",
    "#print(epochxxx)    \n",
    "\n",
    "#保存模型和權重\n",
    "saved = model.save('./LSTM model performance/try_0612_dropout_adam/Regression.h5')    \n",
    "model.save_weights('./LSTM model performance/try_0612_dropout_adam/Regression_weights.h5')  # to store\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cea8a172",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-5d8d8c9801ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#画出迭代loss和acc曲线\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "#画出迭代loss和acc曲线\n",
    "pd.DataFrame(model.history.history).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f19d61aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122 122\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22380\\2258532660.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Value(mm)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'True Values vs Predictions'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Ray Lee\\anaconda3\\envs\\tf1\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mxticks\u001b[1;34m(ticks, labels, **kwargs)\u001b[0m\n\u001b[0;32m   1812\u001b[0m             \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1813\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1814\u001b[1;33m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_xticklabels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1815\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1816\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mlocs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Ray Lee\\anaconda3\\envs\\tf1\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mget_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mowner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Ray Lee\\anaconda3\\envs\\tf1\\lib\\site-packages\\matplotlib\\axis.py\u001b[0m in \u001b[0;36m_set_ticklabels\u001b[1;34m(self, labels, fontdict, minor, **kwargs)\u001b[0m\n\u001b[0;32m   1796\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfontdict\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1797\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfontdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1798\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_ticklabels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mminor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1799\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1800\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set_tick_locations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mticks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Ray Lee\\anaconda3\\envs\\tf1\\lib\\site-packages\\matplotlib\\axis.py\u001b[0m in \u001b[0;36mset_ticklabels\u001b[1;34m(self, ticklabels, minor, **kwargs)\u001b[0m\n\u001b[0;32m   1711\u001b[0m         \"\"\"\n\u001b[0;32m   1712\u001b[0m         ticklabels = [t.get_text() if hasattr(t, 'get_text') else t\n\u001b[1;32m-> 1713\u001b[1;33m                       for t in ticklabels]\n\u001b[0m\u001b[0;32m   1714\u001b[0m         locator = (self.get_minor_locator() if minor\n\u001b[0;32m   1715\u001b[0m                    else self.get_major_locator())\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#在训练集上的拟合结果\n",
    "\n",
    "y_train_predict=model.predict(X_train)\n",
    "y_train_predict=y_train_predict[:,0]\n",
    "\n",
    "#categories = ['Category 1', 'Category 2']\n",
    "#x = range(len(categories))\n",
    "a = np.arange(20)\n",
    "b = np.arange(20)\n",
    "print(len(y_train),len(y_train_predict))\n",
    "\n",
    "plt.bar(a,y_train[0:20], label='True Values',color='blue')\n",
    "plt.bar(b,y_train_predict[0:20],label='Predictions',color='orange')\n",
    "#plt.title('title name')\n",
    "plt.xlabel('Training Data')\n",
    "plt.ylabel('Value(mm)')\n",
    "plt.title('True Values vs Predictions')\n",
    "#plt.xticks(a, 20)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "print(X_train)\n",
    "plt.plot(y_train, label='True Values')\n",
    "plt.plot(y_train_predict, label='Predictions')\n",
    "plt.xlabel('Training Data')\n",
    "plt.ylabel('Value(mm)')\n",
    "plt.title('True Values vs Predictions')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "'''\n",
    "'''\n",
    "draw=pd.concat([pd.DataFrame(y_train),pd.DataFrame(y_train_predict)],axis=1)\n",
    "draw.iloc[100:150,0].plot(figsize=(12,6))\n",
    "draw.iloc[100:150,1].plot(figsize=(12,6))\n",
    "plt.legend(('real', 'predict'),fontsize='15')\n",
    "plt.title(\"Training Data\",fontsize='30') #添加标题\n",
    "#plt.show()\n",
    "#fig.savefig('./LSTM model performance/Regression_heel_test/train_Validation_loss.png')\n",
    "#展示在训练集上的表现 \n",
    "'''\n",
    "'''\n",
    "epocha=range(len(y_train))\n",
    "epochb=range(len(y_train_predict))\n",
    "plt.plot(epocha, y_train, 'g', label='real')\n",
    "plt.plot(epochb, y_train_predict, 'b', label='predict')\n",
    "plt.legend(('real', 'predict'),fontsize='15')\n",
    "plt.title(\"Train Data\",fontsize='30') #添加标题\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07dc0c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\nepochc=range(len(y_test))\\nepochd=range(len(y_test_predict))\\n\\nplt.plot(epochc, y_test, \\'g\\', label=\\'real\\')\\nplt.plot(epochd, y_test_predict, \\'b\\', label=\\'predict\\')\\nplt.title(\"Test Data\",fontsize=\\'30\\') #添加标题\\nplt.legend((\\'real\\', \\'predict\\'),loc=\\'upper right\\',fontsize=\\'15\\')\\nplt.show()\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_predict=model.predict(X_test)\n",
    "y_test_predict=y_test_predict[:,0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Plot the true values and predictions\n",
    "plt.plot(y_test, label='True Values')\n",
    "plt.plot(y_test_predict, label='Predictions')\n",
    "plt.xlabel('Testing Data')\n",
    "plt.ylabel('Value(mm)')\n",
    "plt.title('True Values vs Predictions')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "#在测试集上的预测\n",
    "y_test_predict=model.predict(X_test)\n",
    "y_test_predict=y_test_predict[:,0]\n",
    "draw=pd.concat([pd.DataFrame(y_test),pd.DataFrame(y_test_predict)],axis=1);\n",
    "draw.iloc[200:250,0].plot(figsize=(12,6))\n",
    "draw.iloc[200:250,1].plot(figsize=(12,6))\n",
    "plt.legend(('real', 'predict'),loc='upper right',fontsize='15')\n",
    "plt.title(\"Test Data\",fontsize='30') #添加标题\n",
    "#展示在测试集上的表现 \n",
    "\n",
    "y_test_predict = model.predict(X_test).flatten()\n",
    "y_test_predict=y_test_predict[:,0]\n",
    "a = plt.axes(aspect='equal')\n",
    "plt.scatter(y_test, y_test_predict)\n",
    "plt.xlabel('True Values [MPG]')\n",
    "plt.ylabel('Predictions [MPG]')\n",
    "lims = [0, 100]\n",
    "plt.xlim(lims)\n",
    "plt.ylim(lims)\n",
    "_ = plt.plot(lims, lims)\n",
    "'''\n",
    "'''\n",
    "epochc=range(len(y_test))\n",
    "epochd=range(len(y_test_predict))\n",
    "\n",
    "plt.plot(epochc, y_test, 'g', label='real')\n",
    "plt.plot(epochd, y_test_predict, 'b', label='predict')\n",
    "plt.title(\"Test Data\",fontsize='30') #添加标题\n",
    "plt.legend(('real', 'predict'),loc='upper right',fontsize='15')\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca6cf74d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練集上的MAE/MSE/MAPE\n",
      "41.703923405811715\n",
      "2764.15434413441\n",
      "24.243047491279114\n",
      "測試集上的MAE/MSE/MAPE\n",
      "39.79790393067814\n",
      "2894.908845695323\n",
      "23.135052921911413\n",
      "預測漲跌正確: 0.0\n",
      "Training Model took:  270.006472826004\n",
      "TOTAL time spent 400.6702301502228\n"
     ]
    }
   ],
   "source": [
    "#輸出结果\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "def mape(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_pred - y_true) / y_true)) * 100\n",
    "print('訓練集上的MAE/MSE/MAPE')\n",
    "print(mean_absolute_error(y_train_predict, y_train))\n",
    "print(mean_squared_error(y_train_predict, y_train) )\n",
    "print(mape(y_train_predict, y_train) )\n",
    "print('測試集上的MAE/MSE/MAPE')\n",
    "print(mean_absolute_error(y_test_predict, y_test))\n",
    "print(mean_squared_error(y_test_predict, y_test) )\n",
    "print(mape(y_test_predict,  y_test) )\n",
    "y_var_test=y_test[1:]-y_test[:len(y_test)-1]\n",
    "y_var_predict=y_test_predict[1:]-y_test_predict[:len(y_test_predict)-1]\n",
    "txt=np.zeros(len(y_var_test))\n",
    "for i in range(len(y_var_test-1)):\n",
    "    txt[i]=np.sign(y_var_test[i])==np.sign(y_var_predict[i])\n",
    "result=sum(txt)/len(txt)\n",
    "print('預測漲跌正確:',result)\n",
    "print('Training Model took: ', fitting_model_time - start_fitting)\n",
    "#print('训练时间（秒）:',54.56)\n",
    "\n",
    "end = time.time()\n",
    "print('TOTAL time spent', end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d8642d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
